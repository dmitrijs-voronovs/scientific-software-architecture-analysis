id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/624:191,safety,error,error,191,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:269,safety,avail,available,269,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:8,security,model,model,8,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:14,security,availab,availability,14,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:56,security,model,model,56,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:83,security,availab,available,83,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:231,security,model,model,231,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:269,security,availab,available,269,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:356,security,model,models,356,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:433,security,model,model,433,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:466,security,model,model,466,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:472,security,model,model,472,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:561,security,model,models,561,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:638,security,model,model,638,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:671,security,model,model,671,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:677,security,model,model,677,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:139,testability,simpl,simply,139,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:139,usability,simpl,simply,139,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:191,usability,error,error,191,"RNA-seq model availability for v1.5.0; Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```. # works . curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. # fails. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/625:0,availability,Checkpoint,Checkpoint,0,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:165,availability,error,error,165,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1789,availability,checkpoint,checkpoint,1789,"ain=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1854,availability,checkpoint,checkpoint,1854,"ile ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1887,availability,checkpoint,checkpoint,1887,"e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2931,availability,checkpoint,checkpoint,2931,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:657,deployability,modul,module,657,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2061,deployability,LOG,LOGDIR,2061,"File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2085,deployability,log,logs,2085,"c2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2106,deployability,LOG,LOGDIR,2106,"7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postproc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2194,deployability,LOG,LOGDIR,2194,"/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2202,deployability,log,log,2202,"es/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2216,deployability,LOG,LOGDIR,2216,"/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2778,deployability,log,log,2778,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3059,deployability,log,log,3059,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3396,deployability,log,log,3396,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:137,energy efficiency,model,model,137,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2947,energy efficiency,model,models,2947,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2958,energy efficiency,model,model,2958,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:29,interoperability,mismatch,mismatched,29,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:753,interoperability,platform,platform,753,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:657,modifiability,modul,module,657,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:726,modifiability,pac,packages,726,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:165,performance,error,error,165,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2129,performance,time,time,2129,"a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2158,performance,parallel,parallel,2158,"deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:0,reliability,Checkpoint,Checkpoint,0,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1789,reliability,checkpoint,checkpoint,1789,"ain=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1854,reliability,checkpoint,checkpoint,1854,"ile ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1887,reliability,checkpoint,checkpoint,1887,"e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2931,reliability,checkpoint,checkpoint,2931,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:78,safety,test,tested,78,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:117,safety,test,testdata,117,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:165,safety,error,error,165,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:331,safety,input,input,331,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:374,safety,input,input,374,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:657,safety,modul,module,657,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2061,safety,LOG,LOGDIR,2061,"File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2085,safety,log,logs,2085,"c2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2106,safety,LOG,LOGDIR,2106,"7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postproc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2194,safety,LOG,LOGDIR,2194,"/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2202,safety,log,log,2202,"es/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2216,safety,LOG,LOGDIR,2216,"/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2778,safety,log,log,2778,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3059,safety,log,log,3059,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3396,safety,log,log,3396,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:137,security,model,model,137,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2061,security,LOG,LOGDIR,2061,"File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2085,security,log,logs,2085,"c2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2106,security,LOG,LOGDIR,2106,"7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postproc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2194,security,LOG,LOGDIR,2194,"/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2202,security,log,log,2202,"es/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2216,security,LOG,LOGDIR,2216,"/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2778,security,log,log,2778,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2947,security,model,models,2947,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2958,security,model,model,2958,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3059,security,log,log,3059,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3396,security,log,log,3396,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:78,testability,test,tested,78,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:117,testability,test,testdata,117,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:410,testability,Trace,Traceback,410,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2061,testability,LOG,LOGDIR,2061,"File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2085,testability,log,logs,2085,"c2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2106,testability,LOG,LOGDIR,2106,"7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postproc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2194,testability,LOG,LOGDIR,2194,"/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2202,testability,log,log,2202,"es/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2216,testability,LOG,LOGDIR,2216,"/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2693,testability,unit,unittest,2693,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2778,testability,log,log,2778,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3059,testability,log,log,3059,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3195,testability,unit,unittest,3195,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3396,testability,log,log,3396,"all_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing? Thanks,. Raisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:165,usability,error,error,165,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:331,usability,input,input,331,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:374,usability,input,input,374,"Checkpoint and examples have mismatched number of channels; Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1943,usability,command,command,1943,"9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/626:648,availability,avail,available,648,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:284,deployability,observ,observed,284,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:222,integrability,sub,submission,222,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:382,integrability,sub,submission,382,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:559,integrability,sub,submission,559,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:584,integrability,filter,filtering,584,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:639,integrability,pub,publicly,639,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:648,reliability,availab,available,648,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:648,safety,avail,available,648,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:648,security,availab,available,648,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:284,testability,observ,observed,284,"Benchmarking of NA24385 sample with v1.5.0; I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`. deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/627:17,availability,error,error,17,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:207,availability,error,error,207,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:245,availability,Operat,Operating,245,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:37,deployability,instal,installed,37,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:53,deployability,version,version,53,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:285,deployability,version,version,285,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:303,deployability,Instal,Installation,303,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:53,integrability,version,version,53,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:285,integrability,version,version,285,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:53,modifiability,version,version,53,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:285,modifiability,version,version,285,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:17,performance,error,error,17,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:207,performance,error,error,207,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:17,safety,error,error,17,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:207,safety,error,error,207,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:17,usability,error,error,17,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:207,usability,error,error,207,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:395,usability,Command,Command,395,"dv_* file syntax error from bioconda installed 1.4.0 version DeepVariant; . Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**. - Operating system: Centos. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**. - Command: dv_make_examples.py -h.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/628:130,availability,error,error,130,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:398,availability,operat,operations,398,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:452,availability,operat,operations,452,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3345,availability,checkpoint,checkpoint,3345,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:1199,deployability,modul,module,1199,"nsorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2553,deployability,LOG,LOGDIR,2553,"app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2577,deployability,log,logs,2577,"un. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2598,deployability,LOG,LOGDIR,2598,"gs). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2686,deployability,LOG,LOGDIR,2686,"b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2694,deployability,log,log,2694,"15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2708,deployability,LOG,LOGDIR,2708,"iant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3192,deployability,log,log,3192,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3440,deployability,log,log,3440,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3678,deployability,log,log,3678,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:7,energy efficiency,model,model,7,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:106,energy efficiency,model,model,106,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:211,energy efficiency,core,core,211,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:277,energy efficiency,optim,optimized,277,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:357,energy efficiency,CPU,CPU,357,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:810,energy efficiency,model,models,810,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:824,energy efficiency,model,model,824,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2433,energy efficiency,model,models,2433,"-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2447,energy efficiency,model,model,2447,"ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 &",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3361,energy efficiency,model,models,3361,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3375,energy efficiency,model,model,3375,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3720,energy efficiency,model,model,3720,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:20,interoperability,mismatch,mismatch,20,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:216,interoperability,platform,platform,216,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:1295,interoperability,platform,platform,1295,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2299,interoperability,mismatch,mismatch,2299,"/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2356,interoperability,mismatch,mismatch,2356,"gs_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:0,modifiability,PAC,PACBIO,0,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:65,modifiability,PAC,PACBIO,65,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:99,modifiability,PAC,PACBIO,99,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:817,modifiability,pac,pacbio,817,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:1199,modifiability,modul,module,1199,"nsorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:1268,modifiability,pac,packages,1268,"y is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2440,modifiability,pac,pacbio,2440,"eb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3368,modifiability,pac,pacbio,3368,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:130,performance,error,error,130,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:277,performance,optimiz,optimized,277,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:311,performance,Network,Network,311,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:357,performance,CPU,CPU,357,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:377,performance,perform,performance-critical,377,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2621,performance,time,time,2621,"/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2650,performance,parallel,parallel,2650,"70ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) >",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3345,reliability,checkpoint,checkpoint,3345,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:37,safety,test,tested,37,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:130,safety,error,error,130,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:651,safety,input,input,651,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:694,safety,input,input,694,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:863,safety,input,input,863,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:906,safety,input,input,906,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:1199,safety,modul,module,1199,"nsorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2553,safety,LOG,LOGDIR,2553,"app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2577,safety,log,logs,2577,"un. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2598,safety,LOG,LOGDIR,2598,"gs). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2686,safety,LOG,LOGDIR,2686,"b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2694,safety,log,log,2694,"15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2708,safety,LOG,LOGDIR,2708,"iant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3192,safety,log,log,3192,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3440,safety,log,log,3440,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3678,safety,log,log,3678,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3764,safety,input,input,3764,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:7,security,model,model,7,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:106,security,model,model,106,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:311,security,Network,Network,311,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:810,security,model,models,810,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:824,security,model,model,824,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2433,security,model,models,2433,"-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2447,security,model,model,2447,"ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 &",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2553,security,LOG,LOGDIR,2553,"app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2577,security,log,logs,2577,"un. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2598,security,LOG,LOGDIR,2598,"gs). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2686,security,LOG,LOGDIR,2686,"b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2694,security,log,log,2694,"15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2708,security,LOG,LOGDIR,2708,"iant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3192,security,log,log,3192,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3361,security,model,models,3361,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3375,security,model,model,3375,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3440,security,log,log,3440,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3678,security,log,log,3678,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3720,security,model,model,3720,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:37,testability,test,tested,37,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:952,testability,Trace,Traceback,952,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2553,testability,LOG,LOGDIR,2553,"app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2577,testability,log,logs,2577,"un. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2598,testability,LOG,LOGDIR,2598,"gs). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2686,testability,LOG,LOGDIR,2686,"b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2694,testability,log,log,2694,"15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2708,testability,LOG,LOGDIR,2708,"iant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3192,testability,log,log,3192,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3440,testability,log,log,3440,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3678,testability,log,log,3678,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:130,usability,error,error,130,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:377,usability,perform,performance-critical,377,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:651,usability,input,input,651,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:694,usability,input,input,694,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:863,usability,input,input,863,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:906,usability,input,input,906,"PACBIO model: Shape mismatch; Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```. 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10]. Traceback (most recent call last):. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2485,usability,command,command,2485,"b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postpro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3764,usability,input,input,3764,". sys.exit(main(argv)). File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants. raise ValueError(f'Shape mismatch in {example_info_json} and '. ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json. ```. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this? Thanks,. Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/629:512,deployability,pipelin,pipeline,512,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:512,integrability,pipelin,pipeline,512,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:141,performance,perform,performing,141,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:353,performance,time,time,353,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:372,reliability,doe,does,372,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:112,security,team,team,112,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:327,security,sign,significantly,327,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:367,security,team,team,367,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:141,usability,perform,performing,141,"VG-giraffe and indel realignment; I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news! -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/630:330,performance,perform,performs,330,"Strands support for each allele; Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus? In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,. Wenfei.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/630:8,usability,support,support,8,"Strands support for each allele; Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus? In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,. Wenfei.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/630:119,usability,support,supporting,119,"Strands support for each allele; Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus? In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,. Wenfei.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/630:245,usability,support,supported,245,"Strands support for each allele; Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus? In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,. Wenfei.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/630:330,usability,perform,performs,330,"Strands support for each allele; Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus? In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,. Wenfei.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/631:524,availability,operat,operations,524,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:590,availability,operat,operations,590,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1774,availability,operat,operations,1774,"iate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1840,availability,operat,operations,1840,"termediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2136,availability,operat,operations,2136,"iate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2202,availability,operat,operations,2202,"alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2498,availability,operat,operations,2498,"sc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2564,availability,operat,operations,2564,"616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2860,availability,operat,operations,2860,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2926,availability,operat,operations,2926,"424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3222,availability,operat,operations,3222,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3288,availability,operat,operations,3288,"128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3584,availability,operat,operations,3584,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3650,availability,operat,operations,3650,"384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3946,availability,operat,operations,3946,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4012,availability,operat,operations,4012,"502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4308,availability,operat,operations,4308,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4374,availability,operat,operations,4374,"454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4670,availability,operat,operations,4670,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4736,availability,operat,operations,4736,"042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5032,availability,operat,operations,5032,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5098,availability,operat,operations,5098,"699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5394,availability,operat,operations,5394,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5460,availability,operat,operations,5460,"518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5756,availability,operat,operations,5756,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5822,availability,operat,operations,5822,"775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6118,availability,operat,operations,6118,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6184,availability,operat,operations,6184,"846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6480,availability,operat,operations,6480,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6546,availability,operat,operations,6546,"371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6842,availability,operat,operations,6842,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6908,availability,operat,operations,6908,"427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7204,availability,operat,operations,7204,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7270,availability,operat,operations,7270,"219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7566,availability,operat,operations,7566,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7632,availability,operat,operations,7632,"431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7928,availability,operat,operations,7928,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7994,availability,operat,operations,7994,"198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8290,availability,operat,operations,8290,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8356,availability,operat,operations,8356,"949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8652,availability,operat,operations,8652,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8718,availability,operat,operations,8718,"141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9014,availability,operat,operations,9014,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9080,availability,operat,operations,9080,"575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9376,availability,operat,operations,9376,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9442,availability,operat,operations,9442,"862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9738,availability,operat,operations,9738,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9804,availability,operat,operations,9804,"554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10100,availability,operat,operations,10100,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10166,availability,operat,operations,10166,"879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10462,availability,operat,operations,10462,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10528,availability,operat,operations,10528,"700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10824,availability,operat,operations,10824,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10890,availability,operat,operations,10890,"882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12495,availability,operat,operations,12495,"78176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12561,availability,operat,operations,12561,"', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12857,availability,operat,operations,12857," input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Networ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12923,availability,operat,operations,12923,"ed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13219,availability,operat,operations,13219,"03_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13285,availability,operat,operations,13285,"017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13581,availability,operat,operations,13581,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13647,availability,operat,operations,13647,"837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13943,availability,operat,operations,13943,"rFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 14010242685",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:14009,availability,operat,operations,14009,"788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15353,availability,operat,operations,15353,"2: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15419,availability,operat,operations,15419,"an the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39569,availability,error,error,39569,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:17,deployability,fail,failed,17,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:274,deployability,fail,failed,274,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:286,deployability,log,log,286,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39490,deployability,fail,failed,39490,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:337,energy efficiency,core,core,337,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:403,energy efficiency,optim,optimized,403,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:483,energy efficiency,CPU,CPU,483,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1587,energy efficiency,core,core,1587," operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1653,energy efficiency,optim,optimized,1653,"I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1733,energy efficiency,CPU,CPU,1733,"rectory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1949,energy efficiency,core,core,1949,"t 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2015,energy efficiency,optim,optimized,2015,"-ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2095,energy efficiency,CPU,CPU,2095,"G003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2311,energy efficiency,core,core,2311,"artition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2377,energy efficiency,optim,optimized,2377,"tition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2457,energy efficiency,CPU,CPU,2457,"s --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2673,energy efficiency,core,core,2673,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2739,energy efficiency,optim,optimized,2739,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2819,energy efficiency,CPU,CPU,2819,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3035,energy efficiency,core,core,3035,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3101,energy efficiency,optim,optimized,3101,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3181,energy efficiency,CPU,CPU,3181,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3397,energy efficiency,core,core,3397,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3463,energy efficiency,optim,optimized,3463,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3543,energy efficiency,CPU,CPU,3543,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3759,energy efficiency,core,core,3759,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3825,energy efficiency,optim,optimized,3825,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3905,energy efficiency,CPU,CPU,3905,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4121,energy efficiency,core,core,4121,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4187,energy efficiency,optim,optimized,4187,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4267,energy efficiency,CPU,CPU,4267,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4483,energy efficiency,core,core,4483,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4549,energy efficiency,optim,optimized,4549,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4629,energy efficiency,CPU,CPU,4629,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4845,energy efficiency,core,core,4845,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4911,energy efficiency,optim,optimized,4911,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4991,energy efficiency,CPU,CPU,4991,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5207,energy efficiency,core,core,5207,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5273,energy efficiency,optim,optimized,5273,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5353,energy efficiency,CPU,CPU,5353,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5569,energy efficiency,core,core,5569,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5635,energy efficiency,optim,optimized,5635,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5715,energy efficiency,CPU,CPU,5715,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5931,energy efficiency,core,core,5931,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5997,energy efficiency,optim,optimized,5997,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6077,energy efficiency,CPU,CPU,6077,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6293,energy efficiency,core,core,6293,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6359,energy efficiency,optim,optimized,6359,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6439,energy efficiency,CPU,CPU,6439,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6655,energy efficiency,core,core,6655,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6721,energy efficiency,optim,optimized,6721,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6801,energy efficiency,CPU,CPU,6801,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7017,energy efficiency,core,core,7017,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7083,energy efficiency,optim,optimized,7083,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7163,energy efficiency,CPU,CPU,7163,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7379,energy efficiency,core,core,7379,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7445,energy efficiency,optim,optimized,7445,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7525,energy efficiency,CPU,CPU,7525,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7741,energy efficiency,core,core,7741,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7807,energy efficiency,optim,optimized,7807,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7887,energy efficiency,CPU,CPU,7887,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8103,energy efficiency,core,core,8103,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8169,energy efficiency,optim,optimized,8169,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8249,energy efficiency,CPU,CPU,8249,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8465,energy efficiency,core,core,8465,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8531,energy efficiency,optim,optimized,8531,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8611,energy efficiency,CPU,CPU,8611,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8827,energy efficiency,core,core,8827,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8893,energy efficiency,optim,optimized,8893,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8973,energy efficiency,CPU,CPU,8973,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9189,energy efficiency,core,core,9189,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9255,energy efficiency,optim,optimized,9255,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9335,energy efficiency,CPU,CPU,9335,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9551,energy efficiency,core,core,9551,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9617,energy efficiency,optim,optimized,9617,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9697,energy efficiency,CPU,CPU,9697,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9913,energy efficiency,core,core,9913,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9979,energy efficiency,optim,optimized,9979,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The ind",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10059,energy efficiency,CPU,CPU,10059,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10275,energy efficiency,core,core,10275,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10341,energy efficiency,optim,optimized,10341,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10421,energy efficiency,CPU,CPU,10421,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10637,energy efficiency,core,core,10637,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10703,energy efficiency,optim,optimized,10703,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I041",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10783,energy efficiency,CPU,CPU,10783,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Start",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12308,energy efficiency,core,core,12308,"e data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12374,energy efficiency,optim,optimized,12374,"1397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12454,energy efficiency,CPU,CPU,12454,"eSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12670,energy efficiency,core,core,12670,"', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12736,energy efficiency,optim,optimized,12736," make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12816,energy efficiency,CPU,CPU,12816,"am is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13032,energy efficiency,core,core,13032,"BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13098,energy efficiency,optim,optimized,13098,"han the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The ind",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13178,energy efficiency,CPU,CPU,13178,"97178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13394,energy efficiency,core,core,13394,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13460,energy efficiency,optim,optimized,13460,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13540,energy efficiency,CPU,CPU,13540,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13756,energy efficiency,core,core,13756,"Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13822,energy efficiency,optim,optimized,13822,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13902,energy efficiency,CPU,CPU,13902,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15166,energy efficiency,core,core,15166," I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15232,energy efficiency,optim,optimized,15232,"g HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I041",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15312,energy efficiency,CPU,CPU,15312,"81125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Start",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:72,integrability,pub,public,72,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:962,integrability,buffer,buffer,962,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:342,interoperability,platform,platform,342,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1592,interoperability,platform,platform,1592,"ions, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1954,interoperability,platform,platform,1954,"ine-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2316,interoperability,platform,platform,2316,"n ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2678,interoperability,platform,platform,2678,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3040,interoperability,platform,platform,3040,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3402,interoperability,platform,platform,3402,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3764,interoperability,platform,platform,3764,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4126,interoperability,platform,platform,4126,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4488,interoperability,platform,platform,4488,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4850,interoperability,platform,platform,4850,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5212,interoperability,platform,platform,5212,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5574,interoperability,platform,platform,5574,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5936,interoperability,platform,platform,5936,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6298,interoperability,platform,platform,6298,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6660,interoperability,platform,platform,6660,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7022,interoperability,platform,platform,7022,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7384,interoperability,platform,platform,7384,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7746,interoperability,platform,platform,7746,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8108,interoperability,platform,platform,8108,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8470,interoperability,platform,platform,8470,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8832,interoperability,platform,platform,8832,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9194,interoperability,platform,platform,9194,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9556,interoperability,platform,platform,9556,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9918,interoperability,platform,platform,9918,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10280,interoperability,platform,platform,10280,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10642,interoperability,platform,platform,10642,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12313,interoperability,platform,platform,12313,"file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12675,interoperability,platform,platform,12675,", '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13037,interoperability,platform,platform,13037,"IZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13399,interoperability,platform,platform,13399,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13761,interoperability,platform,platform,13761,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15171,interoperability,platform,platform,15171,"03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:0,modifiability,Pac,Pacbio,0,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:65,modifiability,pac,pacbio,65,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:747,modifiability,interm,intermediate,747,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:803,modifiability,Interm,Intermediate,803,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:11888,modifiability,deco,decode,11888,"perations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:16417,modifiability,deco,decode,16417,"perations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task 1/32: Overhead for prepar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39644,modifiability,PAC,PACBIO,39644,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:403,performance,optimiz,optimized,403,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:437,performance,Network,Network,437,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:483,performance,CPU,CPU,483,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:503,performance,perform,performance-critical,503,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:918,performance,time,time,918,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:934,performance,parallel,parallel,934,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1653,performance,optimiz,optimized,1653,"I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1687,performance,Network,Network,1687,"0304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1733,performance,CPU,CPU,1733,"rectory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1753,performance,perform,performance-critical,1753,"ults in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2015,performance,optimiz,optimized,2015,"-ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2049,performance,Network,Network,2049,"ata/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2095,performance,CPU,CPU,2095,"G003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2115,performance,perform,performance-critical,2115,"amples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2377,performance,optimiz,optimized,2377,"tition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2411,performance,Network,Network,2411," --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2457,performance,CPU,CPU,2457,"s --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2477,performance,perform,performance-critical,2477,"ck_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2739,performance,optimiz,optimized,2739,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2773,performance,Network,Network,2773,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2819,performance,CPU,CPU,2819,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2839,performance,perform,performance-critical,2839,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3101,performance,optimiz,optimized,3101,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3135,performance,Network,Network,3135,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3181,performance,CPU,CPU,3181,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3201,performance,perform,performance-critical,3201,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3463,performance,optimiz,optimized,3463,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3497,performance,Network,Network,3497,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3543,performance,CPU,CPU,3543,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3563,performance,perform,performance-critical,3563,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3825,performance,optimiz,optimized,3825,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3859,performance,Network,Network,3859,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3905,performance,CPU,CPU,3905,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3925,performance,perform,performance-critical,3925,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4187,performance,optimiz,optimized,4187,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4221,performance,Network,Network,4221,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4267,performance,CPU,CPU,4267,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4287,performance,perform,performance-critical,4287,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4549,performance,optimiz,optimized,4549,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4583,performance,Network,Network,4583,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4629,performance,CPU,CPU,4629,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4649,performance,perform,performance-critical,4649,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4911,performance,optimiz,optimized,4911,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4945,performance,Network,Network,4945,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4991,performance,CPU,CPU,4991,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5011,performance,perform,performance-critical,5011,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5273,performance,optimiz,optimized,5273,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5307,performance,Network,Network,5307,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5353,performance,CPU,CPU,5353,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5373,performance,perform,performance-critical,5373,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5635,performance,optimiz,optimized,5635,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5669,performance,Network,Network,5669,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5715,performance,CPU,CPU,5715,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5735,performance,perform,performance-critical,5735,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5997,performance,optimiz,optimized,5997,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6031,performance,Network,Network,6031,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6077,performance,CPU,CPU,6077,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6097,performance,perform,performance-critical,6097,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6359,performance,optimiz,optimized,6359,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6393,performance,Network,Network,6393,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6439,performance,CPU,CPU,6439,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6459,performance,perform,performance-critical,6459,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6721,performance,optimiz,optimized,6721,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6755,performance,Network,Network,6755,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6801,performance,CPU,CPU,6801,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6821,performance,perform,performance-critical,6821,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7083,performance,optimiz,optimized,7083,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7117,performance,Network,Network,7117,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7163,performance,CPU,CPU,7163,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7183,performance,perform,performance-critical,7183,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7445,performance,optimiz,optimized,7445,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7479,performance,Network,Network,7479,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7525,performance,CPU,CPU,7525,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7545,performance,perform,performance-critical,7545,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7807,performance,optimiz,optimized,7807,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7841,performance,Network,Network,7841,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7887,performance,CPU,CPU,7887,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7907,performance,perform,performance-critical,7907,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8169,performance,optimiz,optimized,8169,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8203,performance,Network,Network,8203,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8249,performance,CPU,CPU,8249,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8269,performance,perform,performance-critical,8269,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8531,performance,optimiz,optimized,8531,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8565,performance,Network,Network,8565,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8611,performance,CPU,CPU,8611,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8631,performance,perform,performance-critical,8631,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8893,performance,optimiz,optimized,8893,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8927,performance,Network,Network,8927,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8973,performance,CPU,CPU,8973,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8993,performance,perform,performance-critical,8993,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9255,performance,optimiz,optimized,9255,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9289,performance,Network,Network,9289,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9335,performance,CPU,CPU,9335,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9355,performance,perform,performance-critical,9355,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9617,performance,optimiz,optimized,9617,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9651,performance,Network,Network,9651,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9697,performance,CPU,CPU,9697,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9717,performance,perform,performance-critical,9717,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9979,performance,optimiz,optimized,9979,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The ind",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10013,performance,Network,Network,10013,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10059,performance,CPU,CPU,10059,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10079,performance,perform,performance-critical,10079,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10341,performance,optimiz,optimized,10341,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10375,performance,Network,Network,10375,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 14030",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10421,performance,CPU,CPU,10421,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10441,performance,perform,performance-critical,10441,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10703,performance,optimiz,optimized,10703,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I041",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10737,performance,Network,Network,10737,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10783,performance,CPU,CPU,10783,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Start",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10803,performance,perform,performance-critical,10803,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12374,performance,optimiz,optimized,12374,"1397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12408,performance,Network,Network,12408,"] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12454,performance,CPU,CPU,12454,"eSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12474,performance,perform,performance-critical,12474,"34488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12736,performance,optimiz,optimized,12736," make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12770,performance,Network,Network,12770,"0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12816,performance,CPU,CPU,12816,"am is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12836,performance,perform,performance-critical,12836,"u are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13098,performance,optimiz,optimized,13098,"han the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The ind",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13132,performance,Network,Network,13132,"RCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13178,performance,CPU,CPU,13178,"97178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13198,performance,perform,performance-critical,13198,"222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13460,performance,optimiz,optimized,13460,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13494,performance,Network,Network,13494,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 14013",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13540,performance,CPU,CPU,13540,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13560,performance,perform,performance-critical,13560,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13822,performance,optimiz,optimized,13822,"tions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13856,performance,Network,Network,13856,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13902,performance,CPU,CPU,13902,"able them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13922,performance,perform,performance-critical,13922,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.45",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15232,performance,optimiz,optimized,15232,"g HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I041",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15266,performance,Network,Network,15266,"tiveSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15312,performance,CPU,CPU,15312,"81125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Start",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15332,performance,perform,performance-critical,15332,"py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:17401,performance,Overhead,Overhead,17401,hat we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task 1/32: Overhead for preparing inputs: 0 seconds. 2023-04-13 03:58:45.052151: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150307_110540_42163R_c100797562550000001823175109091582_s1_p0/37128/0_19287: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.053598: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/91844/0_18528: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055002: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_051246_42177R_c100797732550000001823175109091551_s1_p0/147399/7609_36513: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055473: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_113145_42177R_c100797732550000001823175109091552_s1_p0/162383/0_18982: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.056350: W,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39569,performance,error,error,39569,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:17,reliability,fail,failed,17,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:274,reliability,fail,failed,274,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39490,reliability,fail,failed,39490,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12,safety,test,test,12,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:37,safety,test,tested,37,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:286,safety,log,log,286,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:11252,safety,input,inputs,11252,"00511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with Nativ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:11863,safety,input,input,11863,"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operation",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:14371,safety,input,inputs,14371,"98464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15117,safety,input,inputs,15117,"than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15781,safety,input,inputs,15781,"9', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with Nativ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:16392,safety,input,input,16392,"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:17424,safety,input,inputs,17424,M using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task 1/32: Overhead for preparing inputs: 0 seconds. 2023-04-13 03:58:45.052151: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150307_110540_42163R_c100797562550000001823175109091582_s1_p0/37128/0_19287: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.053598: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/91844/0_18528: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055002: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_051246_42177R_c100797732550000001823175109091551_s1_p0/147399/7609_36513: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055473: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_113145_42177R_c100797732550000001823175109091552_s1_p0/162383/0_18982: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.056350: W third_party/nucleus/i,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39569,safety,error,error,39569,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:286,security,log,log,286,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:437,security,Network,Network,437,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1687,security,Network,Network,1687,"0304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2049,security,Network,Network,2049,"ata/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2411,security,Network,Network,2411," --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2773,security,Network,Network,2773,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3135,security,Network,Network,3135,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3497,security,Network,Network,3497,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3859,security,Network,Network,3859,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4221,security,Network,Network,4221,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4583,security,Network,Network,4583,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4945,security,Network,Network,4945,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5307,security,Network,Network,5307,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5669,security,Network,Network,5669,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6031,security,Network,Network,6031,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6393,security,Network,Network,6393,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6755,security,Network,Network,6755,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7117,security,Network,Network,7117,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7479,security,Network,Network,7479,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7841,security,Network,Network,7841,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8203,security,Network,Network,8203,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8565,security,Network,Network,8565,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8927,security,Network,Network,8927,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9289,security,Network,Network,9289,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9651,security,Network,Network,9651,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10013,security,Network,Network,10013,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10375,security,Network,Network,10375,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 14030",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10737,security,Network,Network,10737,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12408,security,Network,Network,12408,"] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12770,security,Network,Network,12770,"0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13132,security,Network,Network,13132,"RCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13494,security,Network,Network,13494,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 14013",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13856,security,Network,Network,13856,"rations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15266,security,Network,Network,15266,"tiveSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12,testability,test,test,12,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:37,testability,test,tested,37,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:116,testability,trace,trace,116,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:286,testability,log,log,286,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:503,usability,perform,performance-critical,503,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:903,usability,command,command,903,"Pacbio data test failed; **hello,. I tested DeepVariant 1.5.0 on pacbio public data. The data link is:. https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam. But it failed. The log :** . 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This Tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1753,usability,perform,performance-critical,1753,"ults in intermediate_results_dir. ***** Intermediate results will be written to intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2115,usability,perform,performance-critical,2115,"amples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2477,usability,perform,performance-critical,2477,"ck_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. . 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2839,usability,perform,performance-critical,2839,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3201,usability,perform,performance-critical,3201,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3563,usability,perform,performance-critical,3563,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3925,usability,perform,performance-critical,3925,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4287,usability,perform,performance-critical,4287,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4649,usability,perform,performance-critical,4649,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5011,usability,perform,performance-critical,5011,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5373,usability,perform,performance-critical,5373,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5735,usability,perform,performance-critical,5735,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6097,usability,perform,performance-critical,6097,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6459,usability,perform,performance-critical,6459,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6821,usability,perform,performance-critical,6821,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7183,usability,perform,performance-critical,7183,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7545,usability,perform,performance-critical,7545,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7907,usability,perform,performance-critical,7907,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8269,usability,perform,performance-critical,8269,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8631,usability,perform,performance-critical,8631,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8993,usability,perform,performance-critical,8993,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9355,usability,perform,performance-critical,9355,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9717,usability,perform,performance-critical,9717,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10079,usability,perform,performance-critical,10079,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10441,usability,perform,performance-critical,10441,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10803,usability,perform,performance-critical,10803,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:11252,usability,input,inputs,11252,"00511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with Nativ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:11863,usability,input,input,11863,"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operation",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12474,usability,perform,performance-critical,12474,"34488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12836,usability,perform,performance-critical,12836,"u are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13198,usability,perform,performance-critical,13198,"222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13560,usability,perform,performance-critical,13560,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13922,usability,perform,performance-critical,13922,"s, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.45",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:14371,usability,input,inputs,14371,"98464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15117,usability,input,inputs,15117,"than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15332,usability,perform,performance-critical,15332,"py:257] Task 6/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15781,usability,input,inputs,15781,"9', '20', '21', '22', 'X', 'Y', 'MT']. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs. 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with Nativ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:16392,usability,input,input,16392,"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:17424,usability,input,inputs,17424,M using the reference you passed in with --ref. 2023-04-13 03:58:44.073860: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.208032 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai. I0413 03:58:44.372821 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader. I0413 03:58:44.385237 140193998387008 make_examples_core.py:257] Task 1/32: Writing gvcf records to intermediate_results_dir/gvcf.tfrecord-00001-of-00032.gz. I0413 03:58:44.415542 140193998387008 make_examples_core.py:257] Task 1/32: Writing examples to intermediate_results_dir/make_examples.tfrecord-00001-of-00032.gz. I0413 03:58:44.415678 140193998387008 make_examples_core.py:257] Task 1/32: Overhead for preparing inputs: 0 seconds. 2023-04-13 03:58:45.052151: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150307_110540_42163R_c100797562550000001823175109091582_s1_p0/37128/0_19287: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.053598: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/91844/0_18528: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055002: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_051246_42177R_c100797732550000001823175109091551_s1_p0/147399/7609_36513: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.055473: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150305_113145_42177R_c100797732550000001823175109091552_s1_p0/162383/0_18982: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.056350: W third_party/nucleus/i,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39569,usability,error,error,39569,60908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores. 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0). Fatal Python error: Aborted. cmd:. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref hs37d5.fasta \. --reads HG003_PacBio_GRCh37.bam \. --output_vcf HG003_PacBio.depv.vcf.gz \. --output_gvcf HG003_PacBio.depv.g.vcf.gz \. --num_shards 32 \. --intermediate_results_dir intermediate_results_dir. . What can i do to fix it? Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/632:33,availability,error,error,33,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:380,availability,Operat,Operating,380,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:681,availability,Error,Error,681,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:729,availability,Error,Error,729,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1243,availability,error,error,1243,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1260,availability,Error,Error,1260,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:438,deployability,version,version,438,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:469,deployability,Instal,Installation,469,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:462,energy efficiency,gpu,gpu,462,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1968,energy efficiency,optim,optimal,1968,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:438,integrability,version,version,438,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1082,interoperability,format,format,1082,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1304,interoperability,format,format,1304,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:438,modifiability,version,version,438,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:33,performance,error,error,33,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:462,performance,gpu,gpu,462,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:681,performance,Error,Error,681,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:729,performance,Error,Error,729,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1243,performance,error,error,1243,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1260,performance,Error,Error,1260,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1709,reliability,Doe,Does,1709,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:20,safety,Test,Test,20,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:33,safety,error,error,33,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:681,safety,Error,Error,681,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:729,safety,Error,Error,729,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:998,safety,input,input,998,"eepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional conte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1007,safety,input,input,1007,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1243,safety,error,error,1243,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1260,safety,Error,Error,1260,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1351,safety,input,input,1351,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1360,safety,input,input,1360,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1730,safety,test,test,1730,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1766,safety,test,test,1766,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:20,testability,Test,Test,20,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:560,testability,instrument,instrument,560,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:687,testability,trace,trace,687,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1730,testability,test,test,1730,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1766,testability,test,test,1766,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1996,testability,context,context,1996,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:25,usability,Command,Command,25,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:33,usability,error,error,33,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:669,usability,Command,Command,669,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:681,usability,Error,Error,681,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:729,usability,Error,Error,729,"DeepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:998,usability,input,input,998,"eepTrio Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional conte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1007,usability,input,input,1007,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1076,usability,tool,tools,1076,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1215,usability,command,command,1215,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1243,usability,error,error,1243,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1260,usability,Error,Error,1260,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1351,usability,input,input,1351,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1360,usability,input,input,1360,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1461,usability,tool,tools,1461,"o Quickstart Test Command error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**. - Operating system: Ubuntu 22.04, Docker 23+. - DeepVariant version: deeptrio-1.5.0-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. realtimegenomics/rtg-tools format \. -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta"". ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```. ```. sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/reference"":""/reference"" \. -v ""${PWD}/output"":""/output"" \. realtimegenomics/rtg-tools mendelian \. -i ""/output/HG002_trio_merged.vcf.gz"" \. -o ""/output/HG002_trio_annotated.output.vcf.gz"" \. --pedigree=/reference/trio.ped \. -t /reference/GRCh38_no_alt_analysis_set.sdf \. | tee output/deepvariant.input_rtg_output.txt. ``` . **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/633:1379,availability,down,downstream,1379,"s using deepvariant and merged these with GLnexus as recommended. However, there seems to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:. e.g. . `. 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1562,availability,down,downstream,1562,"y low or zero DP:. e.g. . `. 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, inde",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1708,availability,Operat,Operating,1708,":0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1732,availability,cluster,cluster,1732,",0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1997,availability,Error,Error,1997,":29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2013,availability,error,errors,2013,":1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:304,deployability,pipelin,pipeline,304,"Issues merging gVCFs with GLnexus; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yep. **Describe the issue:**. The issue is actually with GLnexus, however noone is replying there (people with same issues), and since it is recommended here in the deepvariant pipeline, I thought I would ask here. . I have produced a large set of gVCF files using deepvariant and merged these with GLnexus as recommended. However, there seems to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:. e.g. . `. 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Err",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1732,deployability,cluster,cluster,1732,",0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1755,deployability,version,version,1755,"0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1780,deployability,Instal,Installation,1780,"9,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3719,deployability,scale,scaled,3719,"true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unreprese",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4093,deployability,scale,scale,4093,", ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5339,deployability,scale,scaled,5339,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3719,energy efficiency,scale,scaled,3719,"true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unreprese",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3922,energy efficiency,Frequenc,Frequency,3922,"Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3932,energy efficiency,estimat,estimate,3932,"on=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about pre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4093,energy efficiency,scale,scale,4093,", ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5339,energy efficiency,scale,scaled,5339,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:304,integrability,pipelin,pipeline,304,"Issues merging gVCFs with GLnexus; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yep. **Describe the issue:**. The issue is actually with GLnexus, however noone is replying there (people with same issues), and since it is recommended here in the deepvariant pipeline, I thought I would ask here. . I have produced a large set of gVCF files using deepvariant and merged these with GLnexus as recommended. However, there seems to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:. e.g. . `. 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Err",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1466,integrability,filter,filter,1466,"s to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:. e.g. . `. 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1755,integrability,version,version,1755,"0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2075,integrability,FILTER,FILTER,2075,":1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2108,integrability,filter,filters,2108,",0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_var",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3005,integrability,filter,filtered,3005," no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Des",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4279,integrability,FILTER,FILTER,4279,"d\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5081,integrability,filter,filtered,5081,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2891,interoperability,FORMAT,FORMAT,2891,"and:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Typ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3171,interoperability,FORMAT,FORMAT,3171,"figName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genoty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3440,interoperability,FORMAT,FORMAT,3440,"yper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3663,interoperability,FORMAT,FORMAT,3663,"ef_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4453,interoperability,FORMAT,FORMAT,4453,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4515,interoperability,FORMAT,FORMAT,4515,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4968,interoperability,FORMAT,FORMAT,4968,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5096,interoperability,FORMAT,FORMAT,5096,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5213,interoperability,FORMAT,FORMAT,5213,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5284,interoperability,FORMAT,FORMAT,5284,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1755,modifiability,version,version,1755,"0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3719,modifiability,scal,scaled,3719,"true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unreprese",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4093,modifiability,scal,scale,4093,", ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5339,modifiability,scal,scaled,5339,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1997,performance,Error,Error,1997,":29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2013,performance,error,errors,2013,":1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:3719,performance,scale,scaled,3719,"true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unreprese",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4093,performance,scale,scale,4093,", ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:5339,performance,scale,scaled,5339,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1997,safety,Error,Error,1997,":29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2013,safety,error,errors,2013,":1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4647,safety,input,input,4647,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2003,testability,trace,trace,2003,"0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4699,testability,coverag,coverage,4699,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4917,testability,assert,assertion,4917,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1890,usability,Command,Command,1890,"0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FOR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1997,usability,Error,Error,1997,":29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2013,usability,error,errors,2013,":1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:2417,usability,prefer,preference,2417," like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. . So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you! **Setup**. - Operating system: linux/cluster. - DeepVariant version: latest (1.5). - Installation method: Docker. - Type of data: . Illumina WES data (.cram to .gvcf). **Steps to reproduce:**. - Command:. ```. glnexus_cli --config DeepVariant --bed ${regions} \. folder/*.g.vcf.gz > output.bcf. ```. - Error trace: no errors. This is the vcf header:. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##GLnexusVersion=v1.4.1-0-g68e25e5. ##GLnexusConfigName=DeepVariant. ##GLnexusConfigCRC32C=2932316105. ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4647,usability,input,input,4647,"on_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}. ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">. ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">. ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">. ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">. ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/634:890,availability,Error,Error,890,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1212,availability,operat,operations,1212,"/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1266,availability,operat,operations,1266,"e/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:0,deployability,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:24,deployability,modul,module,24,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1431,deployability,modul,module,1431,"ocker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1548,deployability,modul,module,1548,"eference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1684,deployability,modul,module,1684,"0-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1812,deployability,modul,module,1812,"esults_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1951,deployability,modul,module,1951,"nd any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2089,deployability,modul,module,2089,"ptimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2254,deployability,modul,module,2254,"in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2393,deployability,modul,module,2393,"/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2531,deployability,modul,module,2531," line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2706,deployability,modul,module,2706,". File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2868,deployability,modul,module,2868,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3024,deployability,modul,module,3024,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3221,deployability,modul,module,3221,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3432,deployability,modul,module,3432,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3627,deployability,modul,module,3627,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3747,deployability,modul,module,3747,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3772,deployability,Modul,ModuleNotFoundError,3772,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3796,deployability,modul,module,3796,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1025,energy efficiency,core,core,1025,"ule named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1091,energy efficiency,optim,optimized,1091,"e=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1171,energy efficiency,CPU,CPU,1171," INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1030,interoperability,platform,platform,1030,"ed 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2581,interoperability,distribut,distribute,2581,"File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/fai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2667,interoperability,distribut,distribute,2667,"ine 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ss",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2817,interoperability,distribut,distribute,2817,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2891,interoperability,rpc,rpc,2891,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2970,interoperability,distribut,distribute,2970,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2994,interoperability,rpc,rpc,2994,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3056,interoperability,distribut,distribute,3056,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3080,interoperability,rpc,rpc,3080,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3170,interoperability,distribut,distribute,3170,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3253,interoperability,distribut,distribute,3253,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3369,interoperability,distribut,distribute,3369,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3464,interoperability,distribut,distribute,3464,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3572,interoperability,distribut,distribute,3572,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:0,modifiability,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:24,modifiability,modul,module,24,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1431,modifiability,modul,module,1431,"ocker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1501,modifiability,pac,packages,1501,"_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1548,modifiability,modul,module,1548,"eference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1622,modifiability,pac,packages,1622,".novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1684,modifiability,modul,module,1684,"0-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1747,modifiability,pac,packages,1747,"-output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1812,modifiability,modul,module,1812,"esults_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1879,modifiability,pac,packages,1879,"1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1951,modifiability,modul,module,1951,"nd any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2014,modifiability,pac,packages,2014,"orflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2089,modifiability,modul,module,2089,"ptimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2189,modifiability,pac,packages,2189,"rformance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2254,modifiability,modul,module,2254,"in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2321,modifiability,pac,packages,2321,"r flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2393,modifiability,modul,module,2393,"/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2456,modifiability,pac,packages,2456," tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2531,modifiability,modul,module,2531," line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2629,modifiability,pac,packages,2629,"nsorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2706,modifiability,modul,module,2706,". File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2779,modifiability,pac,packages,2779,"1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2868,modifiability,modul,module,2868,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2932,modifiability,pac,packages,2932,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3024,modifiability,modul,module,3024,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3143,modifiability,pac,packages,3143,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3221,modifiability,modul,module,3221,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3342,modifiability,pac,packages,3342,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3432,modifiability,modul,module,3432,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3545,modifiability,pac,packages,3545,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3627,modifiability,modul,module,3627,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3702,modifiability,pac,packages,3702,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3747,modifiability,modul,module,3747,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3772,modifiability,Modul,ModuleNotFoundError,3772,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3796,modifiability,modul,module,3796,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:890,performance,Error,Error,890,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:915,performance,cach,cached,915,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1091,performance,optimiz,optimized,1091,"e=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1125,performance,Network,Network,1125,"et/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1171,performance,CPU,CPU,1171," INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1191,performance,perform,performance-critical,1191,"notation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:0,safety,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:24,safety,modul,module,24,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:249,safety,input,input,249,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:890,safety,Error,Error,890,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1431,safety,modul,module,1431,"ocker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1548,safety,modul,module,1548,"eference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1684,safety,modul,module,1684,"0-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1812,safety,modul,module,1812,"esults_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1951,safety,modul,module,1951,"nd any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2089,safety,modul,module,2089,"ptimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2254,safety,modul,module,2254,"in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2393,safety,modul,module,2393,"/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2531,safety,modul,module,2531," line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2706,safety,modul,module,2706,". File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:2868,safety,modul,module,2868,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3024,safety,modul,module,3024,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3221,safety,modul,module,3221,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3432,safety,modul,module,3432,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3627,safety,modul,module,3627,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3747,safety,modul,module,3747,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3772,safety,Modul,ModuleNotFoundError,3772,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:3796,safety,modul,module,3796,". from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py"", line 37, in <module>. from tensorflow._api.v2.compat.v2 import distribute. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/__init__.py"", line 182, in <module>. from . import experimental. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/__init__.py"", line 10, in <module>. from . import rpc. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/distribute/experimental/rpc/__init__.py"", line 8, in <module>. from tensorflow.python.distribute.experimental.rpc.rpc_ops import Client. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/experimental/__init__.py"", line 22, in <module>. from tensorflow.python.distribute.failure_handling import failure_handling. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/failure_handling.py"", line 34, in <module>. from tensorflow.python.distribute.failure_handling import gce_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/failure_handling/gce_util.py"", line 20, in <module>. import requests. File ""/home/data/ssy43/.local/lib/python3.8/site-packages/requests/__init__.py"", line 44, in <module>. import chardet. ModuleNotFoundError: No module named 'chardet'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1125,security,Network,Network,1125,"et/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:896,testability,trace,trace,896,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1334,testability,Trace,Traceback,1334," singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py"", line 33, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:50,usability,Command,Command,50,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:249,usability,input,input,249,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:890,usability,Error,Error,890,"ModuleNotFoundError: No module named 'chardet'; - Command:#docker. BIN_VERSION=""1.5.0"". reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference. INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1191,usability,perform,performance-critical,1191,"notation_Geneset/11.variant_calling/deepvariant/input. OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir. singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \. --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. . - Error trace: INFO: Using cached SIF image. WARNING: Could not find any nv files on this host! 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>. from ._api.v2 import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>. from . import v1. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>. from . import compat. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>. from . import v2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>. from tensorflow._api.v2.compat.v2 import __internal__. File ""/usr/local/lib/python3.8/dist-packages/ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/635:322,energy efficiency,model,model,322,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:222,modifiability,paramet,parameter,222,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:306,reliability,Doe,Does,306,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:56,safety,test,testing,56,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:171,safety,input,input,171,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:322,security,model,model,322,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:56,testability,test,testing,56,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/635:171,usability,input,input,171,"Some questions about RNAseq data analysis; hello,. I am testing RNA-seq data with deepvarian1.4. . I have some questions about：. 1. Is GATK SplitNCigarReads necessary for input bam? 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose? 3. Does the RNAseq model only apply to the CDS region? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/636:690,availability,error,error,690,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:760,availability,checkpoint,checkpoint,760,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:794,availability,restor,restore,794,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:900,availability,restor,restore,900,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:997,availability,checkpoint,checkpoints,997,"ing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1130,availability,checkpoint,checkpoint,1130,"ase of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2094,availability,checkpoint,checkpoint,2094,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2105,availability,checkpoint,checkpoint,2105,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2234,availability,restor,restored,2234,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2371,availability,checkpoint,checkpoint,2371,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:131,deployability,releas,release,131,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:219,deployability,modul,module,219,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:626,deployability,modul,module,626,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:637,deployability,fail,failed,637,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:802,deployability,API,API,802,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:959,deployability,build,building,959,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1310,deployability,modul,module,1310,"_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1825,energy efficiency,model,model,1825,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:696,integrability,messag,message,696,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:802,integrability,API,API,802,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1093,integrability,messag,message,1093,"keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/che",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:696,interoperability,messag,message,696,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:802,interoperability,API,API,802,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1029,interoperability,format,format,1029,"eepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1093,interoperability,messag,message,1093,"keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/che",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:219,modifiability,modul,module,219,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:626,modifiability,modul,module,626,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:844,modifiability,variab,variables,844,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1310,modifiability,modul,module,1310,"_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1915,modifiability,pac,packages,1915,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2067,modifiability,pac,packages,2067,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2249,modifiability,Variab,Variable,2249,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:690,performance,error,error,690,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:930,performance,time,time,930,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:637,reliability,fail,failed,637,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:760,reliability,checkpoint,checkpoint,760,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:794,reliability,restor,restore,794,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:900,reliability,restor,restore,900,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:997,reliability,checkpoint,checkpoints,997,"ing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1130,reliability,checkpoint,checkpoint,1130,"ase of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2094,reliability,checkpoint,checkpoint,2094,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2105,reliability,checkpoint,checkpoint,2105,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2234,reliability,restor,restored,2234,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2371,reliability,checkpoint,checkpoint,2371,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:219,safety,modul,module,219,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:626,safety,modul,module,626,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:690,safety,error,error,690,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1310,safety,modul,module,1310,"_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1825,security,model,model,1825,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1156,testability,Trace,Traceback,1156,"ed some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise Ass",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2158,testability,Assert,AssertionError,2158,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2175,testability,Assert,AssertionError,2175,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:250,usability,command,command,250,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:582,usability,command,command,582,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:690,usability,error,error,690,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:969,usability,Prefer,Prefer,969,"Facing issues while using ""run_deepvariant_keras.py"" ; Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `. python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10. `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2455,usability,help,help,2455,"e above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_. _run_main(main, args). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main. call_variants(. File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored:. <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------. Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_. Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_? Thanks,. Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/639:373,availability,Operat,Operating,373,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:412,deployability,version,version,412,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:428,deployability,Instal,Installation,428,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:412,integrability,version,version,412,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:2485,integrability,filter,filterting,2485,"_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,990,990,990. 1	69848	.	G	<*>	0	.	END=69920	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	C,<*>	0.7	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:8:6:2,4,0:0.666667,0:0,8,13,990,990,990. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69897	.	T	C,<*>	14.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:2:0,2,0:1,0:13,11,0,990,990,990. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. ```. Seems as long as GQ is >0 there is a call? That seems very low. I do not want to start manually filterting sites as this defeats the purpose of using DeepVariant, but some clarification would be much appreciated. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:412,modifiability,version,version,412,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:4,reliability,doe,does,4,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:179,testability,understand,understand,179,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:555,usability,Command,Command,555,"How does DeepVariant decide on Call or No-Call?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**. - Operating system: Linux. - DeepVariant version: 1.5. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES Data (Illumina). **Steps to reproduce:**. - Command:. - . DeepVariant:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. ```. GLNexus:. ```. glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf. bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz. bcftools index Exomes.vcf.gz. ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):. ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0. 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29. 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0. 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/640:334,availability,ERROR,ERROR,334,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:662,availability,Operat,Operating,662,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1608,availability,Error,Error,1608,"cations on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2174,availability,operat,operations,2174,"arity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,01",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2228,availability,operat,operations,2228,"R}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3425,availability,operat,operations,3425,"furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3479,availability,operat,operations,3479,"/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:14,deployability,modul,module,14,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:38,deployability,API,API,38,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:42,deployability,version,version,42,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:64,deployability,version,version,64,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:311,deployability,CONTAIN,CONTAINER,311,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:355,deployability,modul,module,355,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:379,deployability,API,API,379,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:383,deployability,version,version,383,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:405,deployability,version,version,405,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:451,deployability,API,API,451,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:583,deployability,api,api-incompatibility,583,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:717,deployability,version,version,717,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:735,deployability,Instal,Installation,735,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5135,deployability,modul,module,5135,", note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5159,deployability,API,API,5159,"ode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5163,deployability,version,version,5163,"AM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5185,deployability,version,version,5185," you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5231,deployability,API,API,5231,"09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5363,deployability,api,api-incompatibility,5363,"cs_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5649,deployability,modul,module,5649,"] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2189, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8107,deployability,fail,failed,8107,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8144,deployability,fail,failed,8144,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1987,energy efficiency,core,core,1987,"g special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2053,energy efficiency,optim,optimized,2053,"*Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2133,energy efficiency,CPU,CPU,2133,"UTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3238,energy efficiency,core,core,3238,"rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.4270",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3304,energy efficiency,optim,optimized,3304,"6.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3384,energy efficiency,CPU,CPU,3384,"ntermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8091,energy efficiency,core,core,8091,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:38,integrability,API,API,38,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:42,integrability,version,version,42,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:64,integrability,version,version,64,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:379,integrability,API,API,379,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:383,integrability,version,version,383,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:405,integrability,version,version,405,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:451,integrability,API,API,451,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:583,integrability,api,api-incompatibility,583,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:717,integrability,version,version,717,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1936,integrability,Messag,Message,1936,"(sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2725,integrability,buffer,buffer,2725,"hub.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5159,integrability,API,API,5159,"ode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5163,integrability,version,version,5163,"AM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5185,integrability,version,version,5185," you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5231,integrability,API,API,5231,"09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5363,integrability,api,api-incompatibility,5363,"cs_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:38,interoperability,API,API,38,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:379,interoperability,API,API,379,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:451,interoperability,API,API,451,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:455,interoperability,incompatib,incompatibility,455,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:583,interoperability,api,api-incompatibility,583,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1192,interoperability,bind,bind,1192,"e the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1936,interoperability,Messag,Message,1936,"(sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1992,interoperability,platform,platform,1992,"al that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3243,interoperability,platform,platform,3243," TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5159,interoperability,API,API,5159,"ode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5231,interoperability,API,API,5231,"09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5235,interoperability,incompatib,incompatibility,5235," I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5363,interoperability,api,api-incompatibility,5363,"cs_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:14,modifiability,modul,module,14,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:42,modifiability,version,version,42,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:64,modifiability,version,version,64,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:355,modifiability,modul,module,355,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:383,modifiability,version,version,383,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:405,modifiability,version,version,405,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:717,modifiability,version,version,717,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1192,modifiability,bind,bind,1192,"e the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2385,modifiability,interm,intermediate,2385,"-ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU ins",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2504,modifiability,Interm,Intermediate,2504,"000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4158,modifiability,deco,decode,4158,"0:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against AP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5135,modifiability,modul,module,5135,", note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5163,modifiability,version,version,5163,"AM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5185,modifiability,version,version,5185," you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5649,modifiability,modul,module,5649,"] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2189, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:334,performance,ERROR,ERROR,334,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1608,performance,Error,Error,1608,"cations on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2053,performance,optimiz,optimized,2053,"*Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2087,performance,Network,Network,2087,":. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2133,performance,CPU,CPU,2133,"UTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2153,performance,perform,performance-critical,2153,"-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2682,performance,time,time,2682,"your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2697,performance,parallel,parallel,2697,"lease test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3304,performance,optimiz,optimized,3304,"6.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3338,performance,Network,Network,3338,"variant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3384,performance,CPU,CPU,3384,"ntermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3404,performance,perform,performance-critical,3404,"cratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5079,performance,Overhead,Overhead,5079,"or_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/23",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8125,performance,parallel,parallel,8125,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1650,reliability,Doe,Does,1650,"etup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8107,reliability,fail,failed,8107,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8144,reliability,fail,failed,8144,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:14,safety,modul,module,14,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:334,safety,ERROR,ERROR,334,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:355,safety,modul,module,355,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1123,safety,test,testdata,1123,"thub.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the foll",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1214,safety,input,input,1214,"r and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1397,safety,input,input,1397,"this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1446,safety,input,input,1446,"C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1608,safety,Error,Error,1608,"cations on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1671,safety,test,test,1671,"ystem: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the comman",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1707,safety,test,test,1707,"Variant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2790,safety,input,input,2790,"t.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 14004032014",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2838,safety,input,input,2838," using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3618,safety,input,input,3618,"mpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 1400403201",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3752,safety,input,inputs,3752,"ke_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3831,safety,input,input,3831,"s ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 1400403201452",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4133,safety,input,input,4133,"ord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4400,safety,input,input,4400," performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4530,safety,input,input,4530,"mpiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5102,safety,input,inputs,5102,"true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_mer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5135,safety,modul,module,5135,", note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5649,safety,modul,module,5649,"] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2189, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8210,safety,input,input,8210,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8256,safety,input,input,8256,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2087,security,Network,Network,2087,":. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3338,security,Network,Network,3338,"variant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:952,testability,instrument,instrument,952,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1123,testability,test,testdata,1123,"thub.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the foll",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1419,testability,unit,unittest,1419,"s 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1614,testability,trace,trace,1614,"s on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1671,testability,test,test,1671,"ystem: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the comman",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1707,testability,test,test,1707,"Variant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1924,testability,context,context,1924,"pe of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2812,testability,unit,unittest,2812,"to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5430,testability,Trace,Traceback,5430,"m with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8232,testability,unit,unittest,8232,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:213,usability,clear,clear,213,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:334,usability,ERROR,ERROR,334,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:543,usability,user,user,543,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:607,usability,indicat,indications,607,"RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1084,usability,Command,Command,1084," **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**. (A clear and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1214,usability,input,input,1214,"r and concise description of what the issue is.). CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1397,usability,input,input,1397,"this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1446,usability,input,input,1446,"C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1608,usability,Error,Error,1608,"cations on how to solve this problem. **Setup**. - Operating system: Ubuntu 18.04 (bionic). - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:. BIN_VERSION=""1.5.0"". singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). EXAMPLE DATA PROVIDED. **Steps to reproduce:**. - Command:. INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2153,usability,perform,performance-critical,2153,"-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \. /fh/fast/furlan_s/grp/sifs/deepvariant.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2667,usability,command,command,2667,"test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamRe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2790,usability,input,input,2790,"t.md. Is there any way to reproduce the issue by using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 14004032014",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2838,usability,input,input,2838," using the quick start? YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3404,usability,perform,performance-critical,3404,"cratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3618,usability,input,input,3618,"mpzz53zv8p in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 1400403201",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3752,usability,input,inputs,3752,"ke_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3831,usability,input,input,3831,"s ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 1400403201452",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4133,usability,input,input,4133,"ord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4400,usability,input,input,4400," performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:4530,usability,input,input,4530,"mpiler flags. I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs. I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']. I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5102,usability,input,inputs,5102,"true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_mer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5323,usability,user,user,5323,"28. I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:5387,usability,indicat,indications,5387,"ading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.665297 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0502 14:42:09.668077 140040320145216 make_examples_core.py:257] Writing gvcf records to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord-00000-of-00001.gz. I0502 14:42:10.668800 140040320145216 make_examples_core.py:257] Writing examples to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord-00000-of-00001.gz. I0502 14:42:10.669139 140040320145216 make_examples_core.py:257] Overhead for preparing inputs: 1 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main. make_examples_core.make_examples_runner(options). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8210,usability,input,input,8210,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8256,usability,input,input,8256,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:8621,usability,user,user,8621,"4e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1187, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1793, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample)). File ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/Bazel.runfiles_24e7ffgp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample. rows = ([self._encoder.encode_reference(refbases)] *. ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz --channels insert_size --gvcf /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real	1m18.483s. user	0m6.533s. sys	0m5.261s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/641:166,availability,down,download,166,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:978,deployability,pipelin,pipeline,978,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:223,integrability,sub,submissions,223,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:458,integrability,Filter,Filter,458,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:978,integrability,pipelin,pipeline,978,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:61,modifiability,Pac,PacBio,61,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:138,modifiability,Pac,Pacbio,138,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:1020,modifiability,paramet,parameters,1020,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:1133,modifiability,PAC,PACBIO,1133,"Benchmark with low precision and recall on indels with HG002 PacBio Revio data; I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score. INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211. SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/642:7,integrability,filter,filter,7,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:233,integrability,filter,filtering,233,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:308,integrability,sub,subsequent,308,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:371,integrability,filter,filter,371,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:421,integrability,filter,filtering,421,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:451,integrability,filter,filter,451,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:473,integrability,filter,filter-name,473,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:492,integrability,filter,filter,492,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:512,integrability,filter,filter-name,512,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:531,integrability,filter,filter,531,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:553,integrability,filter,filter-name,553,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:572,integrability,filter,filter,572,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:593,integrability,filter,filter-name,593,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:612,integrability,filter,filter,612,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:635,integrability,filter,filter-name,635,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:656,integrability,filter,filter,656,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:676,integrability,filter,filter-name,676,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:243,modifiability,paramet,parameters,243,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:431,modifiability,paramet,parameters,431,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/642:354,usability,tool,tools,354,"How to filter a merged gvcf file ; Hello:. I have a population with 35 indivuals , and called gvcf for each individual by the DeepVariant ,and then, combined all individual gvcfs file using the GLnexus. Although there are some basic filtering parameters when combining by the GLnexus, but they can't meet my subsequent analysis. so if there some ways or tools to further filter the combined gvcf (which are equivalent to filtering parameters with "" --filter ""QUAL <50.0"" --filter-name LowQ --filter ""DP <200 "" --filter-name LowD --filter ""DP> 10000 "" --filter-name HigD --filter "" MQ<40.0 "" --filter-name SedT --filter ""SOR > 50.0 "" --filter-name LowSOR --filter ""AN <150 "" --filter-name LowMiss"" by GATK software).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/642
https://github.com/google/deepvariant/issues/643:97,deployability,version,version,97,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:481,deployability,scale,scales,481,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:791,deployability,scale,scales,791,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:481,energy efficiency,scale,scales,481,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:791,energy efficiency,scale,scales,791,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:97,integrability,version,version,97,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:521,interoperability,distribut,distribution,521,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:97,modifiability,version,version,97,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:481,modifiability,scal,scales,481,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:791,modifiability,scal,scales,791,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:481,performance,scale,scales,481,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:791,performance,scale,scales,791,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:252,usability,Statu,Status,252,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/643:645,usability,user,user-images,645,"weird character for minus values in plot axis of the visual_report.html; using the latest docker version 1.5.0 on ubuntu 22. ```. latest: Pulling from google/deepvariant. Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e. Status: Image is up to date for google/deepvariant:latest. docker.io/google/deepvariant:latest. ```. When I open the final report html page, I get weird ```â^'``` characters where I would expect a minus '-' symbol for the x-axis scales of the bottom two biallelic size distribution plots. All other plots lack negative values and are not affected. ![Screenshot 2023-05-04 at 17 13 33](https://user-images.githubusercontent.com/858516/236251296-d4169c1a-f3e1-4472-982b-893914b66747.png). Is this something that can be fixed to get prettier scales? Thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/643
https://github.com/google/deepvariant/issues/644:39,usability,visual,visualize,39,"Visulaize pileup image; Hello,. How to visualize the pile up image created in the make examples step? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/644
https://github.com/google/deepvariant/issues/645:177,availability,Down,Downstream,177,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:370,availability,Operat,Operating,370,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1226,availability,down,downstream,1226,"ber of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:3:3,0:0:20,0,50:II	0/0:4:4,0:12:0,12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6765,availability,sli,slightly,6765,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:409,deployability,version,version,409,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:428,deployability,Instal,Installation,428,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6714,deployability,Configurat,Configuration,6714,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:0,integrability,Filter,Filtering,0,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:341,integrability,filter,filtered,341,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:409,integrability,version,version,409,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1112,integrability,filter,filtering,1112,"iant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1406,integrability,filter,filtered,1406,"ersion: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:3:3,0:0:20,0,50:II	0/0:4:4,0:12:0,12,119:..	0/0:25:25,0:48:0,75,749:..	1/1:8:1,7:17:39,19,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:9:0,9:33:38,35,0:..	./.:2:2,0:0:23,0,23:II	1/1:2:0,2:28:37,30,0:..	0/0:20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1585,integrability,filter,filtering,1585,"studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:3:3,0:0:20,0,50:II	0/0:4:4,0:12:0,12,119:..	0/0:25:25,0:48:0,75,749:..	1/1:8:1,7:17:39,19,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:9:0,9:33:38,35,0:..	./.:2:2,0:0:23,0,23:II	1/1:2:0,2:28:37,30,0:..	0/0:20:20,0:50:0,99,989:..	./.:2:2,0:0:23,0,23:II	./.:2:2,0:0:23,0,23:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:3:0,3:37:39,40,0:..	1/1:5:0,5:31:34,33,0:..	./.:5:5,0:0:14,0,104:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6643,integrability,filter,filters,6643,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6714,integrability,Configur,Configuration,6714,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:409,modifiability,version,version,409,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6714,modifiability,Configur,Configuration,6714,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6765,reliability,sli,slightly,6765,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6838,safety,input,input,6838,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1165,security,ident,identified,1165,"ue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1178,security,sign,significant,1178,"eam association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6714,security,Configur,Configuration,6714,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:519,testability,instrument,instrument,519,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:997,testability,context,context,997,"iltering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:3713,testability,coverag,coverage,3713,"5:33,27,0:..	0/0:20:20,0:50:0,204,2039:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:26:34,28,0:..	0/0:0:0,0:1:0,0,0:..	0/1:56:46,10:26:26,0,32:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	0/0:16:16,0:48:0,144,1439:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	./.:6:6,0:0:11,0,131:II	1/1:5:0,5:32:36,34,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:8:1,7:21:36,23,0:..	1/1:5:0,5:32:37,34,0:..	1/1:9:0,9:36:39,38,0:..	./.:1:1,0:0:29,3,0:II	./.:3:3,0:0:20,0,50:II	1/1:5:0,5:30:38,32,0:..	./.:11:9,2:3:0,2,5:II	0/0:23:23,0:50:0,189,1889:..	./.:3:3,0:0:20,0,50:II	./.:3:3,0:0:20,0,50:II	0/1:8:3,5:11:29,0,10:..	0/0:33:33,0:48:0,117,1169:..	1/1:9:0,9:37:39,41,0:..	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:29:32,31,0:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	0/1:9:2,7:4:15,0,1:..	./.:7:7,0:0:8,0,158:II	1/1:5:0,5:37:39,41,0:..	0/1:32:22,10:15:25,0,14:..	1/1:3:0,3:35:38,37,0:..	0/0:0:0,0:1:0,0,0:..`. There are many ./. and 0/0 with low coverage / confidence, where DV thinks this is a ref. The actual alt-AF of this site should be closer to 0.80. Here is another:. `. 1	19626624	1_19626624_G_T	G	T	52	.	AF=0.021795;AQ=52	GT:DP:AD:GQ:PL:RNC	0/1:3:0,3:2:24,4,0:..	0/1:3:0,3:2:23,4,0:..	1/1:4:0,4:2:28,8,0:..	1/1:5:0,5:5:34,11,0:..	0/1:2:0,2:2:19,4,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:2:30,8,0:..	0/1:3:0,3:1:20,5,0:..	0/1:2:0,2:3:22,3,0:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:28,6,0:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:28,8,0:..	0/1:2:0,2:0:17,6,0:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:3:14,3,0:..	0/1:3:0,3:0:27,6,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	./.:4:4,0:0:17,0,77:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:26,6,0:..	0/1:7:4,3:27:27,0,45:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:2:20,4,0:..	0/1:2:0,2:3:19,3,0:..	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:3:30,9,0:..	0/1:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:5192,testability,coverag,coverage,5192,",3,0:..	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:28,8,0:..	0/1:2:0,2:0:17,6,0:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:3:14,3,0:..	0/1:3:0,3:0:27,6,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	./.:4:4,0:0:17,0,77:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:26,6,0:..	0/1:7:4,3:27:27,0,45:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:2:20,4,0:..	0/1:2:0,2:3:19,3,0:..	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:3:30,9,0:..	0/1:3:0,3:0:22,6,0:..	1/1:4:0,4:1:32,7,0:..	0/0:2:2,0:6:0,9,89:..	0/1:2:0,2:2:21,4,0:..	0/1:2:0,2:2:19,4,0:..	0/1:2:0,2:2:20,4,0:..	0/1:3:0,3:1:25,5,0:..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,158",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:5292,testability,coverag,coverage,5292,"1:1,0:0:29,3,0:II	0/1:2:0,2:3:14,3,0:..	0/1:3:0,3:0:27,6,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	./.:4:4,0:0:17,0,77:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:26,6,0:..	0/1:7:4,3:27:27,0,45:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:2:20,4,0:..	0/1:2:0,2:3:19,3,0:..	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:3:30,9,0:..	0/1:3:0,3:0:22,6,0:..	1/1:4:0,4:1:32,7,0:..	0/0:2:2,0:6:0,9,89:..	0/1:2:0,2:2:21,4,0:..	0/1:2:0,2:2:19,4,0:..	0/1:2:0,2:2:20,4,0:..	0/1:3:0,3:1:25,5,0:..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6541,testability,understand,understand,6541,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:10,usability,clear,clear,10,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:642,usability,Command,Command,642,"Filtering clear false positives / low-confidence sites; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1090,usability,help,help,1090,"github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**. Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**. - Operating system: Linux. - DeepVariant version: Latest. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**. - Command: . DeepVariant:. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${cram_in} \. --regions ${regions} \. --output_gvcf ${sample}.g.vcf.gz \. --output_vcf ${sample}.vcf.gz \. --num_shards 8 \. GLnexus:. glnexus_cli --config DeepVariantWES --bed ${regions} \. 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there! Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file. Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:3808,usability,close,closer,3808,",0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:26:34,28,0:..	0/0:0:0,0:1:0,0,0:..	0/1:56:46,10:26:26,0,32:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	0/0:16:16,0:48:0,144,1439:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	./.:6:6,0:0:11,0,131:II	1/1:5:0,5:32:36,34,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:8:1,7:21:36,23,0:..	1/1:5:0,5:32:37,34,0:..	1/1:9:0,9:36:39,38,0:..	./.:1:1,0:0:29,3,0:II	./.:3:3,0:0:20,0,50:II	1/1:5:0,5:30:38,32,0:..	./.:11:9,2:3:0,2,5:II	0/0:23:23,0:50:0,189,1889:..	./.:3:3,0:0:20,0,50:II	./.:3:3,0:0:20,0,50:II	0/1:8:3,5:11:29,0,10:..	0/0:33:33,0:48:0,117,1169:..	1/1:9:0,9:37:39,41,0:..	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:29:32,31,0:..	./.:1:1,0:0:29,3,0:II	./.:2:2,0:0:23,0,23:II	0/1:9:2,7:4:15,0,1:..	./.:7:7,0:0:8,0,158:II	1/1:5:0,5:37:39,41,0:..	0/1:32:22,10:15:25,0,14:..	1/1:3:0,3:35:38,37,0:..	0/0:0:0,0:1:0,0,0:..`. There are many ./. and 0/0 with low coverage / confidence, where DV thinks this is a ref. The actual alt-AF of this site should be closer to 0.80. Here is another:. `. 1	19626624	1_19626624_G_T	G	T	52	.	AF=0.021795;AQ=52	GT:DP:AD:GQ:PL:RNC	0/1:3:0,3:2:24,4,0:..	0/1:3:0,3:2:23,4,0:..	1/1:4:0,4:2:28,8,0:..	1/1:5:0,5:5:34,11,0:..	0/1:2:0,2:2:19,4,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:2:30,8,0:..	0/1:3:0,3:1:20,5,0:..	0/1:2:0,2:3:22,3,0:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:28,6,0:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:28,8,0:..	0/1:2:0,2:0:17,6,0:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:3:14,3,0:..	0/1:3:0,3:0:27,6,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	./.:4:4,0:0:17,0,77:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,3,29:..	0/1:3:0,3:0:26,6,0:..	0/1:7:4,3:27:27,0,45:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:2:20,4,0:..	0/1:2:0,2:3:19,3,0:..	0/0:0:0,0:1:0,3,29:..	1/1:4:0,4:3:30,9,0:..	0/1:3:0,3:0:22,6,0:..	1/1:4:0,4:1:32,7,0:..	0/0:2:2,0:6:0,9,89:..	0/1:2:0,2:2:21,4,0:..	0/1:2:0,2:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6622,usability,command,command,6622,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6838,usability,input,input,6838,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/646:18,availability,Error,Error,18,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:173,availability,error,error,173,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:204,availability,Operat,Operating,204,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1340,availability,Error,Error,1340,"- Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1384,availability,error,error,1384,"rence genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1395,availability,error,error,1395,"e, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4823,availability,error,error,4823,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:247,deployability,version,version,247,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:274,deployability,Instal,Installation,274,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3417,deployability,modul,module,3417,"com_google_deepvariant/deepvariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3445,deployability,fail,failed,3445,"ariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcess",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3948,deployability,modul,module,3948,"arity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4773,deployability,Fail,Failed,4773,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1402,energy efficiency,Current,Current,1402,"ing special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfj",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:247,integrability,version,version,247,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4250,integrability,sub,subprocess,4250,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4343,integrability,sub,subprocess,4343,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4424,integrability,sub,subprocess,4424,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4507,integrability,buffer,buffer,4507,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:247,modifiability,version,version,247,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3417,modifiability,modul,module,3417,"com_google_deepvariant/deepvariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3948,modifiability,modul,module,3948,"arity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4008,modifiability,pac,packages,4008,"jmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4108,modifiability,pac,packages,4108,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:18,performance,Error,Error,18,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:173,performance,error,error,173,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1340,performance,Error,Error,1340,"- Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1384,performance,error,error,1384,"rence genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1395,performance,error,error,1395,"e, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3426,performance,parallel,parallel,3426,"_deepvariant/deepvariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subpro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4464,performance,time,time,4464,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4479,performance,parallel,parallel,4479,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4823,performance,error,error,4823,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3445,reliability,fail,failed,3445,"ariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcess",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4773,reliability,Fail,Failed,4773,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4835,reliability,Doe,Does,4835,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:18,safety,Error,Error,18,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:173,safety,error,error,173,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1340,safety,Error,Error,1340,"- Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1384,safety,error,error,1384,"rence genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1395,safety,error,error,1395,"e, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3417,safety,modul,module,3417,"com_google_deepvariant/deepvariant/make_examples_core.py"", line 1145 in process. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3948,safety,modul,module,3948,"arity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4823,safety,error,error,4823,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4856,safety,test,test,4856,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4892,safety,test,test,4892,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:371,testability,instrument,instrument,371,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1346,testability,trace,trace,1346," of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3844,testability,Trace,Traceback,3844,"eepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4856,testability,test,test,4856,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4892,testability,test,test,4892,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:5067,testability,context,context,5067,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:18,usability,Error,Error,18,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:173,usability,error,error,173,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:528,usability,Command,Command,528,"Fatal: python Bus Error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. Yes. **Describe the issue:**. Run into Fatal python Bus error repeatedly. **Setup**. - Operating system: CentOS 7 . - DeepVariant version: 1.4 (DeepTrio). - Installation method (Docker, built from source, etc.): singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1340,usability,Error,Error,1340,"- Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1384,usability,error,error,1384,"rence genome, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1395,usability,error,error,1395,"e, anything special that is unlike the case studies?). Illumina NovaSeq data, reference genome hg19. . **Steps to reproduce:**. - Command:. - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. - Error trace: (if applicable). `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:3747,usability,user,user,3747,"t_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 302 in main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4272,usability,command,command,4272,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4455,usability,Command,Command,4455,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4823,usability,error,error,4823,"/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>. parallel: This job failed:. /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s. user 287m31.460s. sys 2m20.121s. I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_. Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error. `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/647:231,modifiability,paramet,parameter,231,"The question about the analysis of WES data; hello,. When analyzing WES data, I want to force the output of some sites to ensure that they appear in the vcf file. Does deepvariant1.4 have a function similar to the sentieon --given parameter? ![1683857742780](https://github.com/google/deepvariant/assets/70870741/b8abded4-4325-4f07-9c72-8b2f40bae666). Look forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/647
https://github.com/google/deepvariant/issues/647:163,reliability,Doe,Does,163,"The question about the analysis of WES data; hello,. When analyzing WES data, I want to force the output of some sites to ensure that they appear in the vcf file. Does deepvariant1.4 have a function similar to the sentieon --given parameter? ![1683857742780](https://github.com/google/deepvariant/assets/70870741/b8abded4-4325-4f07-9c72-8b2f40bae666). Look forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/647
https://github.com/google/deepvariant/issues/648:217,modifiability,paramet,parameter,217,"question about WES data analysis; hello,. When analyzing WES data, I want to force the output of some sites to ensure that they appear in the vcf file. Does deepvariant have a function similar to the sentieon --given parameter? ![1683857742780](https://github.com/google/deepvariant/assets/70870741/b8abded4-4325-4f07-9c72-8b2f40bae666). Look forward to your favourable reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/648
https://github.com/google/deepvariant/issues/648:152,reliability,Doe,Does,152,"question about WES data analysis; hello,. When analyzing WES data, I want to force the output of some sites to ensure that they appear in the vcf file. Does deepvariant have a function similar to the sentieon --given parameter? ![1683857742780](https://github.com/google/deepvariant/assets/70870741/b8abded4-4325-4f07-9c72-8b2f40bae666). Look forward to your favourable reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/648
https://github.com/google/deepvariant/issues/649:443,deployability,resourc,resources,443,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:443,energy efficiency,resourc,resources,443,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:763,energy efficiency,cpu,cpus,763,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:314,interoperability,bind,bind,314,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:0,modifiability,Pac,PacBio,0,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:314,modifiability,bind,bind,314,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:419,modifiability,PAC,PACBIO,419,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:443,performance,resourc,resources,443,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:763,performance,cpu,cpus,763,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:443,safety,resourc,resources,443,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/649:443,testability,resourc,resources,443,"PacBio Variant Call and Phasing step; Hi,. I am new to Long reads seq and Deepvariant i tried to to WGS Variant calling steps from Alignment ( pbmm2 ) from GIAB data and Variant Call through Deepvariant Singularity Image ( singularity pull --name deepvariant.simg docker://google/deepvariant). `singularity exec --bind /data $path/Programs/DeepVariant/deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref $path/Data/resources/Homo_sapiens_assembly38.fasta --reads $path/Data/m84011_220902_175841_Aln.bam --output_vcf $path/Analysis/out_m84011_220902_175841_sif.vcf.gz --num_shards 60`. My query: Is Haplotype phasing with whatshap mandatory step after variant call ? As it takes more than 3hrs i do not see anyway to speed up with more cpus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/649
https://github.com/google/deepvariant/issues/650:314,deployability,pipelin,pipeline,314,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:434,deployability,version,version,434,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:508,deployability,resourc,resource,508,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:542,deployability,version,version,542,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:766,deployability,resourc,resource,766,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:775,deployability,log,log,775,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:806,deployability,log,log,806,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:842,deployability,log,log,842,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1018,deployability,log,log,1018,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1091,deployability,log,log,1091,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:36,energy efficiency,GPU,GPU,36,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:155,energy efficiency,GPU,GPU,155,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:233,energy efficiency,profil,profile,233,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:330,energy efficiency,GPU,GPU,330,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:430,energy efficiency,CPU,CPU,430,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:491,energy efficiency,optim,optimizing,491,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:502,energy efficiency,cloud,cloud,502,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:508,energy efficiency,resourc,resource,508,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:517,energy efficiency,alloc,allocations,517,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:538,energy efficiency,GPU,GPU,538,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:762,energy efficiency,GPU,GPU,762,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:766,energy efficiency,resourc,resource,766,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:787,energy efficiency,gpu,gpustat,787,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:873,energy efficiency,GPU,GPU,873,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1007,energy efficiency,gpu,gpu,1007,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1080,energy efficiency,gpu,gpu,1080,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:314,integrability,pipelin,pipeline,314,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:434,integrability,version,version,434,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:542,integrability,version,version,542,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:944,integrability,sub,subject,944,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:967,interoperability,share,share,967,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:434,modifiability,version,version,434,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:542,modifiability,version,version,542,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:709,modifiability,Pac,PacBio,709,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:36,performance,GPU,GPU,36,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:155,performance,GPU,GPU,155,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:233,performance,profil,profile,233,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:330,performance,GPU,GPU,330,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:430,performance,CPU,CPU,430,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:491,performance,optimiz,optimizing,491,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:502,performance,cloud resourc,cloud resource,502,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:538,performance,GPU,GPU,538,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:762,performance,GPU,GPU,762,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:766,performance,resourc,resource,766,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:787,performance,gpu,gpustat,787,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:873,performance,GPU,GPU,873,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1007,performance,gpu,gpu,1007,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1080,performance,gpu,gpu,1080,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:855,reliability,doe,doesn,855,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:214,safety,reme,remember,214,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:508,safety,resourc,resource,508,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:695,safety,test,test,695,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:766,safety,resourc,resource,766,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:775,safety,log,log,775,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:806,safety,log,log,806,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:842,safety,log,log,842,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1018,safety,log,log,1018,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1091,safety,log,log,1091,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:775,security,log,log,775,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:806,security,log,log,806,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:842,security,log,log,842,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1018,security,log,log,1018,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1091,security,log,log,1091,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:508,testability,resourc,resource,508,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:695,testability,test,test,695,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:766,testability,resourc,resource,766,"Study on cost benefit of running in GPU mode; **Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode. Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode. The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed. So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below). Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you! Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
