id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/743:475,usability,Error,Error,475,"Error on testing deepvariant for WES; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/743
https://github.com/google/deepvariant/issues/744:73,deployability,pipelin,pipeline,73,"splitting bam for deepvariant input; Hello,. I am working on a next-flow pipeline and have a question about using the deep variant tool. Would it still work correctly if I split the bam file into chromosomes, or if it's not designed to be used with a splitter? Additionally, I would like to know if there would be any speed issues between the two options. Using the splitter chromosomes would be faster, but I am unsure.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/744
https://github.com/google/deepvariant/issues/744:73,integrability,pipelin,pipeline,73,"splitting bam for deepvariant input; Hello,. I am working on a next-flow pipeline and have a question about using the deep variant tool. Would it still work correctly if I split the bam file into chromosomes, or if it's not designed to be used with a splitter? Additionally, I would like to know if there would be any speed issues between the two options. Using the splitter chromosomes would be faster, but I am unsure.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/744
https://github.com/google/deepvariant/issues/744:30,safety,input,input,30,"splitting bam for deepvariant input; Hello,. I am working on a next-flow pipeline and have a question about using the deep variant tool. Would it still work correctly if I split the bam file into chromosomes, or if it's not designed to be used with a splitter? Additionally, I would like to know if there would be any speed issues between the two options. Using the splitter chromosomes would be faster, but I am unsure.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/744
https://github.com/google/deepvariant/issues/744:30,usability,input,input,30,"splitting bam for deepvariant input; Hello,. I am working on a next-flow pipeline and have a question about using the deep variant tool. Would it still work correctly if I split the bam file into chromosomes, or if it's not designed to be used with a splitter? Additionally, I would like to know if there would be any speed issues between the two options. Using the splitter chromosomes would be faster, but I am unsure.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/744
https://github.com/google/deepvariant/issues/744:131,usability,tool,tool,131,"splitting bam for deepvariant input; Hello,. I am working on a next-flow pipeline and have a question about using the deep variant tool. Would it still work correctly if I split the bam file into chromosomes, or if it's not designed to be used with a splitter? Additionally, I would like to know if there would be any speed issues between the two options. Using the splitter chromosomes would be faster, but I am unsure.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/744
https://github.com/google/deepvariant/issues/745:293,availability,error,error,293,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:523,deployability,contain,container,523,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:216,energy efficiency,gpu,gpu,216,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:216,performance,gpu,gpu,216,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:293,performance,error,error,293,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:293,safety,error,error,293,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:115,usability,command,command,115,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/745:293,usability,error,error,293,"/opt/deepvariant/bin/deeptrio/run_deeptrio: No such file or directory; I tried to run deeptrio using the suggested command:. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_deeptrio-1.6.0rc2-gpu.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio. However, there was an error showing that. /opt/nvidia/nvidia_entrypoint.sh: line 67: /opt/deepvariant/bin/run_deeptrio: No such file or directory. I shelled into the sif file and couldn't find /opt/deepvariant/bin/run_deeptrio. Is this file missing in container or shall I use another executable? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/745
https://github.com/google/deepvariant/issues/746:258,availability,error,error,258,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:593,availability,operat,operations,593,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:647,availability,operat,operations,647,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2858,deployability,modul,module,2858,"e.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2882,deployability,API,API,2882,"s are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2886,deployability,version,version,2886,"['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2908,deployability,version,version,2908,":46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2954,deployability,API,API,2954,".py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3086,deployability,api,api-incompatibility,3086,"eference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3320,deployability,modul,module,3320,"ader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5245,deployability,fail,failed,5245,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5282,deployability,fail,failed,5282,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:406,energy efficiency,core,core,406,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:472,energy efficiency,optim,optimized,472,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:552,energy efficiency,CPU,CPU,552,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5229,energy efficiency,core,core,5229,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1039,integrability,buffer,buffer,1039,"'m trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2882,integrability,API,API,2882,"s are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2886,integrability,version,version,2886,"['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2908,integrability,version,version,2908,":46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2954,integrability,API,API,2954,".py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3086,integrability,api,api-incompatibility,3086,"eference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:411,interoperability,platform,platform,411,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2882,interoperability,API,API,2882,"s are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2954,interoperability,API,API,2954,".py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2958,interoperability,incompatib,incompatibility,2958,"tarting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3086,interoperability,api,api-incompatibility,3086,"eference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:803,modifiability,interm,intermediate,803,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:870,modifiability,Interm,Intermediate,870,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2073,modifiability,deco,decode,2073,"ples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2858,modifiability,modul,module,2858,"e.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2886,modifiability,version,version,2886,"['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2908,modifiability,version,version,2908,":46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3320,modifiability,modul,module,3320,"ader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:258,performance,error,error,258,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:472,performance,optimiz,optimized,472,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:506,performance,Network,Network,506,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:552,performance,CPU,CPU,552,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:572,performance,perform,performance-critical,572,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:996,performance,time,time,996,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1011,performance,parallel,parallel,1011,"ing docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is defaul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2802,performance,Overhead,Overhead,2802," I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5263,performance,parallel,parallel,5263,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5245,reliability,fail,failed,5245,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5282,reliability,fail,failed,5282,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:156,safety,test,test,156,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:258,safety,error,error,258,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1116,safety,test,testdata,1116,"Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1179,safety,test,testdata,1179,"ogle/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1519,safety,test,testdata,1519,"oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/ki",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1655,safety,input,inputs,1655," rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1745,safety,test,testdata,1745,"16 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2048,safety,input,input,2048,"deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2213,safety,test,testdata,2213,"m"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2357,safety,test,testdata,2357,"lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscrat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2825,safety,input,inputs,2825," 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2858,safety,modul,module,2858,"e.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3320,safety,modul,module,3320,"ader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5360,safety,test,testdata,5360,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5421,safety,test,testdata,5421,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:506,security,Network,Network,506,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:156,testability,test,test,156,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1116,testability,test,testdata,1116,"Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1141,testability,unit,unittest,1141,"uick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1179,testability,test,testdata,1179,"ogle/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1519,testability,test,testdata,1519,"oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/ki",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1745,testability,test,testdata,1745,"16 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2213,testability,test,testdata,2213,"m"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2357,testability,test,testdata,2357,"lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscrat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3153,testability,Trace,Traceback,3153,"500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5360,testability,test,testdata,5360,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5385,testability,unit,unittest,5385,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5421,testability,test,testdata,5421,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:258,usability,error,error,258,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:300,usability,help,help,300,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:572,usability,perform,performance-critical,572,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:981,usability,command,command,981,"Issue with running docker image; Hello,. I'm trying to run Deepvariant using singularity. I just followed the ""Notes on Singularity"" section in quick start test (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md), and I got an error regarding numpy as below. Could you help me resolve this issue? I used deepvariant_1.6.0 image. ```. 2023-12-02 23:23:35.126320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:1655,usability,input,inputs,1655," rebuild TensorFlow with the appropriate compiler flags. I1202 23:23:41.449015 46912500266816 run_deepvariant.py:519] Re-using the directory for intermediate results in /flashscratch/kimkw/tmp/tmppin2lwy5. ***** Intermediate results will be written to /flashscratch/kimkw/tmp/tmppin2lwy5 in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2048,usability,input,input,2048,"deepvariant/bin/make_examples --mode calling --ref ""./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I1202 23:23:46.123890 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.133658 46912500266816 make_examples_core.py:301] Preparing inputs. I1202 23:23:46.139615 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.140348 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:2825,usability,input,inputs,2825," 46912500266816 make_examples_core.py:301] Common contigs are ['chr20']. I1202 23:23:46.141555 46912500266816 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3046,usability,user,user,3046,"input, note that we will decode CRAM using the reference you passed in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:3110,usability,indicat,indications,3110,"in with --ref. I1202 23:23:46.150200 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.240882 46912500266816 genomics_reader.py:222] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1202 23:23:46.241135 46912500266816 make_examples_core.py:301] Writing gvcf records to /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord-00000-of-00001.gz. I1202 23:23:46.248160 46912500266816 make_examples_core.py:301] Writing examples to /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord-00000-of-00001.gz. I1202 23:23:46.248263 46912500266816 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . Traceback (most recent call last):. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/746:5684,usability,user,user,5684,"line 224, in main. make_examples_core.make_examples_runner(options). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2847, in make_examples_runner. region_example_shape = region_processor.writes_examples_in_region(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1566, in writes_examples_in_region. for example in self.create_pileup_examples(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2333, in create_pileup_examples. pileup_images = self.pic.create_pileup_images(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 602, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 544, in _pileup_for_pair_of_alts. ref_image = self.build_pileup(. File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 490, in build_pileup. build_pileup_for_one_sample(reads_for_samples[i], sample). File ""/flashscratch/kimkw/tmp/Bazel.runfiles_hubgarxp/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 400, in build_pileup_for_one_sample. self._encoder.encode_reference(refbases). ImportError: numpy.core.multiarray failed to import. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /flashscratch/kimkw/tmp/tmppin2lwy5/make_examples.tfrecord@1.gz --channels insert_size --gvcf /flashscratch/kimkw/tmp/tmppin2lwy5/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m6.183s. user 0m3.271s. sys 0m1.140s. ``` .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/746
https://github.com/google/deepvariant/issues/747:288,safety,test,test,288,"I have built Deepvariant:1.6.0 successfully in my Ubuntu20.04. I want to know something about its usage.; 1. How can i use deepvariant if I have built it from source?(By bazel-bin/deepvariant/*runfiles?). 2. If i want to change the source of deepvariant/pileup_image_native.cc, how can I test it after changing the source.(It means how can i rerun deepvariant if i change the source code, do i need to recompile and how?). Thank you for your help and patience!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/747
https://github.com/google/deepvariant/issues/747:288,testability,test,test,288,"I have built Deepvariant:1.6.0 successfully in my Ubuntu20.04. I want to know something about its usage.; 1. How can i use deepvariant if I have built it from source?(By bazel-bin/deepvariant/*runfiles?). 2. If i want to change the source of deepvariant/pileup_image_native.cc, how can I test it after changing the source.(It means how can i rerun deepvariant if i change the source code, do i need to recompile and how?). Thank you for your help and patience!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/747
https://github.com/google/deepvariant/issues/747:442,usability,help,help,442,"I have built Deepvariant:1.6.0 successfully in my Ubuntu20.04. I want to know something about its usage.; 1. How can i use deepvariant if I have built it from source?(By bazel-bin/deepvariant/*runfiles?). 2. If i want to change the source of deepvariant/pileup_image_native.cc, how can I test it after changing the source.(It means how can i rerun deepvariant if i change the source code, do i need to recompile and how?). Thank you for your help and patience!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/747
https://github.com/google/deepvariant/issues/748:31,deployability,log,log,31,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:648,deployability,log,log,648,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1811,deployability,log,log,1811,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1911,deployability,log,logtostderr,1911,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1992,deployability,log,logging,1992,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:405,energy efficiency,cpu,cpus,405,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1102,energy efficiency,CPU,CPUs,1102,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:980,integrability,Transform,Transforming,980,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1138,integrability,transform,transformation,1138,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1703,integrability,coupl,couple,1703,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1847,integrability,coupl,couple,1847,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:980,interoperability,Transform,Transforming,980,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1138,interoperability,transform,transformation,1138,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1703,modifiability,coupl,couple,1703,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1847,modifiability,coupl,couple,1847,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:405,performance,cpu,cpus,405,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:585,performance,memor,memory,585,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1102,performance,CPU,CPUs,1102,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1111,performance,parallel,parallelization,1111,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1797,performance,time,times,1797,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:31,safety,log,log,31,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:648,safety,log,log,648,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1811,safety,log,log,1811,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1911,safety,log,logtostderr,1911,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1992,safety,log,logging,1992,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:31,security,log,log,31,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:648,security,log,log,648,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1811,security,log,log,1811,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1911,security,log,logtostderr,1911,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1992,security,log,logging,1992,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:31,testability,log,log,31,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:648,testability,log,log,648,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1703,testability,coupl,couple,1703,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1811,testability,log,log,1811,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1847,testability,coupl,couple,1847,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1911,testability,log,logtostderr,1911,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:1992,testability,log,logging,1992,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:111,usability,command,command,111,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/748:585,usability,memor,memory,585,"Using PAR region flag seems to log NativeBedReader endlessly; Hi,. This is running v1.6 via singularity with a command like. ```. /opt/deepvariant/bin/postprocess_variants --ref ref.fa --infile call_variants_output@1.tfrecord.gz --outfile all.vcf.gz --gvcf_outfile all.g.vcf.gz --nonvariant_site_tfrecord_path gvcf.tfrecord@24.gz --novcf_stats_report --haploid_contigs ""X,Y"" --par_regions_bed ""PAR.bed"" --cpus 2. ```. where PAR.bed is. ```. X 133300518 139009144. Y 1 6822380. ```. Running this without the haploid contigs and bed args works fine (although seems to use a **lot** more memory compared to v1.5), but when I try with these flags, the log file just explodes with . ```. 2023-12-08 16:13:45.044559: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 11203892. I1208 16:16:08.029405 47184308283200 postprocess_variants.py:1313] CVO sorting took 3.885532522201538 minutes. I1208 16:16:08.030001 47184308283200 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1208 16:16:08.030090 47184308283200 postprocess_variants.py:1318] Using 4 CPUs for parallelization of variant transformation. I1208 16:16:08.959253 47184308283200 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample. I1208 16:20:43.170422 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.188045 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.189731 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. I1208 16:20:43.205978 47184308283200 genomics_reader.py:222] Reading PAR.bed with NativeBedReader. ... . ```. Within a couple of minutes it had written that ""Reading PAR.bed with NativeBedReader"" nearly 2 million times and the log file was already 200 Mb after a couple of minutes. I tried using `--logging_level FATAL` and `--logtostderr --stderrthreshold fatal`, but I couldn't find a way to turn off that logging.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/748
https://github.com/google/deepvariant/issues/749:0,availability,Checkpoint,Checkpointing,0,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:457,availability,error,error,457,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:595,availability,Operat,Operating,595,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:964,availability,Error,Error,964,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1337,availability,avail,available,1337,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:544,deployability,pipelin,pipeline,544,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:642,deployability,version,version,642,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:658,deployability,Instal,Installation,658,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:902,energy efficiency,CPU,CPUs,902,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1396,energy efficiency,GPU,GPU,1396,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:506,integrability,wrap,wrapper,506,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:544,integrability,pipelin,pipeline,544,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:642,integrability,version,version,642,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:506,interoperability,wrapper,wrapper,506,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:642,modifiability,version,version,642,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:457,performance,error,error,457,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:902,performance,CPU,CPUs,902,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:964,performance,Error,Error,964,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1396,performance,GPU,GPU,1396,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:0,reliability,Checkpoint,Checkpointing,0,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:996,reliability,Doe,Does,996,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1337,reliability,availab,available,1337,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:194,safety,compl,completion,194,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:228,safety,compl,completes,228,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:439,safety,compl,completed,439,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:457,safety,error,error,457,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:964,safety,Error,Error,964,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1017,safety,test,test,1017,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1063,safety,compl,complete,1063,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1105,safety,test,test,1105,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1337,safety,avail,available,1337,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:194,security,compl,completion,194,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:228,security,compl,completes,228,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:439,security,compl,completed,439,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1063,security,compl,complete,1063,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1337,security,availab,available,1337,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:757,testability,instrument,instrument,757,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:970,testability,trace,trace,970,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1017,testability,test,test,1017,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1105,testability,test,test,1105,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:1280,testability,context,context,1280,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:16,usability,resum,resuming,16,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:457,usability,error,error,457,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:514,usability,command,command,514,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:952,usability,Command,Command,952,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/749:964,usability,Error,Error,964,"Checkpointing / resuming analysis; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. I am struggling to get DeepTrio to run to completion on a small dataset. It completes at the end of call_variants.py but my system just collapses when at postprocess_variants. Through using --dry_run=true, I'm able to keep going only after being sufficiently confident the last step has completed without error. So in short, is it possible to re-run the wrapper command and have the analysis pipeline pick up where it left off? . **Setup**. - Operating system: Rocky Linux 8. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): through Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) illumina, 151bp, same reference as case studies. - RAM 64 GB. - CPUs 32 (c6i.8xlarge). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?** Yes they do. they complete because they are small. . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Unfortunately, i cant run it on g4dn.8xlarge available to me since that EC2 running Amazon Linux 2, and GPU DeepVariant seems to need Ubuntu. In short, a ""step_x_completed"" sentinel file at end of each step would be great IMO. . Thanks,. -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/749
https://github.com/google/deepvariant/issues/750:70,safety,test,tested,70,"How to understand the running results of deepvariant?; Hello,. When I tested Deepvariant, I found one site reported as Refcall by deepvariant. `chr1	155205518	.	C	G	0.3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:12:391:275,116:0.296675:0,11,29`. But the result of GATK is: `0/1:581,245:826:99:4620,0,14057`. How should I understand RefCall? The VAF of these sites is less than 0.3 due to misalignment caused by high homology in this region. Is there a way for deepvariant to recognize them as PASS? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/750
https://github.com/google/deepvariant/issues/750:7,testability,understand,understand,7,"How to understand the running results of deepvariant?; Hello,. When I tested Deepvariant, I found one site reported as Refcall by deepvariant. `chr1	155205518	.	C	G	0.3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:12:391:275,116:0.296675:0,11,29`. But the result of GATK is: `0/1:581,245:826:99:4620,0,14057`. How should I understand RefCall? The VAF of these sites is less than 0.3 due to misalignment caused by high homology in this region. Is there a way for deepvariant to recognize them as PASS? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/750
https://github.com/google/deepvariant/issues/750:70,testability,test,tested,70,"How to understand the running results of deepvariant?; Hello,. When I tested Deepvariant, I found one site reported as Refcall by deepvariant. `chr1	155205518	.	C	G	0.3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:12:391:275,116:0.296675:0,11,29`. But the result of GATK is: `0/1:581,245:826:99:4620,0,14057`. How should I understand RefCall? The VAF of these sites is less than 0.3 due to misalignment caused by high homology in this region. Is there a way for deepvariant to recognize them as PASS? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/750
https://github.com/google/deepvariant/issues/750:311,testability,understand,understand,311,"How to understand the running results of deepvariant?; Hello,. When I tested Deepvariant, I found one site reported as Refcall by deepvariant. `chr1	155205518	.	C	G	0.3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:12:391:275,116:0.296675:0,11,29`. But the result of GATK is: `0/1:581,245:826:99:4620,0,14057`. How should I understand RefCall? The VAF of these sites is less than 0.3 due to misalignment caused by high homology in this region. Is there a way for deepvariant to recognize them as PASS? Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/750
https://github.com/google/deepvariant/issues/751:424,availability,state,statement,424,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:679,availability,down,downstream,679,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:838,availability,down,downstream,838,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:154,deployability,version,version,154,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:469,energy efficiency,current,current,469,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:154,integrability,version,version,154,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:424,integrability,state,statement,424,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:371,interoperability,specif,specified,371,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:154,modifiability,version,version,154,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:192,performance,time,time,192,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:903,security,sign,significant,903,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:200,testability,understand,understand,200,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:644,testability,understand,understand,644,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:135,usability,support,support,135,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:418,usability,clear,clear,418,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:441,usability,document,documentation,441,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:665,usability,tool,tools,665,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/751:1238,usability,tool,tool,1238,"Representation of hemizygous genotypes as homozygous when using --haploid_contigs in postprocess_variants; It was great to see haploid support added with version 1.6. However, it took me some time to understand that I had it working correctly as my expectation was that the genotypes would be represented as hemizygous (0 or 1) rather than homozygous (0/0 or 1/1) in the specified regions. Would it be useful to add a clear statement in the documentation regarding the current representation in ""haploid"" regions, and to possibly consider adding an option in postprocess_variants that allowed an alternative output with hemizygous genotypes? I understand that some tools used in downstream applications may have problems with hemizygous genotypes, and therefore the desirability of representing them as homozygous. However there are also downstream applications where true hemizygote representation has significant value. For us this would be the ability to generate accurate AF, AC and AN values after aggregating into multisample vcfs, but I am sure there are others that would benefit from a more accurate representation of genotypes on the true X and Y chromosomes. Many thanks for considering this and for providing this very useful tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/751
https://github.com/google/deepvariant/issues/752:374,availability,error,error,374,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2210,availability,Operat,Operating,2210,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2632,availability,Error,Error,2632,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:298,deployability,fail,failed,298,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1940,deployability,modul,module,1940,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1968,deployability,fail,failed,1968,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2242,deployability,contain,container,2242,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2267,deployability,version,version,2267,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2285,deployability,Instal,Installation,2285,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:390,energy efficiency,Current,Current,390,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2267,integrability,version,version,2267,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1940,modifiability,modul,module,1940,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2267,modifiability,version,version,2267,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:374,performance,error,error,374,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1949,performance,parallel,parallel,1949,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2632,performance,Error,Error,2632,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:298,reliability,fail,failed,298,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1968,reliability,fail,failed,1968,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:374,safety,error,error,374,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:1940,safety,modul,module,1940,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2632,safety,Error,Error,2632,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2638,testability,trace,trace,2638,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:374,usability,error,error,374,"Unable to run DeepVariant with Star Alignments for RNASeq data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. YES, RNA and STAR are not covered not covered. **Describe the issue:**. 2023-12-14 03:00:18.822708: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (8 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f351d854740 (most recent call first):. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 72 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2401,usability,Command,Command,2401,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/752:2632,usability,Error,Error,2632,"t/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_imzp9_kb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. **Setup**. - Operating system: Google Docker container. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: RNASeq. . **Steps to reproduce:**. - Command: /opt/deepvariant/bin/make_examples --mode calling --ref dnaref/genome.fa --reads SAMN02990337.star.bam --examples /tmp/tmp6yy2ufd4/make_examples.tfrecord@16.gz --channels insert_size --regions enough.merge.bed --task 4. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/752
https://github.com/google/deepvariant/issues/753:468,availability,error,error,468,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:62,deployability,version,version,62,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:212,deployability,version,version,212,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:236,deployability,contain,contain,236,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:684,deployability,modul,module,684,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:790,deployability,modul,module,790,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:42,energy efficiency,gpu,gpu,42,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:192,energy efficiency,gpu,gpu,192,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:62,integrability,version,version,62,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:212,integrability,version,version,212,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:62,modifiability,version,version,62,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:212,modifiability,version,version,212,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:544,modifiability,variab,variable,544,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:684,modifiability,modul,module,684,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:790,modifiability,modul,module,790,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:42,performance,gpu,gpu,42,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:192,performance,gpu,gpu,192,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:468,performance,error,error,468,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:475,reliability,doe,does,475,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:468,safety,error,error,468,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:684,safety,modul,module,684,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:790,safety,modul,module,790,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:580,testability,Trace,Traceback,580,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/753:468,usability,error,error,468,"docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 and the proto file cannot import; . **Describe the issue:**. i have use docker pull from google/deepvariant:1.6.0-gpu ,but the python version is 3.11 in this contain，i don't know why. <img width=""1165"" alt=""iShot_2023-12-14_15 23 49"" src=""https://github.com/google/deepvariant/assets/15654389/d61f07f0-b540-4bda-8a9e-ccb633cfe3e7"">. I want to debug with source code, but there will be this error, does this deepvariant.proto need to be compiled manually？. `ironment variable `TF_ENABLE_ONEDNN_OPTS=0`. Traceback (most recent call last):. File ""/code/deepvariant/deepvariant/call_variants.py"", line 48, in <module>. from deepvariant import dv_utils. File ""/code/deepvariant/deepvariant/dv_utils.py"", line 44, in <module>. from deepvariant.protos import deepvariant_pb2. ImportError: cannot import name 'deepvariant_pb2' from 'deepvariant.protos' (unknown location). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/753
https://github.com/google/deepvariant/issues/754:12,availability,error,error,12,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:92,availability,error,error,92,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:197,deployability,modul,module,197,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:314,deployability,modul,module,314,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:478,deployability,modul,module,478,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:627,deployability,modul,module,627,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:789,deployability,modul,module,789,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:954,deployability,modul,module,954,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:21,energy efficiency,gpu,gpu,21,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:71,energy efficiency,gpu,gpu,71,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:652,energy efficiency,core,core,652,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:744,energy efficiency,core,core,744,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:197,modifiability,modul,module,197,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:267,modifiability,pac,packages,267,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:314,modifiability,modul,module,314,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:424,modifiability,pac,packages,424,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:478,modifiability,modul,module,478,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:568,modifiability,pac,packages,568,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:627,modifiability,modul,module,627,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:724,modifiability,pac,packages,724,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:789,modifiability,modul,module,789,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:900,modifiability,pac,packages,900,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:954,modifiability,modul,module,954,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:1121,modifiability,pac,packages,1121,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:12,performance,error,error,12,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:21,performance,gpu,gpu,21,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:71,performance,gpu,gpu,71,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:92,performance,error,error,92,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:12,safety,error,error,12,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:92,safety,error,error,92,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:197,safety,modul,module,197,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:314,safety,modul,module,314,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:478,safety,modul,module,478,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:627,safety,modul,module,627,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:789,safety,modul,module,789,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:954,safety,modul,module,954,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:100,testability,Trace,Traceback,100,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:523,testability,context,context,523,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:601,testability,context,context,601,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:12,usability,error,error,12,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:92,usability,error,error,92,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:346,usability,tool,tools,346,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/754:1176,usability,help,help,1176,"deepvariant error on gpu; I am running deep variant example code using gpu but getting this error:. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 5, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 51, in <module>. from google.protobuf.pyext import _message. ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/home/rmehmood/.local/lib/python3.8/site-packages/google/protobuf/pyext/__init__.py). need kind help, many thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/754
https://github.com/google/deepvariant/issues/755:0,deployability,Updat,Updates,0,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:82,deployability,version,version,82,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:115,deployability,updat,updating,115,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:156,deployability,version,version,156,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:371,deployability,build,build,371,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:444,deployability,version,version,444,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:82,integrability,version,version,82,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:156,integrability,version,version,156,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:444,integrability,version,version,444,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:82,modifiability,version,version,82,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:156,modifiability,version,version,156,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:444,modifiability,version,version,444,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:272,reliability,Doe,Does,272,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:0,safety,Updat,Updates,0,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:115,safety,updat,updating,115,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:0,security,Updat,Updates,0,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:115,security,updat,updating,115,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:408,security,sign,significant,408,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:106,testability,plan,plans,106,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/755:22,usability,tool,tools,22,"Updates to underlying tools in docker; Hi,. I noticed that DeepTrio uses an older version of GLNexus. any plans on updating the docker image to include new version? This is a bit of naive question but how can i ensure the Docker analysis solution is using Python >= 3.11? Does this mean my system has to be Python 3.11 or greater or is this a question of what is used to build docker image? I ask because of significant speedups gained in this version of Python and beyond... Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/755
https://github.com/google/deepvariant/issues/756:510,availability,error,error,510,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1098,availability,operat,operations,1098,"source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1164,availability,operat,operations,1164,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:192,deployability,build,build-prereq,192,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:289,deployability,build,build,289,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1318,deployability,modul,module,1318,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1421,deployability,modul,module,1421,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1560,deployability,modul,module,1560,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1740,deployability,modul,module,1740,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:911,energy efficiency,core,core,911,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:977,energy efficiency,optim,optimized,977,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1057,energy efficiency,CPU,CPU,1057," . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:916,interoperability,platform,platform,916,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1318,modifiability,modul,module,1318,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1421,modifiability,modul,module,1421,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1560,modifiability,modul,module,1560,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1740,modifiability,modul,module,1740,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:2153,modifiability,pac,packages,2153,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:510,performance,error,error,510,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:977,performance,optimiz,optimized,977,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1011,performance,Network,Network,1011,"de, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the sour",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1057,performance,CPU,CPU,1057," . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1077,performance,perform,performance-critical,1077,"I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:510,safety,error,error,510,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1318,safety,modul,module,1318,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1421,safety,modul,module,1421,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1560,safety,modul,module,1560,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1740,safety,modul,module,1740,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1011,security,Network,Network,1011,"de, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the sour",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1232,testability,Trace,Traceback,1232,". **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ with bazel？. Is there an easy way to reference third_party.nucleus packages ？.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:510,usability,error,error,510,"Debug source code, but bazel compilation has some problems; . **Describe the issue:**. I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/756:1077,usability,perform,performance-critical,1077,"I want to debug source code，and execute “python deepvariant/call_variants.py”. **Setup**. i have execute build-prereq.sh and build_and_test.sh. In order to get the compilation result . i execute ""bazel build ..."",get the file like this :. <img width=""529"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/50fbd52c-afed-4ade-a3fa-f2eaf0859b3d"">. . The same name comes from different directories.so,the error happy:. “from third_party.nucleus.io import sharded_file_utils ” from root workspace. “from third_party.nucleus.protos import variants_pb2” from bazel-bin. <img width=""647"" alt=""image"" src=""https://github.com/google/deepvariant/assets/15654389/76e1373b-dbfb-48b6-95d1-59bd07badbcc"">. `root@7065ad26b62a:/deepvariant# python deepvariant/call_variants.py. 2023-12-19 06:28:51.254398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):. File ""deepvariant/call_variants.py"", line 53, in <module>. from deepvariant import dv_utils. File ""/deepvariant/./deepvariant/dv_utils.py"", line 47, in <module>. from deepvariant.protos import deepvariant_pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/deepvariant_pb2.py"", line 17, in <module>. from deepvariant.protos import realigner_pb2 as deepvariant_dot_protos_dot_realigner__pb2. File ""/deepvariant/bazel-bin/deepvariant/protos/realigner_pb2.py"", line 21, in <module>. from third_party.nucleus.protos import range_pb2 as third__party_dot_nucleus_dot_protos_dot_range__pb2. ImportError: cannot import name 'range_pb2' from 'third_party.nucleus.protos' (/deepvariant/./third_party/nucleus/protos/__init__.py). `. How can i debug the source code in the right way? How to correctly compile proto files and c++ w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/756
https://github.com/google/deepvariant/issues/757:0,availability,Error,Error,0,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:161,availability,error,error,161,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:193,availability,error,error,193,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:744,modifiability,PAC,PACBIO,744,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:0,performance,Error,Error,0,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:161,performance,error,error,161,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:193,performance,error,error,193,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:0,safety,Error,Error,0,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:161,safety,error,error,161,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:193,safety,error,error,193,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:486,safety,test,testdata,486,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:606,safety,input,input,606,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:762,safety,input,input,762,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:802,safety,input,input,802,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:486,testability,test,testdata,486,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:0,usability,Error,Error,0,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:161,usability,error,error,161,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:193,usability,error,error,193,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:222,usability,help,help,222,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:606,usability,input,input,606,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:762,usability,input,input,762,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/757:802,usability,input,input,802,"Error running DeepVariant v1.1.0; Hello,. Thank you very much for providing the software. However, when I run deepvariant v1.1.0, I encounter the following file error. I did not encounter this error before. I hope you can help me solve this problem. Thank you very much for your assistance. Below is my commond:. BIN_VERSION=""1.1.0"". INPUT_DIR=""/data/lilab/hli1/Workspace/DATA/run_out_data/sorted_BAM/vs_F/6_2_vsF"". #DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/run_DeepVariant_6-20231219"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/input/F_unphased.Chr.v2.fa \. 	--reads=/input/6ccs_2_vsF.sorted.bam \. 	--output_vcf=/output/output.vcf.gz \. 	--output_gvcf=/output/output.g.vcf.gz \. 	--intermediate_results_dir /output/intermediate_results_dir \. 	--num_shards=30. [DeepVariant-v1.1.0.docx](https://github.com/google/deepvariant/files/13722568/DeepVariant-v1.1.0.docx).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/757
https://github.com/google/deepvariant/issues/758:293,availability,error,errors,293,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:419,availability,error,error,419,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:982,availability,Operat,Operating,982,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:1021,deployability,version,version,1021,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:1066,deployability,Instal,Installation,1066,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:353,energy efficiency,CPU,CPU,353,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:606,energy efficiency,PREDICT,PREDICTION,606,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:704,energy efficiency,PREDICT,PREDICTION,704,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:1021,integrability,version,version,1021,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:1021,modifiability,version,version,1021,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:293,performance,error,errors,293,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:353,performance,CPU,CPU,353,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:419,performance,error,error,419,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:654,performance,TIME,TIME,654,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:780,performance,TIME,TIME,780,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:293,safety,error,errors,293,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:419,safety,error,error,419,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:606,safety,PREDICT,PREDICTION,606,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:704,safety,PREDICT,PREDICTION,704,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:83,usability,command,command,83,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:293,usability,error,errors,293,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:383,usability,stop,stop,383,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:395,usability,resum,resume,395,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/758:419,usability,error,error,419,"stuck for hours at candidate finding ; running call variants on ONT data using the command . `run_pepper_margin_deepvariant call_variant -b ./Sample/alignments/GRCh38/41195.minimap2.bam -f /data/Homo_sapiens_assembly38.fasta -o Sample -t 4 -s Sample --phased_output --ont_r9_guppy5_sup. `. no errors but it's stuck at Starting Candidate Finding and the CPU is at 0% for hours. Can I stop it and resume? why there is no error? will it ever finish? .... [12-24-2023 05:47:47] INFO: SUMMARY PROCESSED 7280/7280. [12-24-2023 05:47:47] INFO: THREAD 0 FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: FINISHED PREDICTION. [12-24-2023 05:54:33] INFO: ELAPSED TIME: 867 Min 41 Sec. [12-24-2023 05:54:33] INFO: PREDICTION FINISHED SUCCESSFULLY. [12-24-2023 05:54:33] INFO: TOTAL ELAPSED TIME FOR INFERENCE: 867 Min 44 Sec. [12-24-2023 05:54:33] INFO: STEP 3/3 FINDING CANDIDATES. [12-24-2023 05:54:33] INFO: OUTPUT: 41195/pepper/. [12-24-2023 05:55:25] INFO: STARTING CANDIDATE FINDING. - Operating system: Linux. - DeepVariant version: kishwars/pepper_deepvariant r0.8. - Installation method (Docker, built from source, etc.): Docker. ONT long reads .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/758
https://github.com/google/deepvariant/issues/759:171,deployability,observ,observe,171,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:0,energy efficiency,GPU,GPU,0,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:106,energy efficiency,gpu,gpu-memory-is-needed-for-the-keras-models,106,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:183,energy efficiency,model,model,183,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:204,energy efficiency,GPU,GPU,204,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:225,energy efficiency,GPU,GPU,225,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:0,performance,GPU,GPU,0,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:24,performance,memor,memory,24,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:106,performance,gpu,gpu-memory-is-needed-for-the-keras-models,106,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:204,performance,GPU,GPU,204,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:208,performance,memor,memory,208,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:225,performance,GPU,GPU,225,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:255,performance,memor,memory,255,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:162,safety,test,test,162,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:141,security,model,models,141,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:183,security,model,model,183,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:162,testability,test,test,162,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:171,testability,observ,observe,171,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:24,usability,memor,memory,24,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:110,usability,memor,memory-is-needed-for-the-keras-models,110,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:208,usability,memor,memory,208,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/759:255,usability,memor,memory,255,"GPU with less than 16GB memory; Per: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#how-much-gpu-memory-is-needed-for-the-keras-models. 16GB. In our test, we observe the model occupying 16GB GPU memory. I have a GPU NVIDIA RTX A2000 with 6GB memory, is there a way I can use it to do the call variants step with no problems?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/759
https://github.com/google/deepvariant/issues/760:38,availability,error,error,38,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:206,availability,error,error-correction,206,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:326,availability,error,error-correction,326,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:427,availability,error,errors,427,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:515,availability,error,error,515,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:381,deployability,pipelin,pipeline,381,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:381,integrability,pipelin,pipeline,381,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:38,performance,error,error,38,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:206,performance,error,error-correction,206,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:326,performance,error,error-correction,326,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:427,performance,error,errors,427,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:515,performance,error,error,515,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:485,reliability,Doe,Does,485,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:38,safety,error,error,38,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:206,safety,error,error-correction,206,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:326,safety,error,error-correction,326,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:427,safety,error,errors,427,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:515,safety,error,error,515,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:38,usability,error,error,38,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:206,usability,error,error-correction,206,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:326,usability,error,error-correction,326,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:427,usability,error,errors,427,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/760:515,usability,error,error,515,"Is there any option to use sequencing error correction part only?; Hi. I read this post and came here. [https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction](https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction). I'd like to apply the process to my pipeline. But the above example ingores indel errors and considers only regions with no known variants. Does this repo has sequencing error correction part? If then, can I use the part only? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/760
https://github.com/google/deepvariant/issues/761:125,availability,cluster,cluster,125,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1009,availability,Error,Error,1009,"1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1471,availability,avail,available,1471,"ries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1625,availability,avail,available,1625,"blic/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1995,availability,operat,operations,1995,"ards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2061,availability,operat,operations,2061,"A Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2207,availability,operat,operations,2207,"ents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2238,availability,sli,slightly,2238,"A Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2307,availability,error,errors,2307,"r, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12547,availability,checkpoint,checkpoint,12547,"61 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow comm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13380,availability,mainten,maintenance,13380,"roup_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use sav",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13464,availability,down,downstream,13464,"/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:125,deployability,cluster,cluster,125,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:154,deployability,instal,installed,154,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:279,deployability,manag,managed,279,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:302,deployability,version,version,302,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1068,deployability,Version,Version,1068,"epvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1084,deployability,Contain,Container,1084," trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1184,deployability,contain,container,1184,"hrough conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1258,deployability,Contain,Container,1258,"success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numeri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1302,deployability,contain,container,1302,"on with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1421,deployability,contain,container-license,1421,"and, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1489,deployability,contain,container,1489," which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1510,deployability,CONTAIN,CONTAINER-LICENSE,1510,"using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loade",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1651,deployability,Contain,Container,1651,"/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1683,deployability,contain,container,1683,"gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3004,deployability,instal,installed,3004,"X2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3119,deployability,fail,failed,3119,"flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4069,deployability,fail,failed,4069,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4236,deployability,instal,installed,4236,"_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4350,deployability,fail,failed,4350,"f8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4517,deployability,instal,installed,4517,"allel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singular",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5182,deployability,instal,installed,5182,"UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5783,deployability,instal,installed,5783," cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5898,deployability,fail,failed,5898,"dia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_0376",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7452,deployability,fail,failed,7452,"aring inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_0376",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13158,deployability,instal,installed,13158,".263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13396,deployability,releas,release,13396,"cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13493,deployability,depend,dependencies,13493,".tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13784,deployability,fail,failed,13784,"ect file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16159,deployability,instal,installed,16159,"cess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 14041",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16274,deployability,fail,failed,16274,"1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18047,deployability,instal,installed,18047,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18162,deployability,fail,failed,18162,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:35,energy efficiency,gpu,gpu,35,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:254,energy efficiency,gpu,gpu,254,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:279,energy efficiency,manag,managed,279,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:298,energy efficiency,CPU,CPU,298,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:398,energy efficiency,gpu,gpu,398,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:529,energy efficiency,GPU,GPU,529,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:663,energy efficiency,gpu,gpuver,663,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:688,energy efficiency,gpu,gpu,688,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1595,energy efficiency,GPU,GPU,1595,"ic2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1698,energy efficiency,GPU,GPU,1698,"opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1751,energy efficiency,cloud,cloud-native,1751,". --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1808,energy efficiency,core,core,1808,"eddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1874,energy efficiency,optim,optimized,1874,"1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1954,energy efficiency,CPU,CPU,1954,"cf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2170,energy efficiency,core,core,2170,"erved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2538,energy efficiency,load,load,2538,"venience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2926,energy efficiency,GPU,GPU,2926,"DNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4716,energy efficiency,load,load,4716,"--reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with Tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5104,energy efficiency,GPU,GPU,5104,"hat your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5317,energy efficiency,load,load,5317," perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can als",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5705,energy efficiency,GPU,GPU,5705,"ould not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12564,energy efficiency,model,models,12564,"984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12692,energy efficiency,load,load,12692,"] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13080,energy efficiency,GPU,GPU,13080,"ake_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14389,energy efficiency,model,model,14389,"and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14467,energy efficiency,model,models,14467,"ream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14908,energy efficiency,Predict,Predicted,14908,"nts.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15423,energy efficiency,cpu,cpus,15423,"40372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15693,energy efficiency,load,load,15693,"/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16081,energy efficiency,GPU,GPU,16081,"sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16796,energy efficiency,CPU,CPUs,16796,"No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17581,energy efficiency,load,load,17581,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17969,energy efficiency,GPU,GPU,17969,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:302,integrability,version,version,302,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:559,integrability,pub,public,559,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:567,integrability,pub,public,567,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:628,integrability,pub,public,628,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1015,integrability,messag,messages,1015,"ith singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1068,integrability,Version,Version,1068,"epvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3547,integrability,buffer,buffer,3547," library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13493,integrability,depend,dependencies,13493,".tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13517,integrability,repositor,repositories,13517,"amples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14937,integrability,batch,batches,14937,"processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16673,integrability,Transform,Transforming,16673,"64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16832,integrability,transform,transformation,16832,"H: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:806,interoperability,share,shareddata,806,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1015,interoperability,messag,messages,1015,"ith singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1813,interoperability,platform,platform,1813,"Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2493,interoperability,platform,platform,2493,"r at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2623,interoperability,share,shared,2623,"vailable. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/course",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3635,interoperability,share,shareddata,3635,"e: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3751,interoperability,share,shareddata,3751,"024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4297,interoperability,standard,standard,4297," results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4578,interoperability,standard,standard,4578,"amples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4671,interoperability,platform,platform,4671,"e/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4801,interoperability,share,shared,4801,"amples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5272,interoperability,platform,platform,5272," Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5402,interoperability,share,shared,5402,"ttings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 1401735",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6073,interoperability,share,shareddata,6073," would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6563,interoperability,share,shareddata,6563,"orflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 1403291690330",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7627,interoperability,share,shareddata,7627," I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8117,interoperability,share,shareddata,8117,"15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9005,interoperability,share,shareddata,9005,"ring inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9169,interoperability,share,shareddata,9169,"veSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9933,interoperability,share,shareddata,9933,3517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core.py:301] Task 1/2: 6 candidates (8 examples) [0.25s elapsed]. I0105 15:54:39.302088 140329169033024 make_examples_core.py:301] Task 1/2: 2003 candidates (2147 examples) [48.30s elapsed]. I0105 15:54:41.885760 140173517489984 make_examp,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:10097,interoperability,share,shareddata,10097,3517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core.py:301] Task 1/2: 6 candidates (8 examples) [0.25s elapsed]. I0105 15:54:39.302088 140329169033024 make_examples_core.py:301] Task 1/2: 2003 candidates (2147 examples) [48.30s elapsed]. I0105 15:54:41.885760 140173517489984 make_examples_core.py:301] Task 0/2: 2000 candidates (2124 examples) [50.99s elapsed]. I0105 15:55:13.311895 140173517489984 make_examples_core.py:301] Task 0/2: Writing exam,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12647,interoperability,platform,platform,12647,"7 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12777,interoperability,share,shared,12777,"e_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13517,interoperability,repositor,repositories,13517,"amples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15209,interoperability,share,shareddata,15209,"19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15648,interoperability,platform,platform,15648,"blic3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postproce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15778,interoperability,share,shared,15778,"[100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16673,interoperability,Transform,Transforming,16673,"64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16832,interoperability,transform,transformation,16832,"H: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17536,interoperability,platform,platform,17536,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17666,interoperability,share,shared,17666,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:302,modifiability,version,version,302,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1068,modifiability,Version,Version,1068,"epvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2387,modifiability,variab,variable,2387,".com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results wil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3289,modifiability,interm,intermediate,3289,"t round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3367,modifiability,Interm,Intermediate,3367,"e environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7299,modifiability,deco,decode,7299,"name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8853,modifiability,deco,decode,8853,"name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13208,modifiability,pac,packages,13208,"] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13493,modifiability,depend,dependencies,13493,".tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:35,performance,gpu,gpu,35,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:254,performance,gpu,gpu,254,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:298,performance,CPU,CPU,298,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:398,performance,gpu,gpu,398,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:529,performance,GPU,GPU,529,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:663,performance,gpu,gpuver,663,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:688,performance,gpu,gpu,688,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1009,performance,Error,Error,1009,"1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1208,performance,content,contents,1208,"d it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1595,performance,GPU,GPU,1595,"ic2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1698,performance,GPU,GPU,1698,"opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1874,performance,optimiz,optimized,1874,"1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1908,performance,Network,Network,1908,"f=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1954,performance,CPU,CPU,1954,"cf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1974,performance,perform,performance-critical,1974,"f.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2307,performance,error,errors,2307,"r, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2538,performance,load,load,2538,"venience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2926,performance,GPU,GPU,2926,"DNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3504,performance,time,time,3504,"ult/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are sup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3519,performance,parallel,parallel,3519,":64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and instal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4716,performance,load,load,4716,"--reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with Tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5104,performance,GPU,GPU,5104,"hat your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5317,performance,load,load,5317," perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can als",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5705,performance,GPU,GPU,5705,"ould not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9677,performance,Overhead,Overhead,9677,":50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:10605,performance,Overhead,Overhead,10605,"5:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core.py:301] Task 1/2: 6 candidates (8 examples) [0.25s elapsed]. I0105 15:54:39.302088 140329169033024 make_examples_core.py:301] Task 1/2: 2003 candidates (2147 examples) [48.30s elapsed]. I0105 15:54:41.885760 140173517489984 make_examples_core.py:301] Task 0/2: 2000 candidates (2124 examples) [50.99s elapsed]. I0105 15:55:13.311895 140173517489984 make_examples_core.py:301] Task 0/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I0105 15:55:13.312177 140173517489984 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12325,performance,time,time,12325,"55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12692,performance,load,load,12692,"] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13080,performance,GPU,GPU,13080,"ake_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14937,performance,batch,batches,14937,"processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15131,performance,time,time,15131,"of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15423,performance,cpu,cpus,15423,"40372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15693,performance,load,load,15693,"/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16081,performance,GPU,GPU,16081,"sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16796,performance,CPU,CPUs,16796,"No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16805,performance,parallel,parallelization,16805," directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17346,performance,time,time,17346,"ected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with Nati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17581,performance,load,load,17581,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17969,performance,GPU,GPU,17969,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1471,reliability,availab,available,1471,"ries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1625,reliability,availab,available,1625,"blic/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2238,reliability,sli,slightly,2238,"A Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3119,reliability,fail,failed,3119,"flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4069,reliability,fail,failed,4069,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4350,reliability,fail,failed,4350,"f8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5898,reliability,fail,failed,5898,"dia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_0376",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7452,reliability,fail,failed,7452,"aring inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_0376",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12547,reliability,checkpoint,checkpoint,12547,"61 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow comm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13380,reliability,mainten,maintenance,13380,"roup_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use sav",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13784,reliability,fail,failed,13784,"ect file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16274,reliability,fail,failed,16274,"1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18162,reliability,fail,failed,18162,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:207,safety,test,tested,207,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:279,safety,manag,managed,279,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:447,safety,compl,complained,447,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:501,safety,prevent,prevented,501,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1009,safety,Error,Error,1009,"1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1471,safety,avail,available,1471,"ries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1585,safety,detect,detected,1585,"c3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1625,safety,avail,available,1625,"blic/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2307,safety,error,errors,2307,"r, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3190,safety,detect,detected,3190,"neDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5969,safety,detect,detected,5969,"/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6246,safety,input,input,6246,"er/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6461,safety,input,inputs,6461,": /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7274,safety,input,input,7274,"se default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7523,safety,detect,detected,7523,"22] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7800,safety,input,input,7800,"'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8015,safety,input,inputs,8015,"29209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8828,safety,input,input,8828,"se default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s el",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9700,safety,input,inputs,9700,"3024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:10628,safety,input,inputs,10628,"17489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core.py:301] Task 1/2: 6 candidates (8 examples) [0.25s elapsed]. I0105 15:54:39.302088 140329169033024 make_examples_core.py:301] Task 1/2: 2003 candidates (2147 examples) [48.30s elapsed]. I0105 15:54:41.885760 140173517489984 make_examples_core.py:301] Task 0/2: 2000 candidates (2124 examples) [50.99s elapsed]. I0105 15:55:13.311895 140173517489984 make_examples_core.py:301] Task 0/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I0105 15:55:13.312177 140173517489984 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13493,safety,depend,dependencies,13493,".tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13855,safety,detect,detected,13855,"lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14136,safety,input,input,14136,"entioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14179,safety,input,input,14179,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14288,safety,input,input,14288," (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14506,safety,input,input,14506,"m other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14549,safety,input,input,14549,"unity (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14765,safety,input,input,14765,"_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14808,safety,input,input,14808,"_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14908,safety,Predict,Predicted,14908,"nts.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15026,safety,Compl,Complete,15026,"roup_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16345,safety,detect,detected,16345,"call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. tim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18233,safety,detect,detected,18233,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:447,security,compl,complained,447,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:501,security,preven,prevented,501,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1221,security,govern,governed,1221,"er python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1471,security,availab,available,1471,"ries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1585,security,detect,detected,1585,"c3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1625,security,availab,available,1625,"blic/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1908,security,Network,Network,1908,"f=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3190,security,detect,detected,3190,"neDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:5969,security,detect,detected,5969,"/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7523,security,detect,detected,7523,"22] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12564,security,model,models,12564,"984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13457,security,modif,modify,13457,"xamples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] Fro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13855,security,detect,detected,13855,"lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14389,security,model,model,14389,"and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14467,security,model,models,14467,"ream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15026,security,Compl,Complete,15026,"roup_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:16345,security,detect,detected,16345,"call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:06.236791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. tim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18233,security,detect,detected,18233,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:207,testability,test,tested,207,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13417,testability,plan,planned,13417,"9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.2209",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13493,testability,depend,dependencies,13493,".tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:39,usability,support,support,39,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:426,usability,command,command,426,"deepvariant 1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical opera",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1009,usability,Error,Error,1009,"1.6.0 with singularity gpu support; Dear all. I am new to deepvariant. We are trying to use deepvariant on a HPC cluster with singularity. We installed nvidia and cuda drivers through conda, and tested it with other python programs that used gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1249,usability,Learn,Learning,1249," gpu with success. I also managed to run the CPU version with deepvariant with singularity with success. . However when running deepvariant on a gpu node with the following command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly differ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1412,usability,learn,learning-container-license,1412," command, deepvariant complained that certain libraries are not found which prevented it from using the GPU:. `apptainer run --nv -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3 \. /public/software/deepvariants/1.6.0/gpuver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1661,usability,Tool,Toolkit,1661,"uver/deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or direct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1702,usability,support,support,1702,"epvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$REF \. --reads=""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" \. --regions ""NC_037590.1:200,000-950,000"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:1974,usability,perform,performance-critical,1974,"f.gz \. --num_shards=2`. Error messages:. `==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2200,usability,custom,custom,2200," its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I01",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:2307,usability,error,errors,2307,"r, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. WARNING: The NVIDIA Driver was not detected. GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see. https://docs.nvidia.com/datacenter/cloud-native/ . 2024-01-05 15:52:56.748367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-01-05 15:52:57.864310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-01-05 15:53:10.688853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:3489,usability,command,command,3489,"platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:10.692890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:26.990784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:27.004992 140619855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4222,usability,support,supported,4222,"9855705920 run_deepvariant.py:519] Re-using the directory for intermediate results in /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9. ***** Intermediate results will be written to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9 in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.22674",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:4503,usability,support,supported,4503," seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --reads ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"" --regions ""NC_037590.1:200,000-950,000"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LC_CTYPE = ""C.UTF-8"",. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-01-05 15:53:39.096475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.096611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:39.226747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6246,usability,input,input,6246,"er/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:6461,usability,input,inputs,6461,": /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:53:39.226871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 15:53:49.941043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.987410 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.988560 140173517489984 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7274,usability,input,input,7274,"se default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.021419 140173517489984 make_examples_core.py:301] Task 0/2: Preparing inputs. I0105 15:53:50.036767 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.054040 140173517489984 make_examples_core.py:301] Task 0/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:7800,usability,input,input,7800,"'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8015,usability,input,inputs,8015,"29209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.067565 140173517489984 make_examples_core.py:301] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2024-01-05 15:53:49.942446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:53:49.983960 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. W0105 15:53:49.992453 140329169033024 make_examples_core.py:344] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:8828,usability,input,input,8828,"se default as the sample name. You can also provide a sample name with the --sample_name argument. I0105 15:53:50.050559 140329169033024 make_examples_core.py:301] Task 1/2: Preparing inputs. I0105 15:53:50.080640 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.128940 140329169033024 make_examples_core.py:301] Task 1/2: Common contigs are ['NC_037590.1', 'NC_037591.1', 'NC_037592.1', 'NC_037593.1', 'NC_037594.1', 'NC_037595.1', 'NC_037596.1', 'NC_037597.1', 'NC_037598.1', 'NC_037599.1', 'NC_037600.1', 'NC_037601.1', 'NC_037602.1', 'NC_037603.1', 'NW_020229205.1', 'NW_020229206.1', 'NW_020229207.1', 'NW_020229208.1', 'NW_020229209.1', 'NW_020229210.1', 'NW_020229211.1', 'NW_020229212.1', 'NW_020229213.1', 'NC_024586.1']. I0105 15:53:50.174469 140329169033024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s el",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:9700,usability,input,inputs,9700,"3024 make_examples_core.py:301] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0105 15:53:50.325648 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.668989 140173517489984 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.671522 140173517489984 make_examples_core.py:301] Task 0/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00000-of-00002.gz. I0105 15:53:50.685908 140173517489984 make_examples_core.py:301] Task 0/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz. I0105 15:53:50.686180 140173517489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:10628,usability,input,inputs,10628,"17489984 make_examples_core.py:301] Task 0/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.897492 140173517489984 make_examples_core.py:301] Task 0/2: 15 candidates (15 examples) [0.21s elapsed]. I0105 15:53:50.507650 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.743297 140329169033024 genomics_reader.py:222] Reading /public2/courses/ec3121/shareddata/Pomacea_canaliculata/wgs/FSL10-M.bam with NativeSamReader. I0105 15:53:50.748420 140329169033024 make_examples_core.py:301] Task 1/2: Writing gvcf records to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord-00001-of-00002.gz. I0105 15:53:50.752661 140329169033024 make_examples_core.py:301] Task 1/2: Writing examples to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz. I0105 15:53:50.753379 140329169033024 make_examples_core.py:301] Task 1/2: Overhead for preparing inputs: 0 seconds. I0105 15:53:50.999809 140329169033024 make_examples_core.py:301] Task 1/2: 6 candidates (8 examples) [0.25s elapsed]. I0105 15:54:39.302088 140329169033024 make_examples_core.py:301] Task 1/2: 2003 candidates (2147 examples) [48.30s elapsed]. I0105 15:54:41.885760 140173517489984 make_examples_core.py:301] Task 0/2: 2000 candidates (2124 examples) [50.99s elapsed]. I0105 15:55:13.311895 140173517489984 make_examples_core.py:301] Task 0/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I0105 15:55:13.312177 140173517489984 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12263,usability,user,user,12263,"xamples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserW",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:12310,usability,command,command,12310,"7]. I0105 15:55:13.312256 140173517489984 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:13.315201 140173517489984 make_examples_core.py:301] Task 0/2: Found 3287 candidate variants. I0105 15:55:13.315361 140173517489984 make_examples_core.py:301] Task 0/2: Created 3569 examples. I0105 15:55:21.254777 140329169033024 make_examples_core.py:301] Task 1/2: Writing example info to /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I0105 15:55:21.255679 140329169033024 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0105 15:55:21.255904 140329169033024 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:21.262568 140329169033024 make_examples_core.py:301] Task 1/2: Found 3672 candidate variants. I0105 15:55:21.263317 140329169033024 make_examples_core.py:301] Task 1/2: Created 3944 examples. real 1m56.796s. user 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended develo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13260,usability,User,UserWarning,13260,"r 3m3.813s. sys 0m4.710s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:13372,usability,minim,minimal,13372,"/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --examples ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wgs"". 2024-01-05 15:55:31.140705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 15:55:31.140953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:51",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14136,usability,input,input,14136,"entioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14179,usability,input,input,14179,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14288,usability,input,input,14288," (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14506,usability,input,input,14506,"m other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14549,usability,input,input,14549,"unity (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-01-05 15:55:38.664328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14765,usability,input,input,14765,"_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:14808,usability,input,input,14808,"_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 15:55:38.709242 140372734228288 call_variants.py:471] Total 1 writing processes started. I0105 15:55:38.765925 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15067,usability,user,user,15067,"ke_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:15116,usability,command,command,15116,".json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:55:38.766286 140372734228288 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0105 15:55:38.768594 140372734228288 call_variants.py:510] Use saved model: True. I0105 15:56:02.220975 140372734228288 dv_utils.py:365] From /opt/models/wgs/example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:02.221645 140372734228288 dv_utils.py:365] From /public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0105 15:56:51.296850 140372734228288 call_variants.py:583] Predicted 1024 examples in 1 batches [4.670 sec per 100]. I0105 16:00:45.139408 140372734228288 call_variants.py:623] Complete: call_variants. real 5m27.431s. user 6m58.490s. sys 0m19.033s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public2/courses/ec3121/shareddata/Pomacea_canaliculata/refgenome/GCF_003073045.1_ASM307304v1_genomic.fna"" --infile ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/call_variants_output.tfrecord.gz"" --outfile ""./outputgpu/output.vcf.gz"" --cpus ""2"" --gvcf_outfile ""./outputgpu/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public3/group_crf/home/cuirf/.tmp/tmp3vf8mpw9/gvcf.tfrecord@2.gz"". 2024-01-05 16:00:59.661436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:00:59.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17283,usability,user,user,17283," to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 geno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:17331,usability,command,command,17331,"device is detected. I0105 16:01:06.304423 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/761:18377,usability,user,user,18377,"iants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:06.676597 140416700553024 postprocess_variants.py:1313] CVO sorting took 0.006136405467987061 minutes. I0105 16:01:06.677379 140416700553024 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0105 16:01:06.677495 140416700553024 postprocess_variants.py:1318] Using 2 CPUs for parallelization of variant transformation. I0105 16:01:06.808352 140416700553024 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0105 16:01:08.209710 140416700553024 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.01743464469909668 minutes. I0105 16:01:10.258949 140416700553024 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.03414338032404582 minutes. real 0m21.740s. user 0m13.473s. sys 0m2.305s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""./outputgpu/output.vcf.gz"" --outfile_base ""./outputgpu/output"". 2024-01-05 16:01:21.188421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-01-05 16:01:21.188700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-01-05 16:01:28.513759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. I0105 16:01:28.547411 140591583876928 genomics_reader.py:222] Reading ./outputgpu/output.vcf.gz with NativeVcfReader. real 0m18.513s. user 0m11.281s. sys 0m1.577s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/761
https://github.com/google/deepvariant/issues/762:19,availability,error,error,19,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:59,availability,error,error,59,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:278,availability,error,error,278,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:194,deployability,fail,failed,194,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:698,deployability,log,logs,698,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:76,modifiability,Pac,PacBio,76,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:485,modifiability,PAC,PACBIO,485,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:19,performance,error,error,19,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:59,performance,error,error,59,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:278,performance,error,error,278,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:799,performance,time,times,799,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:194,reliability,fail,failed,194,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:19,safety,error,error,19,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:59,safety,error,error,59,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:278,safety,error,error,278,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:378,safety,input,input,378,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:549,safety,input,input,549,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:577,safety,input,input,577,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:698,safety,log,logs,698,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:698,security,log,logs,698,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:698,testability,log,logs,698,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:19,usability,error,error,19,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:59,usability,error,error,59,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:278,usability,error,error,278,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:378,usability,input,input,378,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:549,usability,input,input,549,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/762:577,usability,input,input,577,"Left-normalization error; I have encountered the following error in several PacBio HiFi samples while running the docker image of deepvariant 1.4.0:. > F deepvariant/allelecounter.cc:872] Check failed: left_padding + right_padding < counts_.size() (5000 vs. 4022). Fatal Python error: Aborted. Deepvariant was run while enabling read normalization:. docker run -v ""input_path"":/input -v ""output_path"":/output google/deepvariant:1.4.0 /opt/deepvariant/bin /run_deepvariant --model_type=PACBIO --make_examples_extra_args=""normalize_reads=true"" --ref=/input/reference.fa --reads=/input/sample.bam --output_vcf=/output/sample.vcf --output_gvcf=/output/sample.gvcf --num_shards=16 --logging_dir=/output/logs. I know it is discouraged to enable read normalization due to potential excessive computational times, but I need it to make sure that I am capturing INDELs on the same conditions as my Illumina left-aligned samples. Any ideas on how to solve this issue? Thank you,. Eugenio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/762
https://github.com/google/deepvariant/issues/763:2993,availability,Operat,Operating,2993,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:103,deployability,observ,observation,103,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:415,deployability,contain,contains,415,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3034,deployability,version,version,3034,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3052,deployability,Instal,Installation,3052,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3119,deployability,contain,container,3119,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3034,integrability,version,version,3034,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:94,interoperability,share,share,94,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3034,modifiability,version,version,3034,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:454,performance,time,times,454,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:798,safety,detect,detected,798,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:1975,safety,TEST,TEST,1975,"45_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Ye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:798,security,detect,detected,798,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:103,testability,observ,observation,103,"Variant calls after local realignment : is it the most accurate ?; Dear all,. I would like to share an observation with you. Deepvariant reported a lot of variants in a region where no reads are mapped. It is the consequence of Deepvariant local realignment as expected. But the realigned reads do not seem to belong to this region : the orignal alignment shows less variants than the local realignment. The genome contains a big region repeated several times (see on the screenshots below). The repeats could be the reason why some reads are moved to the left. The given example is for X chromosome but another region in chromosome 1 (_FLG2_ gene region) showed a lot of variants. Why the reads are moved to the left? Are the reads moved to the most possible left position? Original alignment and detected variants (bwa-mem). ![image](https://github.com/google/deepvariant/assets/30355684/7f6ac2c3-59b9-4754-9e15-b70ed8b5461c). Local realignment made by DeepVariant (X_140993145_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:1975,testability,TEST,TEST,1975,"45_140994144). ![image](https://github.com/google/deepvariant/assets/30355684/4c6fdc69-f881-44aa-8935-8c627a591f6f). Example of reads that were moved:. Original alignment. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993994 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Ye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/763:3158,testability,instrument,instrument,3158,"TACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE XA:Z:X,+140993784,79M,2; PG:Z:MarkDuplicates AS:i:74 XS:i:69 MD:Z:17C61 NM:i:1 RG:Z:DM_23_2198. NB501857:464:HH7FWBGXV:2:23210:26812:14806 147 X 140994064 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA XA:Z:X,-140994589,50M3D29M,4; PG:Z:MarkDuplicates AS:i:79 XS:i:67 MD:Z:79 NM:i:0 RG:Z:DM_23_2198. Local realignment. X:140993145-140994144/ X_140993145_140994144realigned_reads.bam X_140993145_140994144realigned_reads.bam.bai. frmascla@frt:DeepV-TEST$ samtools view Local/X_140993145_140994144realigned_reads.bam | grep NB501857:464:HH7FWBGXV:2:23210:26812:14806. NB501857:464:HH7FWBGXV:2:23210:26812:14806 99 X 140993784 50 79M = 140994064 149 CCAGATTCCTGTGAGCCGCTCCTTCTCCTCCACTTTAGTGAGTCTTTTCCAGAGTTCCCCTGAGAGAACTCAGAGTACT AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEAEEEEE. NB501857:464:HH7FWBGXV:2:23210:26812:14806 19 X 140993854 57 79M = 140993994 -149 CAGAGTACTTTTGAGGGTTTTCCCCAGTCTCCTCTCCAGATTCCTGTGAGCTCCTCCTCCTCCTCCACTTTATTGAGTC AAEEEEEEEEEEEEEE<66EEEEEEEEEE/EAEEEEEEEE6EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAAAAA. Original alignment, bam file. https://www.dropbox.com/scl/fi/c9tc01sdtf2sroxj3u3bj/original_alignment.bam?rlkey=jgxnyhyse2ekcu6t1s3l3lnnl&dl=0. Local realignment, bam file. https://www.dropbox.com/scl/fi/oqhny0s7h9hu3zcyrprig/X_140993145_140994144realigned_reads.bam?rlkey=zmbon72t19vjlcdht1zt6m5xg&dl=0. **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. Yes. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity container. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina 2x79bp paired-end sequencing, WES, reference genome=hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/763
https://github.com/google/deepvariant/issues/764:234,availability,Operat,Operating,234,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:801,availability,Error,Error,801,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:18,deployability,version,version,18,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:276,deployability,version,version,276,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:293,deployability,Instal,Installation,293,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:18,integrability,version,version,18,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:276,integrability,version,version,276,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:18,modifiability,version,version,18,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:276,modifiability,version,version,276,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:470,modifiability,PAC,PACBIO-SMART,470,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:672,modifiability,PAC,PACBIO,672,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:801,performance,Error,Error,801,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:931,reliability,Doe,Does,931,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:168,safety,detect,detected,168,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:801,safety,Error,Error,801,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:884,safety,Compl,Complete,884,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:952,safety,test,test,952,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:988,safety,test,test,988,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:168,security,detect,detected,168,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:884,security,Compl,Complete,884,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:389,testability,instrument,instrument,389,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:807,testability,trace,trace,807,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:952,testability,test,test,952,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:988,testability,test,test,988,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:1162,testability,context,context,1162,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:517,usability,person,person,517,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:553,usability,Command,Command,553,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/764:801,usability,Error,Error,801,"There are bugs in version 1.6; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. When variant is not detected, the program will freeze in the last step；. **Setup**. - Operating system:Centos7.6. - DeepVariant version: 1.6 . - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO-SMART；A reference sequence for a normal person；. **Steps to reproduce:**. - Command: /bin/singularity run -B /work/:/work/ /work/deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=human_geneA_reference.fa --reads=reference.align.bam --output_vcf=out.vcf --output_gvcf=out.gvcf --num_shards=32. - Error trace: Last line： I0119 11:43:53.450599 47012502976320 call_variants.py:623] Complete: call_variants（Stuck at this step）. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. [deepvariant_1.6.pdf](https://github.com/google/deepvariant/files/13986125/deepvariant_1.6.pdf).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/764
https://github.com/google/deepvariant/issues/765:120,availability,checkpoint,checkpoint,120,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:474,integrability,sub,sub-sampling,474,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:203,interoperability,share,share,203,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:413,performance,time,time,413,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:421,performance,perform,perform,421,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:120,reliability,checkpoint,checkpoint,120,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:288,safety,input,input,288,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:87,usability,document,documents,87,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:113,usability,custom,custom,113,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:220,usability,command,commands,220,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:288,usability,input,input,288,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:421,usability,perform,perform,421,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/765:677,usability,guidanc,guidance,677,"Better example for training; Hi @pichuan,. I did come across various bits in different documents on how to train custom checkpoint but i don't have a confident on handle on it before I embark. - Can you share the entire commands as an example if i want to re-train using multiple BAMs as input (I saw you are using 18 different BAM to train WGS 1.5). - Do all the generated example files need to live at the same time to perform training? (ie is there a way to do iterative sub-sampling of large BAM and generate examples that get deleted once they are used? - Do you have a good rule of thumb for how many examples needed? (I saw you are over 350M for WGS 1.5). Thank you for guidance! -Daniel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/765
https://github.com/google/deepvariant/issues/766:151,deployability,contain,container,151,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:381,deployability,log,logs,381,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:24,energy efficiency,Model,Model,24,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:98,energy efficiency,model,models,98,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:237,energy efficiency,model,models,237,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:251,energy efficiency,model,model,251,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:272,safety,test,test,272,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:381,safety,log,logs,381,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:660,safety,test,test,660,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:24,security,Model,Model,24,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:98,security,model,models,98,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:237,security,model,models,237,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:251,security,model,model,251,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:381,security,log,logs,381,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:272,testability,test,test,272,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:381,testability,log,logs,381,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:520,testability,context,context,520,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/766:660,testability,test,test,660,"DeepVariant with RNASeq Model ""stuck""; I have tried running deepvariant (v1.6.0) using the rnaseq models using the example data with the google docker container:. `run_deepvariant --num_shards=32 --model_type=WES --customized_model=/opt/models/rnaseq/model.ckpt --regions=test.bed --ref=genome.fa --reads=hg005_gm26107.mrna.grch38.bam --output_vcf=deepvariantrna.vcf --logging_dir=logs --make_examples_extra_args=""split_skip_reads=true,channels=''""`. But it seems to get stuck at the call_variant step. **Any additional context:**. <img width=""1304"" alt=""image"" src=""https://github.com/google/deepvariant/assets/7647927/0c01d955-c1fa-4ede-9579-3f942c262c3a"">. test.bed. chr1 13670 13966. chr1 14409 14501. chr1 15005 15038. chr1 15796 15947. chr1 16607 16765. chr1 16858 17055. chr1 17233 17368. chr1 17369 17436. chr1 17606 17742. chr1 17915 18061. chr1 18268 18366. chr1 24738 24891. chr1 29534 30039. chr1 30267 30667. chr1 30976 31109. chr1 34554 35174. chr1 35245 35481. chr1 35721 36081. chr1 52473 53312. chr1 57598 57653. chr1 58700 58856. chr1 62916 64116. chr1 65419 65433. chr1 65520 65573. chr1 69037 71585. chr1 89295 91629. chr1 92091 92240. chr1 110953 111357. chr1 112700 112804. chr1 120721 120932. chr1 129055 129223. chr1 131025 134836. chr1 135141 135895. chr1 137682 137965. chr1 139790 139847. chr1 140075 140339. chr1 141474 143011. chr1 146386 149707. chr1 155767 155831. chr1 157784 157887. chr1 160446 160690. chr1 161314 161525. chr1 164263 164791. chr1 165491 165942. chr1 167129 168165. chr1 168610 168767. chr1 169049 169264. chr1 172557 172688. chr1 173753 173862. chr1 182696 182746. chr1 183132 183216. chr1 183494 183571. chr1 183740 183901. chr1 183981 184174. chr1 185217 185350. chr1 185491 185559. chr1 186317 186469. chr1 187129 187287. chr1 187376 187577. chr1 187755 187890. chr1 187891 187958. chr1 188130 188266. chr1 188439 188584. chr1 188791 188902. chr1 195263 195411. chr1 257864 259025. chr1 261550 261634. chr1 263015 268655. chr1 268667 268816. chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/766
https://github.com/google/deepvariant/issues/767:0,availability,Error,Error,0,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:650,availability,error,error,650,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:675,availability,Error,Error,675,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:385,deployability,version,version,385,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:328,energy efficiency,cloud,cloud,328,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:385,integrability,version,version,385,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:656,integrability,messag,message,656,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:257,interoperability,specif,specifically,257,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:656,interoperability,messag,message,656,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:385,modifiability,version,version,385,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:0,performance,Error,Error,0,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:503,performance,time,time,503,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:650,performance,error,error,650,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:675,performance,Error,Error,675,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:0,safety,Error,Error,0,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:650,safety,error,error,650,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:675,safety,Error,Error,675,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:690,safety,except,exception,690,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:667,testability,simpl,simply,667,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:0,usability,Error,Error,0,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:467,usability,command,command,467,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:650,usability,error,error,650,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:667,usability,simpl,simply,667,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/767:675,usability,Error,Error,675,"Error running KMC in Giraffe case study; Hi all,. This is not strictly a DeepVariant issue, but it is an issue I ran into while following the Giraffe case study using exome FASTQs from [here](https://www.internationalgenome.org/data-portal/sample/NA12878) (specifically, `SRR1518158_*.fastq.gz`). I'm running this on a DNAnexus cloud workstation (`mem1_ssd1_v2_x8`) and using the same version of KMC used in the case study. I am trying to run KMC using the following command:. ```. TMPDIR=$(mktemp -d). time ./kmc -k29 -okff -t8 sra.fq.paths ./sra.fq $TMPDIR. ```. where `sra.fq.paths` is the result of `ls SRR1518158_*.fastq.gz > sra.fq.paths`. The error message is simply `Error: unknown exception`. Have you seen this before? I thought I'd ask here before filing an issue with the KMC repo. Thanks,. Samantha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/767
https://github.com/google/deepvariant/issues/768:461,availability,down,down,461,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:29,energy efficiency,cpu,cpu,29,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:116,energy efficiency,cpu,cpu,116,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:182,energy efficiency,cpu,cpu,182,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:29,performance,cpu,cpu,29,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:116,performance,cpu,cpu,116,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:182,performance,cpu,cpu,182,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:584,safety,input,input,584,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:795,safety,input,input,795,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:103,security,control,control,103,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:103,testability,control,control,103,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:216,usability,user,user,216,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:584,usability,input,input,584,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/768:795,usability,input,input,795,"How could I lower the Total %cpu when deepvariant running call_variant.py; Hello,. I have a trouble to control the %cpu in Linux when deepvariant run call_variant.py step. It makes %cpu is too high to affect another user to run his program. ![Pasted image 20240201133331(1)](https://github.com/google/deepvariant/assets/91660863/8f6a76bf-5d27-4a27-8175-417a644f396e). How could I make it lower than this picture show? Please look at my picture, And put my code down. . docker run \. -u ""$(id -u)"":""$(id -g)"" \. -v ""${hg19}"":""/home/luohaosen/ref"" \. -v ""${INPUT_DIR}"":""/home/luohaosen/input"" \. -v ""${OUTPUT_DIR}"":""/home/luohaosen/output"" \. luohaosen/deepvariant:v1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/home/luohaosen/ref/ucsc.hg19.fa \. --reads=/home/luohaosen/input/TKQX230060435-1A.MarkDuplicates.bam \. --output_vcf=/home/luohaosen/output/TKQX230060435.deepvariant.vcf.gz \. --intermediate_results_dir=/home/luohaosen/output/intermediate_results_dir \. --num_shards=$num_shards. (Note：luohaosen//deepvariant:v1 is based on google/deepvariant:1.6.0，It is almost the same as origin google/deepvariant:1.6.0 docker image).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/768
https://github.com/google/deepvariant/issues/769:238,availability,Operat,Operating,238,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1020,availability,avail,available,1020,"h38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1105,availability,error,error-free,1105," noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3196,availability,checkpoint,checkpoint,3196,"203 17:23:04.933572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3431,availability,mainten,maintenance,3431,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3515,availability,down,downstream,3515,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:89,deployability,upgrad,upgrading,89,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:288,deployability,API,API,288,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:326,deployability,version,version,326,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:343,deployability,Instal,Installation,343,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:946,deployability,log,log,946,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3447,deployability,releas,release,3447,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3544,deployability,depend,dependencies,3544,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4009,deployability,contain,contain,4009,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4264,deployability,observ,observed,4264,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3213,energy efficiency,model,models,3213,"3572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:288,integrability,API,API,288,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:326,integrability,version,version,326,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3544,integrability,depend,dependencies,3544,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3568,integrability,repositor,repositories,3568,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:288,interoperability,API,API,288,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3568,interoperability,repositor,repositories,3568,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:89,modifiability,upgrad,upgrading,89,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:326,modifiability,version,version,326,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:441,modifiability,Pac,PacBio,441,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:576,modifiability,PAC,PACBIO,576,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3220,modifiability,pac,pacbio,3220,"7565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3259,modifiability,pac,packages,3259," Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3544,modifiability,depend,dependencies,3544,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1105,performance,error,error-free,1105," noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:2987,performance,time,time,2987,"23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.933463 137565708298048 make_examples_core.py:301] Task 7/16: Found 0 candidate variants. I0203 17:23:04.933572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4173,performance,time,time,4173,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1020,reliability,availab,available,1020,"h38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3196,reliability,checkpoint,checkpoint,3196,"203 17:23:04.933572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3431,reliability,mainten,maintenance,3431,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:946,safety,log,log,946,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1020,safety,avail,available,1020,"h38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1105,safety,error,error-free,1105," noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3544,safety,depend,dependencies,3544,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4091,safety,Compl,Complete,4091,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:946,security,log,log,946,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1020,security,availab,available,1020,"h38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3213,security,model,models,3213,"3572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3508,security,modif,modify,3508,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4091,security,Compl,Complete,4091,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:946,testability,log,log,946,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1089,testability,simul,simulates,1089,"ding to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10].",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3468,testability,plan,planned,3468,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3544,testability,depend,dependencies,3544,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:4264,testability,observ,observed,4264,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:132,usability,behavi,behavior,132,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:509,usability,Command,Command,509,"v1.6 hangs when only (GRCh38) alt-mapping reads present.; **Describe the issue:**. After upgrading to v1.6, we noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.93169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:1105,usability,error,error-free,1105," noticed this strange behavior, where the program hangs on a sharded BAM that holds only alt-contig mapping reads. **Setup**. - Operating system: on GCE via Google Life Sciences API (through Cromwell). - DeepVariant version: v1.6. - Installation method (Docker, built from source, etc.): official v1.6 docker. - Type of data: Both PacBio HiFi and ONT (10.4), on GRCh38. . **Steps to reproduce:**. - Command. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --haploid_contigs chrX,chrY \. --par_regions_bed GRCh38.PAR.bed \. --reads=/cromwell_root/<sample_id>.alts.bam \. --output_vcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.vcf.gz \. --output_gvcf=/cromwell_root/dv_output/<sample_id>.alts.deepvariant.g.vcf.gz \. --num_shards=16. ```. - Relevant log . (note it says ""0 examples"", so I suspect it is when no examples are available, not just when there's only alt-mapping reads, e.g. if one simulates reads error-free from the reference itself, it probably will have the same issue). ```. /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00011-of-00016.gz.example_info.json. I0203 17:23:03.253894 135328978921280 make_examples_core.py:2958] example_shape = None. I0203 17:23:03.254237 135328978921280 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:03.255900 135328978921280 make_examples_core.py:301] Task 11/16: Found 0 candidate variants. I0203 17:23:03.256017 135328978921280 make_examples_core.py:301] Task 11/16: Created 0 examples. I0203 17:23:04.930985 137565708298048 make_examples_core.py:301] Task 7/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00007-of-00016.gz.example_info.json. I0203 17:23:04.931358 137565708298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:2919,usability,user,user,2919,"08298048 make_examples_core.py:2958] example_shape = None. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.933463 137565708298048 make_examples_core.py:301] Task 7/16: Found 0 candidate variants. I0203 17:23:04.933572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:2972,usability,command,command,2972,"ne. I0203 17:23:04.931699 137565708298048 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:04.933463 137565708298048 make_examples_core.py:301] Task 7/16: Found 0 candidate variants. I0203 17:23:04.933572 137565708298048 make_examples_core.py:301] Task 7/16: Created 0 examples. I0203 17:23:09.199501 136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3311,usability,User,UserWarning,3311,"136895166957376 make_examples_core.py:301] Task 13/16: Writing example info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/769:3423,usability,minim,minimal,3423,"mple info to /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord-00013-of-00016.gz.example_info.json. I0203 17:23:09.199875 136895166957376 make_examples_core.py:2958] example_shape = None. I0203 17:23:09.200180 136895166957376 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 7, 9, 10]. I0203 17:23:09.201941 136895166957376 make_examples_core.py:301] Task 13/16: Found 0 candidate variants. I0203 17:23:09.202048 136895166957376 make_examples_core.py:301] Task 13/16: Created 0 examples. real 112m20.375s. user 1760m59.767s. sys 11m47.541s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/call_variants_output.tfrecord.gz"" --examples ""/cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0203 17:23:14.218397 132068663560000 call_variants.py:471] Total 1 writing processes started. W0203 17:23:14.224790 132068663560000 call_variants.py:482] Unable to read any records from /cromwell_root/tmp.cd83af44/tmpuzrx3yrs/make_examples.tfrecord@16.gz. Output will contain zero records. I0203 17:23:14.225926 132068663560000 call_variants.py:623] Complete: call_variants. ```. And then the program hangs there for 10+ hours (UTC time when I'm reporting is Feb. 04, 04:05, and the program still appears running). . We've observed this for both ONT and HiFi data on multiple samples, further suggesting this isn't a data issue. Thanks! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/769
https://github.com/google/deepvariant/issues/770:439,deployability,Version,Version,439,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:462,deployability,Version,Version,462,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:41,integrability,FILTER,FILTER,41,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:174,integrability,FILTER,FILTER,174,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:439,integrability,Version,Version,439,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:462,integrability,Version,Version,462,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:799,integrability,filter,filter,799,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:845,integrability,FILTER,FILTER,845,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:439,modifiability,Version,Version,439,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:462,modifiability,Version,Version,462,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:33,security,control,control,33,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:33,testability,control,control,33,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:408,usability,Tool,Toolkit,408,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:752,usability,support,support,752,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/770:791,usability,user,user,791,"How could I set any threshold to control FILTER column which PASS or RefCall?; Hi,. I have two problem about this:. First question, this picture is VCF line, this position's FILTER is RefCall called by deepvariant:1.6.0 (docker's image). ![Pasted image 20240131162641](https://github.com/google/deepvariant/assets/91660863/9767d632-c188-459a-8146-9d7829dbf519). And GATK4-HaplotypeCaller（The Genome Analysis Toolkit (GATK) v4.2.6.1,HTSJDK Version: 2.24.1,Picard Version: 2.27.1) Call the same position Like follow:. `chr5 147499874 . G GA 52.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=-2.210;DP=61;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=0.86;ReadPosRankSum=2.170;SOR=0.846 GT:AD:DP:GQ:PL 0/1:52,9:61:60:60,0,1625`. Why not support INFO column in deepvariant for user to filter snp or indel by them, how could I make FILTER=PASS ? Last question, Why deepvariant call this position's QUAL is zero, and GATK call this position's QUAL is 52.60? which is more accurate?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/770
https://github.com/google/deepvariant/issues/771:708,availability,error,error,708,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:297,deployability,modul,module,297,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:839,deployability,modul,module,839,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:890,deployability,Modul,ModuleNotFoundError,890,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:914,deployability,modul,module,914,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:985,deployability,instal,install,985,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:304,energy efficiency,load,load,304,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:297,modifiability,modul,module,297,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:839,modifiability,modul,module,839,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:890,modifiability,Modul,ModuleNotFoundError,890,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:914,modifiability,modul,module,914,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:304,performance,load,load,304,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:708,performance,error,error,708,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:942,reliability,Doe,Does,942,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:297,safety,modul,module,297,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:708,safety,error,error,708,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:839,safety,modul,module,839,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:890,safety,Modul,ModuleNotFoundError,890,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:914,safety,modul,module,914,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:724,testability,Trace,Traceback,724,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:43,usability,experien,experiencing,43,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/771:708,usability,error,error,708,"Issue calling make_examples.py; Hello! I'm experiencing an issue when trying to run make_examples. Instead of Docker we're using Singularity, and deepvariant has run before with just calling the run_deepvariant.py. . For example, this is what has worked for us in the past in our environment: . > module load singularity. > source activate $condapath/DeepVariant. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/run_deepvariant.py [...]. When trying to run make_examples, this code:. > singularity exec $softwarepath/Singularity_files/deepvariant_1.5.0.sif python3 $softwarepath/deepvariant/deepvariant/make_examples.py [...] . is now throwing this error code: . > Traceback (most recent call last):. > File ""/$softwarepath/deepvariant/deepvariant/make_examples.py"", line 35, in <module>. > from deepvariant import dv_constants. > ModuleNotFoundError: No module named 'deepvariant'. Does this mean there is a problem with our install? Any ideas or suggestions? . Thank you very much for any light you can shed on this issue! Best, . Haley .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/771
https://github.com/google/deepvariant/issues/772:0,modifiability,Maintain,Maintain,0,"Maintain Barcode in Output; When running deepvariant on single cell Pacbio longread data, is it possible to have the output include the barcode where the SNP was found? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/772
https://github.com/google/deepvariant/issues/772:68,modifiability,Pac,Pacbio,68,"Maintain Barcode in Output; When running deepvariant on single cell Pacbio longread data, is it possible to have the output include the barcode where the SNP was found? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/772
https://github.com/google/deepvariant/issues/772:0,safety,Maintain,Maintain,0,"Maintain Barcode in Output; When running deepvariant on single cell Pacbio longread data, is it possible to have the output include the barcode where the SNP was found? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/772
https://github.com/google/deepvariant/issues/773:237,availability,Operat,Operating,237,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:921,availability,Error,Error,921,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3766,availability,error,error,3766,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:276,deployability,version,version,276,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:293,deployability,Instal,Installation,293,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3151,deployability,Fail,Failed,3151," Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3386,deployability,fail,failedCould,3386,"34845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4258,deployability,modul,module,4258,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4505,deployability,Fail,Failed,4505,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:1444,energy efficiency,cpu,cpus,1444,"ingularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2680,energy efficiency,CPU,CPUs,2680,"72254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3568,energy efficiency,core,core,3568,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3782,energy efficiency,Current,Current,3782,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:276,integrability,version,version,276,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:463,integrability,pub,public,463,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2556,integrability,Transform,Transforming,2556,"gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2716,integrability,transform,transformation,2716,"_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2556,interoperability,Transform,Transforming,2556,"gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2716,interoperability,transform,transformation,2716,"_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:276,modifiability,version,version,276,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4258,modifiability,modul,module,4258,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:921,performance,Error,Error,921,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:1108,performance,time,time,1108,"le/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.31017",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:1444,performance,cpu,cpus,1444,"ingularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2680,performance,CPU,CPUs,2680,"72254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:2689,performance,parallel,parallelization,2689,"sh: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 17:31:47.310170: I deepvariant/postprocess_variants.cc:94] Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_gen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3766,performance,error,error,3766,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3151,reliability,Fail,Failed,3151," Read from: /public1/home/yinhang/data/tmp/SRR1572254/call_variants_output-00000-of-00001.tfrecord.gz. 2024-02-17 17:33:25.282554: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 18154823. I0217 17:38:26.134845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3386,reliability,fail,failedCould,3386,"34845 139808123168576 postprocess_variants.py:1313] CVO sorting took 6.647122502326965 minutes. I0217 17:38:26.135649 139808123168576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4505,reliability,Fail,Failed,4505,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:921,safety,Error,Error,921,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:995,safety,Compl,Complete,995,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3766,safety,error,error,3766,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4258,safety,modul,module,4258,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:995,security,Compl,Complete,995,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:927,testability,trace,trace,927,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4333,testability,context,context,4333,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:386,usability,Command,Command,386,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:921,usability,Error,Error,921,"The step of postprocess_variants cannot find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:1038,usability,user,user,1038,"find the VCF file; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:1093,usability,command,command,1093,"thub.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**. The step of postprocess_variants cannot find the VCF file. - Operating system:Centos. - DeepVariant version:1.6.0. - Installation method :singularity. - Type of data: (NGS sequence). **Steps to reproduce:**. - Command:. mkdir /public1/home/yinhang/data/tmp/${SAMPLE}/. singularity exec /public/software/apps/deepvariant-1.6.0-cpu_singularity/deepvariant-1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${ref_genome} \. --reads=""${SORTED_BAM_DIR}/${SAMPLE}/${SAMPLE}.sorted.bam"" \. --output_vcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.vcf.gz"" \. --output_gvcf=""${VCF_DIR}/${SAMPLE}/${SAMPLE}.g.vcf.gz"" \. --intermediate_results_dir=/public1/home/yinhang/data/tmp/${SAMPLE}/ \. --num_shards=60 \. --sample_name ${SAMPLE}. - Error trace:. I0217 17:31:41.680527 139931052529472 call_variants.py:623] Complete: call_variants. real	339m11.258s. user	13508m55.048s. sys	183m10.091s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/public1/home/yinhang/projects/two_genomes/04_T2T/04_ragtag/03_syri/01_data/SH_N0.fasta"" --infile ""/public1/home/yinhang/data/tmp/SRR1572254/call_variants_output.tfrecord.gz"" --outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" --cpus ""60"" --gvcf_outfile ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/public1/home/yinhang/data/tmp/SRR1572254/gvcf.tfrecord@60.gz"" --sample_name ""SRR1572254"". /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). /bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8). I0217 17:31:47.293663 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:31:47.294324 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. 2024-02-17 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3573,usability,statu,statusor,3573,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3596,usability,statu,status,3596,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3612,usability,statu,status,3612,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:3766,usability,error,error,3766,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/773:4284,usability,user,user,4284,"ng call_variants_output to variants. I0217 17:38:26.135714 139808123168576 postprocess_variants.py:1318] Using 60 CPUs for parallelization of variant transformation. I0217 17:39:46.024054 139808123168576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: SRR1572254. I0217 17:39:46.024466 139808123168576 postprocess_variants.py:1216] --sample_name is set but was not used. I0217 17:53:05.493927 139808123168576 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 7.4284539779027305 minutes. [E::hts_open_format] Failed to open file ""/public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz"" : No such file or directory. 2024-02-17 17:53:05.496309: E third_party/nucleus/io/merge_variants.cc:115] opening writer failedCould not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. 2024-02-17 17:53:05.496469: F ./third_party/nucleus/core/statusor.h:230] Non-OK-status: status_ status: UNKNOWN: Could not open variants_path: /public1/home/yinhang/projects/two_genomes/04_T2T/11_snp/03_vcf/SRR1572254/SRR1572254.vcf.gz. Fatal Python error: Aborted. Current thread 0x00007f279d84a740 (most recent call first):. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1391 in main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vibz8587/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419 in <module>. real	27m34.677s. user	18m45.707s. sys	4m47.747s. **Any additional context:**. ![image](https://github.com/google/deepvariant/assets/108465040/18d9cc45-ef3a-4f05-8a85-19eefac74034). call_variants may be have done ,but postprocess_variants Failed to open file ""file.vcf.gz"" : No such file or directory",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/773
https://github.com/google/deepvariant/issues/774:8,availability,error,error,8,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1642,availability,error,errors,1642,"l_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2900,availability,avail,available,2900,"nt/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3207,availability,operat,operations,3207," \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3261,availability,operat,operations,3261,"weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4076,availability,error,error,4076,"ary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7705,availability,error,error,7705,"/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8562,availability,error,error,8562,"2-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_cor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9111,availability,error,error,9111,"33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_read",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13201,availability,checkpoint,checkpoint,13201,"301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14050,availability,mainten,maintenance,14050,"ant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". ___________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14134,availability,down,downstream,14134," --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". ______________________________________________________________________________________________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14508,availability,error,error,14508,"usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16127,availability,checkpoint,checkpoint,16127,"___________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18634,availability,error,error,18634,"ants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20553,availability,error,error,20553,"59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:461,deployability,version,version,461,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1065,deployability,version,version,1065,"tructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2497,deployability,Version,Version,2497,"01.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2513,deployability,Contain,Container,2513,"output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2613,deployability,contain,container,2613,"It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2687,deployability,Contain,Container,2687,"(part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2731,deployability,contain,container,2731,"limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_util",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2850,deployability,contain,container-license,2850,"\. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2918,deployability,contain,container,2918,"iant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2939,deployability,CONTAIN,CONTAINER-LICENSE,2939,"\. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3910,deployability,instal,installed,3910,"is container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4025,deployability,fail,failed,4025,"tform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4923,deployability,fail,failed,4923,"ly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are sup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5373,deployability,instal,installed,5373," input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.10850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5487,deployability,fail,failed,5487,"er. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5937,deployability,instal,installed,5937,"ng: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singular",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6602,deployability,instal,installed,6602,"""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7203,deployability,instal,installed,7203," cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7654,deployability,fail,failed,7654,"rflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.comple",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8511,deployability,fail,failed,8511,"local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I021",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9060,deployability,fail,failed,9060,"60.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13827,deployability,instal,installed,13827,"19 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14066,deployability,releas,release,14066,"ariants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". _________________________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14163,deployability,depend,dependencies,14163,"make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14457,deployability,fail,failed,14457,"file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . =================================================",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18468,deployability,instal,installed,18468,"** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18583,deployability,fail,failed,18583,"sis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20387,deployability,instal,installed,20387,"06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20502,deployability,fail,failed,20502,"CF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21134,deployability,Version,Version,21134,"2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |========================================================================",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21159,deployability,Version,Version,21159,"0: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22635,deployability,version,version,22635," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:37,energy efficiency,gpu,gpu,37,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:242,energy efficiency,gpu,gpu,242,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:457,energy efficiency,CPU,CPU,457,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:829,energy efficiency,cpu,cpu,829,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:901,energy efficiency,cpu,cpu,901,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1061,energy efficiency,GPU,GPU,1061,"he instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1201,energy efficiency,gpu,gpu,1201,"ariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1442,energy efficiency,gpu,gpu,1442,t runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migra,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1514,energy efficiency,gpu,gpu,1514, \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Con,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1653,energy efficiency,GPU,GPU,1653," \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are gover",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1880,energy efficiency,gpu,gpu,1880,"pu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of thi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2121,energy efficiency,gpu,gpu,2121,"nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Net",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2193,energy efficiency,gpu,gpu,2193,"1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3020,energy efficiency,core,core,3020,".complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:26",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3086,energy efficiency,optim,optimized,3086,"apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3166,energy efficiency,CPU,CPU,3166,"iner_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3444,energy efficiency,load,load,3444,"on.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3832,energy efficiency,GPU,GPU,3832,"a-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4333,energy efficiency,model,model,4333,"-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LAN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4374,energy efficiency,load,load,4374,"er/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and ins",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6136,energy efficiency,load,load,6136,".UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with Tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6524,energy efficiency,GPU,GPU,6524,"t your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6737,energy efficiency,load,load,6737," 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 14053",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7125,energy efficiency,GPU,GPU,7125,"ould not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7338,energy efficiency,load,load,7338,"rity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13361,energy efficiency,load,load,13361,"1] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13749,energy efficiency,GPU,GPU,13749,"18 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15009,energy efficiency,model,model,15009,"w features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15023,energy efficiency,Model,Model,15023,"A has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15794,energy efficiency,model,model,15794,"f input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16230,energy efficiency,Alloc,Allocation,16230,"=========================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16371,energy efficiency,Alloc,Allocation,16371,"one, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16490,energy efficiency,Predict,Predicted,16490,"==============. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16629,energy efficiency,Alloc,Allocation,16629,"_____________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16770,energy efficiency,Alloc,Allocation,16770," UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16910,energy efficiency,Alloc,Allocation,16910,"magenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17030,energy efficiency,Predict,Predicted,17030,"s: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17150,energy efficiency,Predict,Predicted,17150,"2-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17272,energy efficiency,Predict,Predicted,17272,"stem memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17710,energy efficiency,gpu,gpu,17710,"445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Usi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17731,energy efficiency,cpu,cpus,17731,"/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17794,energy efficiency,gpu,gpu,17794,"ceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18002,energy efficiency,load,load,18002,"536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18390,energy efficiency,GPU,GPU,18390,"] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19080,energy efficiency,CPU,CPUs,19080,"open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19721,energy efficiency,gpu,gpu,19721,"ame from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19793,energy efficiency,gpu,gpu,19793," 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. -------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19921,energy efficiency,load,load,19921,"04 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ---------------------------------------------------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20309,energy efficiency,GPU,GPU,20309,"ess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Unc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20667,energy efficiency,gpu,gpu,20667,"t --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+---------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20964,energy efficiency,GPU,GPUs,20964,"; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +--------------------------------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21259,energy efficiency,GPU,GPU,21259,"orRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ..",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21369,energy efficiency,GPU,GPU-Util,21369,ned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22002,energy efficiency,GPU,GPU,22002," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22034,energy efficiency,GPU,GPU,22034," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22903,energy efficiency,GPU,GPU,22903," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:461,integrability,version,version,461,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1065,integrability,version,version,1065,"tructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2497,integrability,Version,Version,2497,"01.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4577,integrability,buffer,buffer,4577,"IBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14163,integrability,depend,dependencies,14163,"make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14187,integrability,repositor,repositories,14187,"6.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16519,integrability,batch,batches,16519,": 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17061,integrability,batch,batches,17061,"40119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcubl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17183,integrability,batch,batches,17183,"ow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17305,integrability,batch,batches,17305,".566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18956,integrability,Transform,Transforming,18956,"orm/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19116,integrability,transform,transformation,19116,"directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21134,integrability,Version,Version,21134,"2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |========================================================================",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21159,integrability,Version,Version,21159,"0: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22635,integrability,version,version,22635," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3025,interoperability,platform,platform,3025,"te_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] fail",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3399,interoperability,platform,platform,3399,"r.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.99535",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3529,interoperability,share,shared,3529,"yright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5434,interoperability,standard,standard,5434," results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5998,interoperability,standard,standard,5998,"_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6091,interoperability,platform,platform,6091,"NETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6221,interoperability,share,shared,6221,"SUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6692,interoperability,platform,platform,6692,"US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6822,interoperability,share,shared,6822,"_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7293,interoperability,platform,platform,7293,"vidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7423,interoperability,share,shared,7423,"ils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13316,interoperability,platform,platform,13316,"59 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13446,interoperability,share,shared,13446,"1606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14187,interoperability,repositor,repositories,14187,"6.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16138,interoperability,specif,specified,16138,". Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17957,interoperability,platform,platform,17957," memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Trans",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18087,interoperability,share,shared,18087,"I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18956,interoperability,Transform,Transforming,18956,"orm/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19116,interoperability,transform,transformation,19116,"directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19876,interoperability,platform,platform,19876,"inutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. --------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20006,interoperability,share,shared,20006,"00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:461,modifiability,version,version,461,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1065,modifiability,version,version,1065,"tructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2497,modifiability,Version,Version,2497,"01.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4172,modifiability,interm,intermediate,4172,"ions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4426,modifiability,Interm,Intermediate,4426,"] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10005,modifiability,deco,decode,10005,"mpiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10397,modifiability,deco,decode,10397,"enomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Tas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11636,modifiability,deco,decode,11636,"606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13877,modifiability,pac,packages,13877,"91938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14163,modifiability,depend,dependencies,14163,"make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15145,modifiability,Layer,Layer,15145,"raries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15727,modifiability,pac,packages,15727,"mple_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21134,modifiability,Version,Version,21134,"2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |========================================================================",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21159,modifiability,Version,Version,21159,"0: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22635,modifiability,version,version,22635," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8,performance,error,error,8,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:37,performance,gpu,gpu,37,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:242,performance,gpu,gpu,242,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:457,performance,CPU,CPU,457,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:829,performance,cpu,cpu,829,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:901,performance,cpu,cpu,901,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1061,performance,GPU,GPU,1061,"he instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1201,performance,gpu,gpu,1201,"ariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1442,performance,gpu,gpu,1442,t runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migra,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1514,performance,gpu,gpu,1514, \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Con,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1642,performance,error,errors,1642,"l_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1653,performance,GPU,GPU,1653," \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are gover",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1880,performance,gpu,gpu,1880,"pu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of thi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2121,performance,gpu,gpu,2121,"nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Net",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2193,performance,gpu,gpu,2193,"1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2637,performance,content,contents,2637," errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3086,performance,optimiz,optimized,3086,"apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3120,performance,Network,Network,3120,".output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3166,performance,CPU,CPU,3166,"iner_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3186,performance,perform,performance-critical,3186,".output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3444,performance,load,load,3444,"on.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3832,performance,GPU,GPU,3832,"a-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4076,performance,error,error,4076,"ary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4374,performance,load,load,4374,"er/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and ins",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4533,performance,time,time,4533," object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4549,performance,parallel,parallel,4549,"uch file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	L",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6136,performance,load,load,6136,".UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with Tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6524,performance,GPU,GPU,6524,"t your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:6737,performance,load,load,6737," 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 14053",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7125,performance,GPU,GPU,7125,"ould not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7338,performance,load,load,7338,"rity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7705,performance,error,error,7705,"/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8562,performance,error,error,8562,"2-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_cor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9111,performance,error,error,9111,"33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_read",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11290,performance,Overhead,Overhead,11290,"ing from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:12377,performance,Overhead,Overhead,12377,"es_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13038,performance,time,time,13038,"xamples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13361,performance,load,load,13361,"1] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13749,performance,GPU,GPU,13749,"18 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14508,performance,error,error,14508,"usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16282,performance,memor,memory,16282,"=======. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16422,performance,memor,memory,16422,"====================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16519,performance,batch,batches,16519,": 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16681,performance,memor,memory,16681,"___________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_appt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16821,performance,memor,memory,16821,"nput channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16962,performance,memor,memory,16962,"923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17061,performance,batch,batches,17061,"40119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcubl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17183,performance,batch,batches,17183,"ow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17305,performance,batch,batches,17305,".566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17503,performance,time,time,17503,"examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17710,performance,gpu,gpu,17710,"445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Usi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17731,performance,cpu,cpus,17731,"/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17794,performance,gpu,gpu,17794,"ceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18002,performance,load,load,18002,"536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18390,performance,GPU,GPU,18390,"] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18634,performance,error,error,18634,"ants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19080,performance,CPU,CPUs,19080,"open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19089,performance,parallel,parallelization,19089,"ect file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19628,performance,time,time,19628,"own error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19721,performance,gpu,gpu,19721,"ame from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19793,performance,gpu,gpu,19793," 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. -------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:19921,performance,load,load,19921,"04 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ---------------------------------------------------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20309,performance,GPU,GPU,20309,"ess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Unc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20553,performance,error,error,20553,"59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20667,performance,gpu,gpu,20667,"t --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+---------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20964,performance,GPU,GPUs,20964,"; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +--------------------------------------------------------------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21259,performance,GPU,GPU,21259,"orRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ..",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21354,performance,Memor,Memory-Usage,21354,raries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:21369,performance,GPU,GPU-Util,21369,ned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22002,performance,GPU,GPU,22002," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22034,performance,GPU,GPU,22034," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22038,performance,Memor,Memory,22038," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22903,performance,GPU,GPU,22903," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2900,reliability,availab,available,2900,"nt/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4025,reliability,fail,failed,4025,"tform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4923,reliability,fail,failed,4923,"ly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are sup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5487,reliability,fail,failed,5487,"er. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7654,reliability,fail,failed,7654,"rflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.comple",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8511,reliability,fail,failed,8511,"local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I021",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9060,reliability,fail,failed,9060,"60.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13201,reliability,checkpoint,checkpoint,13201,"301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14050,reliability,mainten,maintenance,14050,"ant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". ___________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14457,reliability,fail,failed,14457,"file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . =================================================",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16127,reliability,checkpoint,checkpoint,16127,"___________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18583,reliability,fail,failed,18583,"sis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20502,reliability,fail,failed,20502,"CF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8,safety,error,error,8,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:303,safety,compl,complete,303,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:401,safety,compl,complete-,401,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:441,safety,test,test,441,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:523,safety,input,input,523,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:530,safety,input,input,530,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:719,safety,input,input,719,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:968,safety,input,input,968,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1132,safety,input,input,1132,"epvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1139,safety,input,input,1139,"nt/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1332,safety,input,input,1332,(https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; c,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1581,safety,input,input,1581,"t_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1642,safety,error,errors,1642,"l_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1811,safety,input,input,1811,"G001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1818,safety,input,input,1818,"ptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2011,safety,input,input,2011,"ccessful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2260,safety,input,input,2260,"e=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2373,safety,compl,complete,2373,"8.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2900,safety,avail,available,2900,"nt/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4076,safety,error,error,4076,"ary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4379,safety,input,input,4379,"/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4694,safety,input,input,4694,"flow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_U",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7705,safety,error,error,7705,"/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7782,safety,input,input,7782,"lerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Ta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7948,safety,input,inputs,7948,"s. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8026,safety,input,input,8026,"s.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_exe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8562,safety,error,error,8562,"2-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_cor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8639,safety,input,input,8639,"ver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8804,safety,input,inputs,8804,"100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8882,safety,input,input,8882,"0533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9111,safety,error,error,9111,"33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_read",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9188,safety,input,input,9188,"ntigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9353,safety,input,inputs,9353,"chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9431,safety,input,input,9431,"5.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9980,safety,input,input,9980,"5.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10133,safety,input,input,10133,"323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Wr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10372,safety,input,input,10372,".967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10525,safety,input,input,10525,"448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10678,safety,input,input,10678,"r10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10827,safety,input,input,10827,"3:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with Nati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11313,safety,input,inputs,11313,"_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11611,safety,input,input,11611,"23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11764,safety,input,input,11764,"3:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.3021",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:11913,safety,input,input,11913,"3:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00015-of-00016.gz. I0217 23:33:34.888697 140533724936000 make_examples_core.py:301] Task 15/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.912838 140533724936000 make_examples_core.py:301] Task 15/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:12400,safety,input,inputs,12400,"5/16: 0 candidates (0 examples) [0.02s elapsed]. I0217 23:33:35.455924 139726133032768 make_examples_core.py:301] Task 4/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:35.526908 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:35.675196 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.810906 140099871606592 make_examples_core.py:301] Task 0/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00000-of-00016.gz. I0217 23:33:34.811542 140099871606592 make_examples_core.py:301] Task 0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:13213,safety,input,input,13213,"0/16: Writing examples to /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz. I0217 23:33:34.811659 140099871606592 make_examples_core.py:301] Task 0/16: Overhead for preparing inputs: 8 seconds. I0217 23:33:34.827609 140099871606592 make_examples_core.py:301] Task 0/16: 0 candidates (0 examples) [0.02s elapsed]. ... I0218 00:34:18.301548 140191938357056 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0218 00:34:18.301738 140191938357056 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:18.302148 140191938357056 make_examples_core.py:301] Task 3/16: Found 9819 candidate variants. I0218 00:34:18.302218 140191938357056 make_examples_core.py:301] Task 3/16: Created 10372 examples. real	62m19.124s. user	928m53.495s. sys	2m16.403s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14163,safety,depend,dependencies,14163,"make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14508,safety,error,error,14508,"usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14756,safety,input,input,14756,"ensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/ince",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14799,safety,input,input,14799,"ries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14908,safety,input,input,14908,"fa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15303,safety,Input,InputLayer,15303,"b.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15823,safety,input,input,15823,", 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15884,safety,input,input,15884,"nts.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:16490,safety,Predict,Predicted,16490,"==============. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17030,safety,Predict,Predicted,17030,"s: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17150,safety,Predict,Predicted,17150,"2-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17272,safety,Predict,Predicted,17272,"stem memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17394,safety,Compl,Complete,17394,"eeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:18634,safety,error,error,18634,"ants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:10.043945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:10.133844 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:12.163552 139719065552704 postprocess_variants.py:1313] CVO sorting took 0.03374857902526855 minutes. I0218 00:48:12.163919 139719065552704 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0218 00:48:12.163960 139719065552704 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation. I0218 00:48:12.684920 139719065552704 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: HG001. I0218 00:48:18.996037 139719065552704 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.06664579312006633 minutes. I0218 00:48:39.012242 139719065552704 postprocess_variants.py:1407] Finished writing VCF and gVCF in 0.33359973033269247 minutes. real	0m59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:20553,safety,error,error,20553,"59.941s. user	0m58.218s. sys	0m5.086s. ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --outfile_base ""output_apptainer_gpu/HG001.apptainer.gpu.output"". 2024-02-18 00:48:50.006549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:48:50.008250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-18 00:48:57.417490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:48:57.421117 139673283618624 genomics_reader.py:222] Reading output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz with NativeVcfReader. real	0m23.982s. user	0m12.056s. sys	0m2.006s. ```. ----------------------------------------------------------------------------------. ----------------------------------------------------------------------------------. My system is Ubuntu 22.04. I have two GPUs. . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:303,security,compl,complete,303,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:401,security,compl,complete-,401,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2373,security,compl,complete,2373,"8.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2650,security,govern,governed,2650,"PU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2900,security,availab,available,2900,"nt/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3120,security,Network,Network,3120,".output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4333,security,model,model,4333,"-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LAN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14127,security,modif,modify,14127,"ecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". _____________________________________________________________________________________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15009,security,model,model,15009,"w features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15023,security,Model,Model,15023,"A has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:15794,security,model,model,15794,"f input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shape Param # Connected to . ==================================================================================================. input_1 (InputLayer) [(None, 100, 221, 7 0 [] . )] . ... classification (Dense) (None, 3) 6147 ['dropout[0][0]'] . . ==================================================================================================. Total params: 21,810,083. Trainable params: 21,775,651. Non-trainable params: 34,432. __________________________________________________________________________________________________. /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0218 00:34:52.923406 140119155529536 keras_modeling.py:325] Number of l2 regularizers: 95. I0218 00:34:52.923618 140119155529536 keras_modeling.py:337] inceptionv3: No initial checkpoint specified. 2024-02-18 00:34:57.911320: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:34:58.566676: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:17394,security,Compl,Complete,17394,"eeds 10% of free system memory. I0218 00:35:01.595164 140119155529536 call_variants.py:583] Predicted 1024 examples in 1 batches [0.637 sec per 100]. 2024-02-18 00:35:02.648043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. 2024-02-18 00:35:03.234445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 842268672 exceeds 10% of free system memory. 2024-02-18 00:35:07.222464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1330642944 exceeds 10% of free system memory. I0218 00:38:56.687749 140119155529536 call_variants.py:583] Predicted 52224 examples in 51 batches [0.463 sec per 100]. I0218 00:42:59.116032 140119155529536 call_variants.py:583] Predicted 103424 examples in 101 batches [0.468 sec per 100]. I0218 00:46:58.822113 140119155529536 call_variants.py:583] Predicted 154624 examples in 151 batches [0.468 sec per 100]. I0218 00:47:39.156648 140119155529536 call_variants.py:623] Complete: call_variants. real	13m21.231s. user	118m36.634s. sys	25m56.983s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/tmpd74of138/call_variants_output.tfrecord.gz"" --outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"". 2024-02-18 00:47:52.195457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:47:52.196245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:22381,security,Team,TeamViewer,22381," . **nvidia-smi** . ``` . Sat Feb 17 23:40:49 2024 . +-----------------------------------------------------------------------------+. | NVIDIA-SMI 525.147.05 Driver Version: 525.147.05 CUDA Version: 12.0 |. |-------------------------------+----------------------+----------------------+. | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |. | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |. | | | MIG M. |. |===============================+======================+======================|. | 0 Quadro RTX 4000 On | 00000000:17:00.0 Off | N/A |. | 30% 27C P8 9W / 125W | 110MiB / 8192MiB | 0% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. | 1 Quadro P4000 On | 00000000:65:00.0 On | N/A |. | 46% 33C P0 28W / 105W | 1048MiB / 8192MiB | 1% Default |. | | | N/A |. +-------------------------------+----------------------+----------------------+. . +-----------------------------------------------------------------------------+. | Processes: |. | GPU GI CI PID Type Process name GPU Memory |. | ID ID Usage |. |=============================================================================|. | 0 N/A N/A 2236 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 3948 G /usr/lib/xorg/Xorg 4MiB |. | 0 N/A N/A 4070 C+G ...ome-remote-desktop-daemon 96MiB |. | 1 N/A N/A 2236 G /usr/lib/xorg/Xorg 21MiB |. | 1 N/A N/A 2504 G ...mviewer/tv_bin/TeamViewer 37MiB |. | 1 N/A N/A 3948 G /usr/lib/xorg/Xorg 509MiB |. | 1 N/A N/A 4182 G /usr/bin/gnome-shell 195MiB |. | 1 N/A N/A 11053 G uex 1MiB |. | 1 N/A N/A 1285104 G ...on=20240130-180151.247000 148MiB |. | 1 N/A N/A 1287635 G ...--variations-seed-version 19MiB |. +-----------------------------------------------------------------------------+. ```. I did run ```export CUDA_VISIBLE_DEVICES=0``` before running deepvariant, as you suggested in this issue https://github.com/google/deepvariant/issues/761. . Why the GPU was not used in my run? Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:441,testability,test,test,441,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14087,testability,plan,planned,14087,"mp/tmpd74of138/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". ______________________________________________",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:14163,testability,depend,dependencies,14163,"make_examples.tfrecord@16.gz"" --checkpoint ""input/weights-51-0.995354.ckpt"". 2024-02-18 00:34:28.767569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-18 00:34:28.768358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. 2024-02-18 00:34:45.482939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0218 00:34:45.513278 140119155529536 call_variants.py:471] Total 1 writing processes started. I0218 00:34:45.536368 140119155529536 dv_utils.py:365] From /tmp/tmpd74of138/make_examples.tfrecord-00000-of-00016.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0218 00:34:45.536543 140119155529536 call_variants.py:506] Shape of input examples: [100, 221, 7]. I0218 00:34:45.537125 140119155529536 call_variants.py:510] Use saved model: False. Model: ""inceptionv3"". __________________________________________________________________________________________________. Layer (type) Output Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8,usability,error,error,8,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:490,usability,command,command,490,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:523,usability,input,input,523,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:530,usability,input,input,530,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:719,usability,input,input,719,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:968,usability,input,input,968,"Running error with deepvariant_1.6.0-gpu.sif; Hi,. I followed the instructions on deepvariant quick start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1094,usability,command,command,1094,"k start (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptain",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1132,usability,input,input,1132,"epvariant/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1139,usability,input,input,1139,"nt/blob/r1.6/docs/deepvariant-quick-start.md) to create deepvariant_1.6.0.sif and deepvariant_1.6.0-gpu.sif successfully using apptainer. . Then, I followed the complete genomics T7 case study (https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1332,usability,input,input,1332,(https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md) to have some test runs. . 1. CPU version. I run the following command:. ```apptainer run \. -B input:/input \. -B output_apptainer_cpu:/output \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; c,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1581,usability,input,input,1581,"t_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1642,usability,error,errors,1642,"l_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_cpu/HG001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1811,usability,input,input,1811,"G001.apptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:1818,usability,input,input,1818,"ptainer.cpu.output.vcf.gz \. --output_gvcf=output_apptainer_cpu/HG001.apptainer.cpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It was successful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2011,usability,input,input,2011,"ccessful. Both vcf and gvcf were generated. 2. GPU version. I run the following command:. ```apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2260,usability,input,input,2260,"e=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. ```. It seems there are some errors and GPU was not used. These are the output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2678,usability,Learn,Learning,2678,"he output (part of the output were removed due to the limit of the characters of this post):. ```. ➜ t7 apptainer run --nv \. -B input:/input \. -B output_apptainer_gpu:/output \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:2841,usability,learn,learning-container-license,2841,"tput \. deepvariant_1.6.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=reference/GRCh38_no_alt_analysis_set.fasta \. --reads=input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam \. --output_vcf=output_apptainer_gpu/HG001.apptainer.gpu.output.vcf.gz \. --output_gvcf=output_apptainer_gpu/HG001.apptainer.gpu.output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, ple",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:3186,usability,perform,performance-critical,3186,".output.g.vcf.gz \. --num_shards=$(nproc) \. --customized_model=input/weights-51-0.995354.ckpt. INFO: /usr/local/etc/singularity/ exists; cleanup by system administrator is not complete (see https://apptainer.org/docs/admin/latest/singularity_migration.html). ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-02-17 23:31:25.687399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4076,usability,error,error,4076,"ary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-02-17 23:31:39.809521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4379,usability,input,input,4379,"/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4518,usability,command,command,4518,"t open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:31:39.810043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:4694,usability,input,input,4694,"flow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:31:59.620996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:31:59.623967 140288433825600 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpd74of138. I0217 23:31:59.629002 140288433825600 run_deepvariant.py:551] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_U",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5359,usability,support,supported,5359,"step will load input/weights-51-0.995354.ckpt* instead. ***** Intermediate results will be written to /tmp/tmpd74of138 in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam"" --examples ""/tmp/tmpd74of138/make_examples.tfrecord@16.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpd74of138/gvcf.tfrecord@16.gz"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:5923,usability,support,supported,5923,"d. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_TIME = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = ""en_US:en"",. 	LC_ALL = (unset),. 	LC_TIME = ""en_US.UTF-8"",. 	LC_MONETARY = ""en_US.UTF-8"",. 	LC_CTYPE = ""C.UTF-8"",. 	LC_ADDRESS = ""en_US.UTF-8"",. 	LC_TELEPHONE = ""en_US.UTF-8"",. 	LC_NAME = ""en_US.UTF-8"",. 	LC_MEASUREMENT = ""en_US.UTF-8"",. 	LC_IDENTIFICATION = ""en_US.UTF-8"",. 	LC_NUMERIC = ""en_US.UTF-8"",. 	LC_PAPER = ""en_US.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). 2024-02-17 23:32:31.107126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.108506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.006781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7705,usability,error,error,7705,"/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7782,usability,input,input,7782,"lerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Ta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:7948,usability,input,inputs,7948,"s. 2024-02-17 23:32:31.007601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8026,usability,input,input,8026,"s.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-02-17 23:32:31.110201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs. ... 2024-02-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_exe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8562,usability,error,error,8562,"2-17 23:33:25.887517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_cor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8639,usability,input,input,8639,"ver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933275 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8804,usability,input,inputs,8804,"100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939588 140533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:8882,usability,input,input,8882,"0533724936000 make_examples_core.py:301] Task 15/16: Preparing inputs. I0217 23:33:25.967685 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9111,usability,error,error,9111,"33:26.024591 140533724936000 make_examples_core.py:301] Task 15/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_read",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9188,usability,input,input,9188,"ntigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9353,usability,input,inputs,9353,"chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. 2024-02-17 23:33:25.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9431,usability,input,input,9431,"5.886408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933485 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.940178 139726133032768 make_examples_core.py:301] Task 4/16: Preparing inputs. I0217 23:33:25.967752 139726133032768 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... 2024-02-17 23:33:25.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:9980,usability,input,input,9980,"5.888518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error. I0217 23:33:25.933323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
https://github.com/google/deepvariant/issues/774:10133,usability,input,input,10133,"323 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:25.939591 140099871606592 make_examples_core.py:301] Task 0/16: Preparing inputs. I0217 23:33:25.967773 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:26.024448 140099871606592 make_examples_core.py:301] Task 0/16: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0217 23:33:34.679437 140533724936000 make_examples_core.py:301] Task 15/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.748554 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.253728 140616181937984 make_examples_core.py:301] Task 14/16: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0217 23:33:34.663679 140616181937984 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. ... I0217 23:33:34.663670 140099871606592 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.887505 140533724936000 genomics_reader.py:222] Reading input/HG001.complete_t7.E100030471QC960.grch38.chr20.bam with NativeSamReader. I0217 23:33:34.888105 140533724936000 make_examples_core.py:301] Task 15/16: Writing gvcf records to /tmp/tmpd74of138/gvcf.tfrecord-00015-of-00016.gz. I0217 23:33:34.888602 140533724936000 make_examples_core.py:301] Task 15/16: Wr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/774
