id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2371:5621,availability,error,error,5621,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:225,deployability,version,version,225,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:871,deployability,contain,contains,871,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1159,deployability,modul,module,1159,"reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_col",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1708,deployability,stack,stacklevel,1708,"pression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1719,deployability,stack,stacklevel,1719,"lsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5530,deployability,updat,updated,5530,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:79,energy efficiency,load,load,79,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:4018,energy efficiency,cloud,cloudpickle,4018,"pe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setupto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:225,integrability,version,version,225,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1678,integrability,wrap,wrapper,1678,"tics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1794,integrability,wrap,wrapper,1794,"ython3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in pars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:891,interoperability,specif,specification,891,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1678,interoperability,wrapper,wrapper,1678,"tics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1794,interoperability,wrapper,wrapper,1794,"ython3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in pars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:225,modifiability,version,version,225,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:812,modifiability,pac,packages,812,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1159,modifiability,modul,module,1159,"reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_col",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1363,modifiability,pac,packages,1363,"ttps://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1639,modifiability,pac,packages,1639,"an/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1838,modifiability,pac,packages,1838,"ook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:2308,modifiability,pac,packages,2308," 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:2757,modifiability,pac,packages,2757,"rgs, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 466 sheet_name=sheet_name,. 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:3268,modifiability,pac,packages,3268," ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykern",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:3507,modifiability,pac,packages,3507,"ands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 1456 DataFrame from the passed in Excel file. 1457 """""". -> 1458 return self._reader.parse(. 1459 sheet_name=sheet_name,. 1460 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:4149,modifiability,deco,decorator,4149,"e an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:4632,modifiability,pac,packaging,4632,"> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:79,performance,load,load,79,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:3987,performance,bottleneck,bottleneck,3987,"footer, convert_float, mangle_dupe_cols, **kwds). 632 . 633 if isinstance(asheetname, str):. --> 634 sheet = self.get_sheet_by_name(asheetname). 635 else: # assume an integer if not a string. 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name). 543 . 544 def get_sheet_by_name(self, name: str):. --> 545 self.raise_if_bad_sheet_by_name(name). 546 return self.book[name]. 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name). 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:. 569 if name not in self.sheet_names:. --> 570 raise ValueError(f""Worksheet named '{name}' not found""). 571 . 572 def parse(. ValueError: Worksheet named 'expression' not found]. ```. #### '1.9.1'. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5621,performance,error,error,5621,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:87,reliability,doe,does,87,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5642,reliability,doe,does,5642,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1159,safety,modul,module,1159,"reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_col",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5530,safety,updat,updated,5530,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5621,safety,error,error,5621,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5510,security,Session,Session,5510,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5530,security,updat,updated,5530,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1042,testability,Trace,Traceback,1042,"() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:185,usability,confirm,confirmed,185,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:268,usability,confirm,confirmed,268,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:359,usability,guid,guide,359,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:414,usability,minim,minimal-bug-reports,414,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:520,usability,Minim,Minimal,520,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:636,usability,User,Users,636,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:646,usability,Document,Documents,646,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:769,usability,User,Users,769,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:853,usability,User,UserWarning,853,"When reading in a .xlsx file with sc.read_excel() it says the sheet I asked to load in does not exist.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1211,usability,User,Users,1211,"the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1221,usability,Document,Documents,1221,"ersion of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ```. ```pytb. [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed. warn(msg). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>. ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype). 73 from pandas import read_excel. 74 . ---> 75 df = read_excel(fspath(filename), sheet). 76 X = df.values[:, 1:]. 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 309 stacklevel=stacklevel,. 310 ). --> 311 return func(*args, **kwargs). 312 . 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options). 463 . 464 try:. --> 465 data = io.parse(. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5170,usability,tool,toolz,5170,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5621,usability,error,error,5621,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5777,usability,user,user-images,5777,"0. scanpy 1.9.1. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.0. llvmlite 0.38.0. louvain 0.8.0. lxml 4.9.1. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.5. openpyxl 3.0.10. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xlrd 2.0.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-11-26 11:30]. </details>. When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2372:159,modifiability,paramet,parameters,159,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:436,modifiability,pac,package,436,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:241,testability,simpl,simple,241,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:679,testability,plan,plan,679,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:233,usability,tool,tool,233,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:241,usability,simpl,simple,241,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:257,usability,tool,tool,257,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:305,usability,tool,tools,305,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:405,usability,tool,tools,405,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/issues/2372:767,usability,support,support,767,"Multiprocess for sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing? Thanks! Best,. Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/pull/2374:94,availability,error,errors,94,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:87,performance,memor,memory,87,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:94,performance,error,errors,94,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:94,safety,error,errors,94,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:429,safety,review,review,429,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:429,testability,review,review,429,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:0,usability,Stop,Stop,0,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:87,usability,memor,memory,87,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:94,usability,error,errors,94,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:280,usability,guid,guidelines,280,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:311,usability,guid,guide,311,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:407,usability,workflow,workflow,407,"Stop ignoring batch_size in sc.external.pp.scanorama_integrate; This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/issues/2375:277,deployability,modul,module,277,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:142,integrability,batch,batch,142,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:277,modifiability,modul,module,277,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:370,modifiability,pac,packages,370,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:677,modifiability,pac,packages,677,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:974,modifiability,paramet,parameters,974,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:142,performance,batch,batch,142,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:277,safety,modul,module,277,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2375:203,testability,Trace,Traceback,203,"TypeError: bbknn() got an unexpected keyword argument 'n_trees'; Hello, When I use `sc.external.pp.bbknn(adata, batch_key='group')`, group is batch in my datasets. something wrongs :. ```pytb. TypeError Traceback (most recent call last). /tmp/ipykernel_173326/699274021.py in <module>. ----> 1 sc.external.pp.bbknn(adata, batch_key='group'). ~/.local/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py in bbknn(adata, batch_key, approx, metric, copy, n_pcs, trim, n_trees, use_faiss, set_op_mix_ratio, local_connectivity, **kwargs). 118 set_op_mix_ratio=set_op_mix_ratio,. 119 local_connectivity=local_connectivity,. --> 120 **kwargs,. 121 ). ~/.local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, use_rep, approx, use_annoy, metric, copy, **kwargs). 123 #call BBKNN proper. 124 	bbknn_out = bbknn_matrix(pca=pca, batch_list=batch_list, approx=approx,. --> 125 							 use_annoy=use_annoy, metric=params['metric'], **kwargs). 126 #store the parameters in .uns['neighbors']['params'], add use_rep and batch_key. 127 adata.uns['neighbors'] = {}. TypeError: bbknn() got an unexpected keyword argument 'n_trees'. ```. How to deal with it ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2375
https://github.com/scverse/scanpy/issues/2376:0,availability,Error,Error,0,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:85,availability,error,error,85,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1710,availability,error,error,1710,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1826,availability,error,error,1826,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2047,availability,error,error,2047,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:606,deployability,version,version,606,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:932,deployability,modul,module,932,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2104,deployability,Version,Versions,2104,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2153,deployability,log,logging,2153,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:606,integrability,version,version,606,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1330,integrability,wrap,wrapper,1330,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2104,integrability,Version,Versions,2104,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1330,interoperability,wrapper,wrapper,1330,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:262,modifiability,pac,packages,262,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:446,modifiability,pac,packages,446,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:606,modifiability,version,version,606,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:932,modifiability,modul,module,932,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1042,modifiability,pac,packages,1042," read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1552,modifiability,pac,packages,1552,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1859,modifiability,layer,layers,1859,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2104,modifiability,Version,Versions,2104,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:0,performance,Error,Error,0,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:85,performance,error,error,85,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1710,performance,error,error,1710,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1826,performance,error,error,1826,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2047,performance,error,error,2047,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:0,safety,Error,Error,0,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:85,safety,error,error,85,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:390,safety,except,except,390,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:397,safety,Except,Exception,397,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:804,safety,except,exception,804,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:823,safety,except,exception,823,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:905,safety,input,input-,905,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:932,safety,modul,module,932,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1710,safety,error,error,1710,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1826,safety,error,error,1826,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2047,safety,error,error,2047,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2153,safety,log,logging,2153,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2153,security,log,logging,2153,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:195,testability,Trace,Traceback,195,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:861,testability,Trace,Traceback,861,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2153,testability,log,logging,2153,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:0,usability,Error,Error,0,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:85,usability,error,error,85,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:905,usability,input,input-,905,"Error while reading h5ad file; When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1710,usability,error,error,1710,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1826,usability,error,error,1826,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1923,usability,Minim,Minimal,1923,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2047,usability,error,error,2047,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-17-97568eff5295> in <module>. ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 872 '1 positional argument'). 873 . --> 874 return dispatch(args[0].__class__)(*args, **kw). 875 . 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2377:30,availability,error,error,30,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:766,availability,error,error,766,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1051,availability,error,error,1051,".pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3672,availability,sli,slicing,3672,"ata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:199,deployability,version,version,199,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:796,deployability,contain,contains,796,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:993,deployability,contain,contains,993,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1124,deployability,contain,contains,1124,"dy been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. M",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1605,deployability,Automat,Automatically,1605,"pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2165,deployability,Automat,Automatically,2165,"nal.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2518,deployability,modul,module,2518,": UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 115",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4612,deployability,Version,Versions,4612,"em_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6789,deployability,updat,updated,6789," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1688,energy efficiency,Estimat,Estimated,1688,"canpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1777,energy efficiency,Estimat,Estimated,1777,"scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2248,energy efficiency,Estimat,Estimated,2248,"on3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 93",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2337,energy efficiency,Estimat,Estimated,2337,"ing to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3201,energy efficiency,core,core,3201," score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keya",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3466,energy efficiency,core,core,3466,"l last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3723,energy efficiency,core,core,3723,"ected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4028,energy efficiency,core,core,4028,"cores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4326,energy efficiency,core,core,4326,"f._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4898,energy efficiency,cloud,cloudpickle,4898,"index_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:199,integrability,version,version,199,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3141,integrability,batch,batch,3141,"ew_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_uniq",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4612,integrability,Version,Versions,4612,"em_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:199,modifiability,version,version,199,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1264,modifiability,pac,packages,1264,"on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1470,modifiability,pac,packages,1470,"oduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1824,modifiability,pac,packages,1824,"iginal adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2030,modifiability,pac,packages,2030,"ould trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet score",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2518,modifiability,modul,module,2518,": UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 115",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2621,modifiability,pac,packages,2621,"reshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3185,modifiability,pac,packages,3185,"old at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_rea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3450,modifiability,pac,packages,3450,"ost recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3707,modifiability,pac,packages,3707,"let_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4012,modifiability,pac,packages,4012,"the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4310,modifiability,pac,packages,4310,"931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4612,modifiability,Version,Versions,4612,"em_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:5030,modifiability,deco,decorator,5030,"dexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:5596,modifiability,pac,packaging,5596, ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:30,performance,error,error,30,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:766,performance,error,error,766,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1051,performance,error,error,1051,".pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3141,performance,batch,batch,3141,"ew_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_uniq",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4795,performance,bottleneck,bottleneck,4795,"ction of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:949,reliability,doe,does,949,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:3672,reliability,sli,slicing,3672,"ata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1151 raise ValueError(""Cannot index with multidimensional key""). 1152 . -> 1153 return self._getitem_iterable(key, axis=axis). 1154 . 1155 # nested tuple slicing. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis). 1091 . 1092 # A collection of keys. -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:30,safety,error,error,30,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:766,safety,error,error,766,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1051,safety,error,error,1051,".pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1105,safety,test,test,1105,"s issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1658,safety,Detect,Detected,1658,"e](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1698,safety,detect,detectable,1698,"/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2218,safety,Detect,Detected,2218,"```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2258,safety,detect,detectable,2258,"-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2518,safety,modul,module,2518,": UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 115",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6789,safety,updat,updated,6789," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1349,security,modif,modify,1349,"hewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1658,security,Detect,Detected,1658,"e](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1698,security,detect,detectable,1698,"/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1909,security,modif,modify,1909,"a). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2218,security,Detect,Detected,2218,"```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2258,security,detect,detectable,2258,"-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4824,security,certif,certifi,4824,"r, indexer = self._get_listlike_indexer(key, axis). 1094 return self.obj._reindex_with_indexers(. 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis). 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr). 1313 . -> 1314 self._validate_read_indexer(keyarr, indexer, axis). 1315 . 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis). 1375 . 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()). -> 1377 raise KeyError(f""{not_found} not in index""). 1378 . 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index"". ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. annoy NA. anyio NA. attr 21.2.0. autoreload NA. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6243,security,soc,socks,6243," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6769,security,Session,Session,6769," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6789,security,updat,updated,6789," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1105,testability,test,test,1105,"s issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1605,testability,Automat,Automatically,1605,"pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2165,testability,Automat,Automatically,2165,"nal.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2442,testability,Trace,Traceback,2442,"cal/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]. 253 . 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. <path>/lib/python3.9/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6165,testability,simpl,simplejson,6165," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:30,usability,error,error,30,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:159,usability,confirm,confirmed,159,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:242,usability,confirm,confirmed,242,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:333,usability,guid,guide,333,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:388,usability,minim,minimal-bug-reports,388,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:766,usability,error,error,766,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:846,usability,Minim,Minimal,846,"`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1051,usability,error,error,1051,".pp.filter_cells/genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1523,usability,User,UserWarning,1523,"due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data). I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error. ```python. import scanpy. adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2083,usability,User,UserWarning,2083," = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes. sc.external.pp.scrublet(test_adata, batch_key = ""label""). ```. ```pytb. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.16. Detected doublet rate = 6.4%. Estimated detectable doublet fraction = 61.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual. adata.var['n_cells'] = number. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Automatically set threshold at doublet score = 0.17. Detected doublet rate = 5.8%. Estimated detectable doublet fraction = 55.7%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 10.5%. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_2434661/1304834185.py in <module>. ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 250 # Now reset the obs to get the scrublet scores. 251 . --> 252 adata.obs = scrubbed_obs.loc[adata.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6165,usability,simpl,simplejson,6165," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6368,usability,tool,toolz,6368," certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. h5py 3.3.0. idna 3.2. igraph 0.10.2. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.23.3. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.9.0. llvmlite 0.37.0. markupsafe 2.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.2.0. nbclassic 0.4.8. nbformat 5.7.0. nbinom_ufunc NA. notebook_shim NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.11.0. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.8. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. pywt 1.1.1. requests 2.26.0. scipy 1.7.1. scrublet NA. seaborn 0.11.2. send2trash NA. session_info 1.0.0. settings NA. simplejson 3.17.6. six 1.16.0. skimage 0.18.3. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. websocket 1.4.2. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2022-12-04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2378:1061,availability,error,error,1061,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1254,availability,error,error,1254,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:0,deployability,modul,module,0,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:170,deployability,version,version,170,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:711,deployability,modul,module,711,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:770,deployability,Version,Versions,770,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1027,deployability,version,version,1027,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1094,deployability,version,version,1094,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1166,deployability,version,version,1166,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1196,deployability,updat,updated,1196,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1210,deployability,version,version,1210,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1637,deployability,log,logging,1637,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:170,integrability,version,version,170,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:770,integrability,Version,Versions,770,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1027,integrability,version,version,1027,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1094,integrability,version,version,1094,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1166,integrability,version,version,1166,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1210,integrability,version,version,1210,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:0,modifiability,modul,module,0,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:170,modifiability,version,version,170,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:645,modifiability,layer,layer,645,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:711,modifiability,modul,module,711,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:770,modifiability,Version,Versions,770,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1027,modifiability,version,version,1027,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1094,modifiability,version,version,1094,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1166,modifiability,version,version,1166,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1210,modifiability,version,version,1210,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1515,modifiability,pac,packages,1515,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1000,performance,time,time,1000,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1061,performance,error,error,1061,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1254,performance,error,error,1254,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:0,safety,modul,module,0,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:711,safety,modul,module,711,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1061,safety,error,error,1061,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1196,safety,updat,updated,1196,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1254,safety,error,error,1254,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1637,safety,log,logging,1637,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1196,security,updat,updated,1196,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1637,security,log,logging,1637,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1637,testability,log,logging,1637,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:130,usability,confirm,confirmed,130,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:213,usability,confirm,confirmed,213,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:304,usability,guid,guide,304,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:359,usability,minim,minimal-bug-reports,359,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:465,usability,Minim,Minimal,465,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:880,usability,learn,learn,880,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1061,usability,error,error,1061,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1254,usability,error,error,1254,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1831,usability,tool,tools,1831,"module 'scanpy' has no attribute 'experimental'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.experimental.pp.highly_variable_genes(. placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'. ). ```. ```pytb. AttributeError: module 'scanpy' has no attribute 'experimental'. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. . Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. . But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this. ```. /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/.  cli.py.  _compat.py.  datasets.  experimental.  external.  get.  __init__.py.  logging.py.  __main__.py.  _metadata.py.  metrics.  neighbors.  plotting.  preprocessing.  __pycache__.  queries.  readwrite.py.  _settings.py.  sim_models.  tools.  _utils. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/pull/2379:282,safety,review,review,282,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:282,testability,review,review,282,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:360,testability,verif,verified,360,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:133,usability,guid,guidelines,133,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:164,usability,guid,guide,164,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:260,usability,workflow,workflow,260,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:329,usability,document,documentation,329,"Spell out flavors in HVG, add scikit-misc requirement to docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I'd like to improve hvg selection documentation a bit. I haven't verified the docs yet.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/issues/2380:722,availability,error,error,722,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:198,deployability,version,version,198,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:198,integrability,version,version,198,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:42,interoperability,specif,specification,42,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:623,interoperability,specif,specify,623,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:198,modifiability,version,version,198,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:362,modifiability,paramet,parameters,362,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:722,performance,error,error,722,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:27,reliability,doe,does,27,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:722,safety,error,error,722,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:810,safety,input,input,810,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:158,usability,confirm,confirmed,158,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:241,usability,confirm,confirmed,241,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:722,usability,error,error,722,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:810,usability,input,input,810,"Using groups in sc.pl.umap does not allow specification of smaller palette; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2381:543,availability,down,downstream,543,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1987,availability,error,error,1987,"a = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:754,deployability,version,version,754,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1141,deployability,scale,scale,1141,"ologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2004,deployability,Version,Versions,2004,"mc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3960,deployability,updat,updated,3960,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:534,energy efficiency,optim,optimise,534,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1141,energy efficiency,scale,scale,1141,"ologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:754,integrability,version,version,754,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2004,integrability,Version,Versions,2004,"mc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3638,integrability,wrap,wrapt,3638,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:332,modifiability,paramet,parameters,332,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:754,modifiability,version,version,754,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1141,modifiability,scal,scale,1141,"ologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1786,modifiability,paramet,parameter,1786," have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2004,modifiability,Version,Versions,2004,"mc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2363,modifiability,deco,decorator,2363,"a.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2920,modifiability,pac,packaging,2920,"an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-gli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3806,modifiability,pac,packaged,3806,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:521,performance,perform,performed,521,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1141,performance,scale,scale,1141,"ologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1987,performance,error,error,1987,"a = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:290,reliability,doe,doesn,290,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1987,safety,error,error,1987,"a = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3960,safety,updat,updated,3960,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:2223,security,certif,certifi,2223,"=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3372,security,soc,socks,3372,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3940,security,Session,Session,3940,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3960,security,updat,updated,3960,"### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.8.1. session_info 1.0.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. sphinxcontrib NA. stack_data 0.4.0. tensorboard 2.11.0. tensorflow 2.11.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.5. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-12-15 16:32. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:521,usability,perform,performed,521,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:607,usability,behavi,behaviour,607,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:714,usability,confirm,confirmed,714,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:797,usability,confirm,confirmed,797,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:864,usability,Minim,Minimal,864,".obsp['distances'] matrix is not symmetric; I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing? Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sp. import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1987,usability,error,error,1987,"a = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000). sp.pp.log1p(data). sp.pp.highly_variable_genes(data, n_top_genes=2000) . sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ). sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}. for i in range(data.obsp['distances'].shape[0]):. num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column. #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors. #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column. ```. ```pytb. No error. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. etils 0.7.1. executing 0.10.0. flatbuffers 22.11.23. fsspec 2022.7.1. gast NA. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.16. jaxlib 0.3.15. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. keras 2.11.0. kiwisolver 1.4.3. leidenalg 0.9.0. llvmlite 0.38.1. louvain 0.8.0. lz4 4.0.2. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numexpr 2.8.3. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.2. parso 0.8.3. pexpect 4.8.0. pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2382:179,deployability,version,version,179,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:668,deployability,log,logging,668,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:824,deployability,Version,Versions,824,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:179,integrability,version,version,179,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:824,integrability,Version,Versions,824,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:1568,interoperability,platform,platformdirs,1568,"ing accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.6.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. yaml 5.4.1. zipp NA. zmq 24.0.1. -----. IPython 8.4.0. jupyter_client 7.4.8. jupyter_core 5.1.0. notebook 6.5.2. -----. Python 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]. Linux-5.4.0-1092-aws-x86_64-with-glibc2.27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:179,modifiability,version,version,179,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:824,modifiability,Version,Versions,824,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:1038,modifiability,deco,decorator,1038, sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpool,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:1473,modifiability,pac,packaging,1473,"ing accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.6.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. yaml 5.4.1. zipp NA. zmq 24.0.1. -----. IPython 8.4.0. jupyter_client 7.4.8. jupyter_core 5.1.0. notebook 6.5.2. -----. Python 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]. Linux-5.4.0-1092-aws-x86_64-with-glibc2.27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:35,reliability,doe,does,35,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:668,safety,log,logging,668,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:668,security,log,logging,668,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:668,testability,log,logging,668,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:139,usability,confirm,confirmed,139,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:222,usability,confirm,confirmed,222,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2382:435,usability,user,user-images,435,adata.var.sort_index(inplace=True) does not sort adata.X; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import matplotlib.pyplot as plt. sc.settings.verbosity = 3. sc.logging.print_header(). adata = sc.datasets.pbmc3k(). adata.to_df()['MPO'].sum(). adata.var.sort_index(inplace=True). adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.17.1. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. loompy 3.0.7. matplotlib 3.6.0. matplotlib_inline NA. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. numpy_groupies 0.9.19. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. scvelo 0.2.4. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.2. stack_data 0.2.0. stat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2383:1758,availability,error,error,1758," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:14,deployability,fail,failed,14,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:193,deployability,version,version,193,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1862,deployability,Version,Versions,1862," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:50,integrability,messag,message,50,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:193,integrability,version,version,193,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1729,integrability,messag,message,1729," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1862,integrability,Version,Versions,1862," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:50,interoperability,messag,message,50,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1729,interoperability,messag,message,1729," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:193,modifiability,version,version,193,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1862,modifiability,Version,Versions,1862," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1758,performance,error,error,1758," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:14,reliability,fail,failed,14,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1758,safety,error,error,1758," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:153,usability,confirm,confirmed,153,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:236,usability,confirm,confirmed,236,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:327,usability,guid,guide,327,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:382,usability,minim,minimal-bug-reports,382,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:488,usability,Minim,Minimal,488,"write anndata failed, pearson_residuals_df header message is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1758,usability,error,error,1758," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1972,usability,learn,learn,1972," is too large; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Write any anndata with pearson residuals in uns. ```python. ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'). ```. The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :. ```python. {'theta': 100,. 'clip': None,. 'computed_on': 'adata.X',. 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \. barcode . GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 . TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 . CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 . TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 . TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 . ... ... ... ... ... . CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 . CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 . AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 . TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 . ```. ```pytb. Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /. ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/pull/2384:167,availability,cluster,clustering,167,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:661,availability,down,downstream,661,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:700,availability,error,error,700,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:167,deployability,cluster,clustering,167,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:138,energy efficiency,Current,Currently,138,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:270,integrability,Sub,Subset,270,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:530,integrability,sub,subset,530,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:634,integrability,filter,filtering,634,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:30,modifiability,paramet,parameter,30,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:71,modifiability,paramet,parameter,71,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:700,performance,error,error,700,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:700,safety,error,error,700,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:626,security,control,control,626,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:626,testability,control,control,626,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:700,usability,error,error,700,"sc.tl.dendrogram 'var_names' -parameter bug fix; ### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**. - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**. - Subset of genes defined by `var_names` is now used. **In addition:**. - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix. - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis). - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`. - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct. - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/issues/2385:104,modifiability,paramet,parameters,104,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:381,modifiability,pac,package,381,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:186,testability,simpl,simple,186,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:178,usability,tool,tool,178,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:186,usability,simpl,simple,186,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:202,usability,tool,tool,202,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:250,usability,tool,tools,250,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2385:350,usability,tool,tools,350,"PyDESeq2 in scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`. Thanks,. Shams.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2386:15,availability,cluster,cluster,15,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:976,availability,down,down,976,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1279,availability,down,down,1279,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:5,deployability,fail,failed,5,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:15,deployability,cluster,cluster,15,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:233,deployability,scale,scale,233,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:708,deployability,version,version,708,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:966,deployability,fail,failed,966,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:233,energy efficiency,scale,scale,233,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:708,integrability,version,version,708,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:233,modifiability,scal,scale,233,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:292,modifiability,layer,layer,292,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:708,modifiability,version,version,708,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:815,modifiability,paramet,parameters,815,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1044,modifiability,pac,package,1044,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1264,modifiability,pac,package,1264,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:233,performance,scale,scale,233,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:5,reliability,fail,failed,5,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:966,reliability,fail,failed,966,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:54,usability,visual,visualization,54,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:612,usability,user,user-images,612,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:851,usability,user,user-images,851,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1066,usability,learn,learn,1066,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1319,usability,user,user-images,1319,"umap failed to cluster the cells; Hello. I tried umap visualization by:. ```. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0). sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'). ```. But the cells can't separate well. ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version. ```. anndata 0.7.5. scanpy 1.6.1. ```. I tried another small dataset with `scanpy` using the same parameters as before:. ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```. import umap. import umap.plot. mapper = umap.UMAP().fit(adata.X). umap.plot.points(mapper). ```. Now the original `umap` package can do down dimension very well:. ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason? Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2387:444,deployability,api,api,444,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:365,energy efficiency,core,cores,365,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:556,energy efficiency,CPU,CPUs,556,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:953,energy efficiency,core,cores,953,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:444,integrability,api,api,444,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:444,interoperability,api,api,444,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:556,performance,CPU,CPUs,556,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2387:589,performance,parallel,parallel,589,"`sc.external.pp.magic`: what is `n_jobs`'s default _really_?; [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.magic.html): . > n_jobs : [Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[[int](https://docs.python.org/3/library/functions.html#int)] (default: None). Number of threads to use in training. All cores are used by default. [magic docs](https://magic.readthedocs.io/en/stable/api.html):. > n_jobs (integer, optional, default: 1)  The number of jobs to use for the computation. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. scanpy code: . https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/external/pp/_magic.py#L164. https://github.com/scverse/scanpy/blob/536ed15bc73ab5d1131c0d530dd9d4f2dc9aee36/scanpy/_settings.py#L82. I'm guessing the scanpy docs are wrong when they say ""All cores are used by default."" ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2387
https://github.com/scverse/scanpy/issues/2388:198,modifiability,pac,package,198,Can I analyze `10X` Single Cell Multiome ATAC + Gene Expression data using `scanpy` ?; Can I analyze `10X` Single Cell Multiome ATAC + Gene Expression data using `scanpy`? . Or is there a companion package for single-cell ATAC seq data analysis? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2388
https://github.com/scverse/scanpy/issues/2389:517,availability,down,downstream,517,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:153,deployability,version,version,153,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3974,deployability,Version,Versions,3974," value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4023,deployability,log,logging,4023,".X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5825,deployability,updat,updated,5825," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4257,energy efficiency,cloud,cloudpickle,4257,"(0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:153,integrability,version,version,153,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3974,integrability,Version,Versions,3974," value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5512,integrability,wrap,wrapt,5512," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2560,interoperability,specif,specifing,2560,",:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3656,interoperability,specif,specifing,3656,"um of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:24,modifiability,layer,layers,24,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:153,modifiability,version,version,153,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:647,modifiability,layer,layers,647,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:754,modifiability,layer,layer,754,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1033,modifiability,layer,layers,1033,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1371,modifiability,layer,layer,1371,"ow to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1414,modifiability,layer,layers,1414," us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1599,modifiability,layer,layer,1599,"tioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1648,modifiability,layer,layers,1648,"rs['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1845,modifiability,layer,layer,1845," count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1888,modifiability,layer,layers,1888,"n. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2102,modifiability,layer,layer,2102," adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2151,modifiability,layer,layers,2151," the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2269,modifiability,layer,layers,2269,"alse, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2579,modifiability,layer,layer,2579,"nt('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2638,modifiability,layer,layer,2638,"LAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2673,modifiability,layer,layer,2673," value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2716,modifiability,layer,layers,2716,"LAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. fin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2901,modifiability,layer,layer,2901,".sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2950,modifiability,layer,layers,2950,"total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3118,modifiability,layer,layer,3118,"cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3238,modifiability,layer,layer,3238,"sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3419,modifiability,layer,layer,3419,"s as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3545,modifiability,layer,layer,3545,"malization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3675,modifiability,layer,layer,3675," in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3749,modifiability,layer,layer,3749,"total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3875,modifiability,layer,layer,3875,"). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3974,modifiability,Version,Versions,3974," value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4389,modifiability,deco,decorator,4389," (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4842,modifiability,pac,packaging,4842,"ll: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5671,modifiability,pac,packaged,5671," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4023,safety,log,logging,4023,".X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5825,safety,updat,updated,5825," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4023,security,log,logging,4023,".X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5805,security,Session,Session,5805," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5825,security,updat,updated,5825," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1328,testability,simpl,simple,1328,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3084,testability,simpl,simple,3084,"('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:4023,testability,log,logging,4023,".X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:113,usability,confirm,confirmed,113,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:196,usability,confirm,confirmed,196,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:287,usability,guid,guide,287,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:342,usability,minim,minimal-bug-reports,342,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:464,usability,user,users,464,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:568,usability,behavi,behavior,568,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:677,usability,document,documentation,677,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:740,usability,behavi,behavior,740,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:794,usability,behavi,behavior,794,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:898,usability,Minim,Minimal,898,"normalize_total affects layers; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1328,usability,simpl,simple,1328,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:. Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning. pp.normalize_total() normalized my .layers['counts'] as well. The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but. such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""). sc.pp.normalize_total(adata, target_sum=1e4). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too. print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3084,usability,simpl,simple,3084,"('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X. cell = adata.obs.index[1]. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""). sc.pp.normalize_total(adata, target_sum=1e4, layer = None). print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()). print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]). print('.X.sum() value in cell: ', adata[cell,:].X.sum()). print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']). print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). ```. ```pytb. #Output:. Run 1: initial values after simple processing: . sum of count layer in designated cell: 4903.0. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 4903.0. sum of count layer of MALAT1 in cell: (0, 0)	142.0. .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: . normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None. normalizing counts per cell. finished (0:00:00). sum of count layer in designated cell: 10000.049. obs[total_counts] value in cell: 4903.0. .X.sum() value in cell: 10000.049. sum of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5394,usability,tool,toolz,5394," of count layer of MALAT1 in cell: (0, 0)	289.61862. .X value of MALAT1 in cell: (0, 0)	289.61862. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. anndata2ri 1.1. annoy NA. backcall 0.2.0. backports NA. bbknn NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. deprecated 1.2.13. entrypoints 0.4. fsspec 2022.11.0. future_fstrings NA. google NA. h5py 3.7.0. igraph 0.9.1. ipykernel 6.14.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.2. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.3. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.5. pytz_deprecation_shim NA. rpy2 3.5.1. scib 1.0.4. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. six 1.16.0. sklearn 1.0.2. statsmodels 0.13.2. storemagic NA. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. tqdm 4.64.1. traitlets 5.5.0. typing_extensions NA. tzlocal NA. umap 0.5.3. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 24.0.1. zope NA. -----. IPython 7.33.0. jupyter_client 7.4.4. jupyter_core 4.11.1. notebook 6.5.1. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid. -----. Session information updated at 2022-12-28 13:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2390:351,interoperability,specif,specify,351,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:132,modifiability,paramet,parameters,132,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:701,safety,compl,completed,701,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:242,security,team,team,242,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:701,security,compl,completed,701,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:767,usability,help,help,767,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2390:786,usability,help,help,786,"Multithreading for scanpy.tl.rank_genes_group?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi ScanPy team. I emailed @ivirshup but others should be involved I think. . This function would be useful if we could specify the number of threads to use: https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html. Based on the number of items in the ""groupby"" field, we could use a basic split-merge approach here: each thread would take several of these items, the calculations are entirely independent of one another, and then when each is completed we would join + concatenate the results. . I'm happy to help write up a PR help (or participate), but I'd like to hear if this is something you'd be willing to prioritize. (It's related to a project whereby Fabian is the PI.). Best, Evan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390
https://github.com/scverse/scanpy/issues/2391:516,availability,error,error,516,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2991,availability,error,error,2991,"olor, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3148,availability,error,error,3148,"on, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3198,availability,error,error,3198,"or, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:202,deployability,version,version,202,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1441,deployability,modul,module,1441,"essary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3363,deployability,Version,Versions,3363,"th, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:5051,deployability,updat,updated,5051,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3522,energy efficiency,cloud,cloudpickle,3522,"*kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:202,integrability,version,version,202,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2112,integrability,compon,components,2112,"al code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3096,integrability,messag,message,3096,"ds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3204,integrability,messag,message,3204,"in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3363,integrability,Version,Versions,3363,"th, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2112,interoperability,compon,components,2112,"al code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3096,interoperability,messag,message,3096,"ds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3204,interoperability,messag,message,3204,"in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:202,modifiability,version,version,202,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1441,modifiability,modul,module,1441,"essary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1569,modifiability,pac,packages,1569,"in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1918,modifiability,pac,packages,1918,"with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2112,modifiability,compon,components,2112,"al code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2136,modifiability,layer,layer,2136,"e can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2599,modifiability,pac,packages,2599,"atterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3044,modifiability,paramet,parameter,3044,"idth, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3363,modifiability,Version,Versions,3363,"th, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3622,modifiability,deco,decorator,3622,"ils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:4120,modifiability,pac,packaging,4120,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:4895,modifiability,pac,packaged,4895,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:516,performance,error,error,516,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2991,performance,error,error,2991,"olor, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3148,performance,error,error,3148,"on, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3198,performance,error,error,3198,"or, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:516,safety,error,error,516,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1441,safety,modul,module,1441,"essary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2991,safety,error,error,2991,"olor, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3148,safety,error,error,3148,"on, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3198,safety,error,error,3198,"or, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:5051,safety,updat,updated,5051,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:5031,security,Session,Session,5031,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:5051,security,updat,updated,5051,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1365,testability,Trace,Traceback,1365,"blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:162,usability,confirm,confirmed,162,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:245,usability,confirm,confirmed,245,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:336,usability,guid,guide,336,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:391,usability,minim,minimal-bug-reports,391,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:516,usability,error,error,516,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:932,usability,command,command,932,"scanpy.pl.spatial TypeError: can't multiply sequence by non-int of type 'float'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:1112,usability,Minim,Minimal,1112,"e has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python. healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'). ```. I calculated qc metrics with this command. ```python. sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True). ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") . ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1314047/3602867448.py in <module>. ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1009 show=False,. 1010 save=False,. -> 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2991,usability,error,error,2991,"olor, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3148,usability,error,error,3148,"on, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3198,usability,error,error,3198,"or, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3262,usability,user,user-images,3262,", legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. --> 399 **kwargs,. 400 ). 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:4647,usability,tool,toolz,4647,"same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. annoy NA. asciitree NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. cloudpickle 2.2.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. fbpca NA. fsspec 2022.11.0. google NA. h5py 3.7.0. igraph 0.10.2. intervaltree NA. ipykernel 6.16.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.4. natsort 8.2.0. nbinom_ufunc NA. numba 0.56.4. numcodecs 0.10.2. numpy 1.21.6. packaging 22.0. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.36. psutil 5.9.3. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.7. scanorama 1.7.1. scipy 1.7.3. seaborn 0.12.1. session_info 1.0.0. setuptools 65.6.3. six 1.16.0. sklearn 1.0.2. sortedcontainers 2.4.0. statsmodels 0.13.5. storemagic NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.8.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. zmq 24.0.1. -----. IPython 7.33.0. jupyter_client 7.4.8. jupyter_core 4.11.1. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]. Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid. -----. Session information updated at 2022-12-28 21:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2392:44,availability,cluster,cluster,44,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:100,availability,cluster,clusters,100,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:143,availability,cluster,cluster,143,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:196,availability,cluster,cluster,196,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:44,deployability,cluster,cluster,44,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:100,deployability,cluster,clusters,100,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:143,deployability,cluster,cluster,143,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:196,deployability,cluster,cluster,196,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:329,integrability,sub,subplots,329,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2392:1770,usability,user,user-images,1770,"How to let `sc.pl.umap` skip a color when a cluster is empty?; Hello. Some of my samples have empty clusters. I want to fix the color for each cluster. How to let `sc.pl.umap` skip a color when a cluster is empty? ```. from matplotlib.pyplot import rc_context. with rc_context({'figure.figsize': (3, 3)}):. fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(6,6)). ax1[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[0]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[0], show=False). ax1[0].set_xlabel(''). ax1[0].set(xlim=xlim, ylim=ylim). ax1[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[1]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax1[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[1], show=False). ax1[1].set_xlabel(''). ax1[1].set_ylabel(''). ax1[1].set(xlim=xlim, ylim=ylim). ax2[0] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[2]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[0],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[2], show=False). ax2[0].set(xlim=xlim, ylim=ylim). #ax2[0].set_xlabel(''). ax2[1] = sc.pl.umap(adata[adata.obs['sample'] == adata.obs['sample'].cat.categories[3]], . color = 'leiden_r1', size=20,. legend_loc = 'on data', ax=ax2[1],. palette = mycolormap_26,. frameon=True, legend_fontsize = 8,title = adata.obs['sample'].cat.categories[3], show=False). ax2[1].set(xlim=xlim, ylim=ylim). #ax2[1].set_xlabel(''). ax2[1].set_ylabel(''). ```. ![image](https://user-images.githubusercontent.com/33963919/209980418-3ffb8db2-bcdc-4baf-8177-7c0d332394c6.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2392
https://github.com/scverse/scanpy/issues/2393:741,availability,error,error,741,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:74,deployability,pipelin,pipeline,74,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:113,deployability,fail,fails,113,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:322,deployability,version,version,322,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:798,deployability,Version,Versions,798,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:847,deployability,log,logging,847,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:74,integrability,pipelin,pipeline,74,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:322,integrability,version,version,322,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:798,integrability,Version,Versions,798,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:322,modifiability,version,version,322,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:798,modifiability,Version,Versions,798,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:741,performance,error,error,741,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:113,reliability,fail,fails,113,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:741,safety,error,error,741,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:847,safety,log,logging,847,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:847,security,log,logging,847,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:847,testability,log,logging,847,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:178,usability,mous,mouse,178,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:282,usability,confirm,confirmed,282,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:365,usability,confirm,confirmed,365,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:456,usability,guid,guide,456,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:511,usability,minim,minimal-bug-reports,511,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:617,usability,Minim,Minimal,617,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:741,usability,error,error,741,"Scanpy analysis for a combined species. I have tried following the normal pipeline to work with the data, but it fails to find MT/mt genes in single cell dataset aligned to both mouse & human genes. ; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2394:128,interoperability,coordinat,coordinates,128,"scanpy.tl.umap should have a `key_added` parameter; If you have multiple neighbors graphs, you can only store the computed UMAP coordinates of one of them in an anndata with sc.tl.umap. Instead, it should be possible to store multiple UMAP embeddings computed from multiple `sc.tl.umap(neighbors_key=X)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2394
https://github.com/scverse/scanpy/issues/2394:41,modifiability,paramet,parameter,41,"scanpy.tl.umap should have a `key_added` parameter; If you have multiple neighbors graphs, you can only store the computed UMAP coordinates of one of them in an anndata with sc.tl.umap. Instead, it should be possible to store multiple UMAP embeddings computed from multiple `sc.tl.umap(neighbors_key=X)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2394
https://github.com/scverse/scanpy/issues/2396:721,availability,error,errors,721,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1285,availability,sli,slice,1285,". ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1602,availability,error,errors,1602,"pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot spe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2166,availability,sli,slice,2166,"es ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2495,availability,error,errors,2495,"g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4479,availability,sli,slice,4479,"data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:189,deployability,version,version,189,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:863,deployability,contain,contains,863,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:985,deployability,log,log,985,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1744,deployability,contain,contains,1744,"rmalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1866,deployability,log,log,1866,"ins infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2641,deployability,contain,contains,2641,"vor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2953,deployability,modul,module,2953,"enes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3487,deployability,contain,contains,3487,"his errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3538,deployability,log,log,3538,"r=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.hi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4865,deployability,modul,module,4865," False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5401,deployability,contain,contains,5401,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5430,deployability,Version,Versions,5430,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5479,deployability,log,logging,5479,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:6176,deployability,updat,updated,6176,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3369,energy efficiency,core,core,3369,">>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5283,energy efficiency,core,core,5283,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:189,integrability,version,version,189,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:933,integrability,sub,subset,933,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1128,integrability,sub,subset,1128,"ted. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1200,integrability,batch,batch,1200,"npy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1261,integrability,batch,batch,1261," master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1410,integrability,sub,subset,1410,"to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1450,integrability,batch,batch,1450," us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1814,integrability,sub,subset,1814,"cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2009,integrability,sub,subset,2009,"ns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/pre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2081,integrability,batch,batch,2081,", layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2142,integrability,batch,batch,2142,"lace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2291,integrability,sub,subset,2291,"c.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2331,integrability,batch,batch,2331,"sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2715,integrability,sub,subset,2715,"er `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3689,integrability,sub,subset,3689,"pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4386,integrability,batch,batch,4386,""", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4451,integrability,batch,batch,4451,"y integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4608,integrability,sub,subset,4608,"> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4648,integrability,batch,batch,4648,"r=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5430,integrability,Version,Versions,5430,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:824,interoperability,specif,specify,824,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1705,interoperability,specif,specify,1705,"y(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2602,interoperability,specif,specify,2602,"rs, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3448,interoperability,specif,specify,3448,"] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5362,interoperability,specif,specify,5362,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:23,modifiability,layer,layer,23,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:189,modifiability,version,version,189,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:664,modifiability,layer,layers,664,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1086,modifiability,layer,layer,1086,"that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1368,modifiability,layer,layer,1368,"/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1545,modifiability,layer,layers,1545,"ata). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seura",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1967,modifiability,layer,layer,1967,"works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2249,modifiability,layer,layer,2249,"ndexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2428,modifiability,layer,layers,2428,"=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. Va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2771,modifiability,pac,packages,2771,"_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2953,modifiability,modul,module,2953,"enes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2993,modifiability,pac,packages,2993,"r=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3162,modifiability,pac,packages,3162,"slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3353,modifiability,pac,packages,3353,"ets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises Val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3647,modifiability,layer,layer,3647,"infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4566,modifiability,layer,layer,4566,"ns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4683,modifiability,pac,packages,4683,", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4865,modifiability,modul,module,4865," False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4906,modifiability,pac,packages,4906,"5] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5076,modifiability,pac,packages,5076,"205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5267,modifiability,pac,packages,5267,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5430,modifiability,Version,Versions,5430,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5803,modifiability,pac,packaging,5803,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:721,performance,error,errors,721,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1200,performance,batch,batch,1200,"npy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1261,performance,batch,batch,1261," master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1450,performance,batch,batch,1450," us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1602,performance,error,errors,1602,"pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot spe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2081,performance,batch,batch,2081,", layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2142,performance,batch,batch,2142,"lace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2331,performance,batch,batch,2331,"sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2495,performance,error,errors,2495,"g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4386,performance,batch,batch,4386,""", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4451,performance,batch,batch,4451,"y integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4648,performance,batch,batch,4648,"r=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:29,reliability,doe,does,29,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1285,reliability,sli,slice,1285,". ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2166,reliability,sli,slice,2166,"es ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4479,reliability,sli,slice,4479,"data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:721,safety,error,errors,721,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:852,safety,input,input,852,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:985,safety,log,log,985,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1602,safety,error,errors,1602,"pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot spe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1733,safety,input,input,1733," X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1866,safety,log,log,1866,"ins infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2495,safety,error,errors,2495,"g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2630,safety,input,input,2630,"ized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2953,safety,modul,module,2953,"enes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3476,safety,input,input,3476,">> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3538,safety,log,log,3538,"r=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.hi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4865,safety,modul,module,4865," False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5390,safety,input,input,5390,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5479,safety,log,logging,5479,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:6176,safety,updat,updated,6176,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:985,security,log,log,985,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1866,security,log,log,1866,"ins infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3538,security,log,log,3538,"r=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.hi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5479,security,log,logging,5479,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:6156,security,Session,Session,6156,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:6176,security,updat,updated,6176,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:985,testability,log,log,985,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1866,testability,log,log,1866,"ins infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2889,testability,Trace,Traceback,2889,"s['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3538,testability,log,log,3538,"r=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.hi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:4801,testability,Trace,Traceback,4801,"11, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5479,testability,log,logging,5479,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:149,usability,confirm,confirmed,149,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:232,usability,confirm,confirmed,232,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:323,usability,guid,guide,323,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:378,usability,minim,minimal-bug-reports,378,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:484,usability,Minim,Minimal,484,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:721,usability,error,errors,721,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:852,usability,input,input,852,"highly_variable_genes: layer does not work together with batch_key; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1602,usability,error,errors,1602,"pbmc3k(). log_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot spe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1733,usability,input,input,1733," X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). ```. ```pytb. >>> import scanpy as sc. g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2495,usability,error,errors,2495,"g_anndata = sc.pp.log1p(pbmc, copy=True). pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2630,usability,input,input,2630,"ized and flavor=""seurat"" requires normalizes data. # ValueError: cannot specify integer `bins` when input data contains infinity. sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data. pbmc.uns['log1p'] = log_anndata.uns['log1p']. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again. pbmc.obs['batch'] = 'A'. column_index = pbmc.obs.columns.get_indexer(['batch']). pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True). >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(). >>> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3476,usability,input,input,3476,">> . >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data. >>> # ValueError: cannot specify integer `bins` when input data contains infinity. >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes. df = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. >>> . >>> # This works, we pass log tranformed data. >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). means dispersions mean_bin dispersions_norm highly_variable. 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. ... ... ... ... ... ... 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5390,usability,input,input,5390,"12 NaN (-0.00411, 0.205] 0.0 False. 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]. >>> . >>> # This raises ValueError again. >>> pbmc.obs['batch'] = 'A'. >>> column_index = pbmc.obs.columns.get_indexer(['batch']). >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'. >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""). .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes. hvg = _highly_variable_genes_single_batch(. File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut. raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.3.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. google NA. h5py 3.7.0. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. numba 0.56.4. numpy 1.23.5. packaging 22.0. pandas 1.5.2. psutil 5.9.4. pyarrow 10.0.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.9.3. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.2.0. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. zoneinfo NA. -----. Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]. Linux-5.15.0-57-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-01-09 18:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/pull/2397:232,safety,review,review,232,Remove ATAC; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/pull/2397:232,testability,review,review,232,Remove ATAC; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/pull/2397:83,usability,guid,guidelines,83,Remove ATAC; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/pull/2397:114,usability,guid,guide,114,Remove ATAC; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/pull/2397:210,usability,workflow,workflow,210,Remove ATAC; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/issues/2398:627,deployability,Version,Versions,627,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2398:627,integrability,Version,Versions,627,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2398:627,modifiability,Version,Versions,627,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2398:38,reliability,doe,does,38,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2398:214,reliability,doe,does,214,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2398:55,usability,guid,guide,55,"scRNA-seq CRISPR data: sc.read_10x_h5 does not include guide sequence in the count matrix and .var; The regular read_10x_h5() function neglects the gRNA in scRNA-seq CRISPR data which were provided to cell ranger (does not show In adata.X and adata.var). However, with the read_mtx() it is included in the adata.X and the gene_ids can be manually added read in from the features.tsv.gz file. @vitkl. ### Example. ```python. adata = sc.read_mtx('matrix.mtx.gz'). print(adata.X.T.shape). adata_raw=sc.read_10x_h5('filtered_feature_bc_matrix.h5'). print(adata_raw.X.shape). ```. ```pytb. (12797, 36685). (12797, 36601). ```. #### Versions. - anndata 0.8.0. - scanpy 1.9.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398
https://github.com/scverse/scanpy/issues/2399:103,deployability,contain,containing,103,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/issues/2399:275,deployability,updat,updated,275,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/issues/2399:189,integrability,filter,filtered,189,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/issues/2399:19,reliability,doe,does,19,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/issues/2399:275,safety,updat,updated,275,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/issues/2399:275,security,updat,updated,275,"sc.pp.filter_cells does not work for pseudo counts data; Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/pull/2400:0,deployability,Updat,Update,0,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:22,deployability,Updat,Update,22,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:86,modifiability,pac,packages,86,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:0,safety,Updat,Update,0,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:22,safety,Updat,Update,22,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:0,security,Updat,Update,0,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:22,security,Updat,Update,22,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:29,security,polic,policy,29,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/pull/2400:49,usability,tool,tools,49,Update external page; Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/issues/2401:38,availability,error,error,38,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:421,availability,error,error,421,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2284,availability,slo,slow,2284,"niconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:195,deployability,version,version,195,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:450,deployability,fail,fails,450,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1006,deployability,modul,module,1006,"UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3550,deployability,stack,stacklevel,3550,"_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3602,deployability,contain,container,3602,"2 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3617,deployability,contain,container,3617,"ate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4120,deployability,contain,container,4120," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4616,deployability,Version,Versions,4616," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4132,energy efficiency,reduc,reduce,4132," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4557,energy efficiency,load,load,4557," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:195,integrability,version,version,195,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1186,integrability,Batch,Batch,1186,"atest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1248,integrability,Sub,SubType,1248," bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1517,integrability,compon,components,1517,"in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4616,integrability,Version,Versions,4616," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1517,interoperability,compon,components,1517,"in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:195,modifiability,version,version,195,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1006,modifiability,modul,module,1006,"UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1323,modifiability,pac,packages,1323,"al_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1517,modifiability,compon,components,1517,"in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1529,modifiability,layer,layer,1529,"wever, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1986,modifiability,pac,packages,1986,"1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2338,modifiability,pac,packages,2338,"tting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2695,modifiability,pac,packages,2695,", vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2943,modifiability,pac,packages,2943,"miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3243,modifiability,pac,packages,3243," not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3481,modifiability,pac,packages,3481,"colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3926,modifiability,pac,packages,3926," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4212,modifiability,pac,packages,4212," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4616,modifiability,Version,Versions,4616," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:38,performance,error,error,38,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:421,performance,error,error,421,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1186,performance,Batch,Batch,1186,"atest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4557,performance,load,load,4557," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4578,performance,memor,memory,4578," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:450,reliability,fail,fails,450,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2243,reliability,doe,does,2243,"','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:2284,reliability,slo,slow,2284,"niconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1267 color_map = {. 1268 k: to_hex(v). -> 1269 for k, v in _get_palette(adata, values_key, palette=palette).items(). 1270 }. 1271 # If color_map does not have unique values, this can be slow as the. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_palette(adata, values_key, palette). 1238 ):. 1239 # set a default palette in case that no colors or few colors are found. -> 1240 _utils._set_default_colors_for_categorical_obs(adata, values_key). 1241 else:. 1242 _utils._validate_palette(adata, values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:38,safety,error,error,38,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:421,safety,error,error,421,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:979,safety,input,input-,979,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:1006,safety,modul,module,1006,"UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3802,safety,except,except,3802," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:935,testability,Trace,Traceback,935,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3682,testability,context,contextlib,3682," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:38,usability,error,error,38,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:155,usability,confirm,confirmed,155,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:238,usability,confirm,confirmed,238,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:421,usability,error,error,421,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:979,usability,input,input-,979,"Plotting UMAP in backed mode leads to error when setting color palettes; - [x ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns. However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works. ```. random_indices=np.random.permutation(adatas['Human'].obs_names). sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',. color=['CellType'],hspace=0.9). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-48-8a1d75e9b375> in <module>. 2 np.random.seed(0). 3 random_indices=np.random.permutation(adatas['Human'].obs_names). ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',. 5 color=['Batch','Region','Condition', 'Grade', . 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 250 groups=groups,. 251 ). --> 252 color_vector, categorical = _color_vector(. 253 adata,. 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:3809,usability,Stop,StopIteration,3809," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4578,usability,memor,memory,4578," values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot). 468 ). 469 . --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]). 471 . 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette). 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]. 429 . --> 430 adata.uns[value_to_plot + '_colors'] = colors_list. 431 . 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value). 104 self.overloaded[key].set(value). 105 else:. --> 106 self.data[key] = value. 107 . 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value). 32 stacklevel=2,. 33 ). ---> 34 with self._update() as container:. 35 container[idx] = value. 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self). 111 del self.args, self.kwds, self.func. 112 try:. --> 113 return next(self.gen). 114 except StopIteration:. 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self). 38 def _update(self):. 39 adata_view, attr_name, keys = self._view_args. ---> 40 new = adata_view.copy(). 41 attr = getattr(new, attr_name). 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename). 1526 . 1527 if filename is None:. -> 1528 raise ValueError(. 1529 ""To copy an AnnData object in backed mode, "". 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2402:38,availability,error,error,38,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1351,availability,error,error,1351,"unt matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1924,availability,sli,sliced,1924," of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2261,availability,sli,slice,2261,"ugh the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would ap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2268,availability,sli,slice,2268," sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3448,availability,error,error,3448,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:302,deployability,contain,contains,302,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3313,deployability,Version,Versions,3313,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3362,deployability,log,logging,3362,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3541,deployability,version,version,3541,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3550,deployability,version,version,3550,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1357,integrability,messag,message,1357,"rix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3313,integrability,Version,Versions,3313,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3454,integrability,messag,message,3454,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3541,integrability,version,version,3541,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3550,integrability,version,version,3550,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1357,interoperability,messag,message,1357,"rix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3454,interoperability,messag,message,3454,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1773,modifiability,pac,packages,1773,"names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2110,modifiability,pac,packages,2110,"ch sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Bool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2391,modifiability,pac,packages,2391,"----------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2653,modifiability,pac,packages,2653,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3313,modifiability,Version,Versions,3313,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3541,modifiability,version,version,3541,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3550,modifiability,version,version,3550,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:38,performance,error,error,38,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1351,performance,error,error,1351,"unt matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3448,performance,error,error,3448,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:101,reliability,doe,does,101,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1924,reliability,sli,sliced,1924," of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2261,reliability,sli,slice,2261,"ugh the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would ap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2268,reliability,sli,slice,2268," sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:2860,reliability,doe,does,2860,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3124,reliability,doe,does,3124,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:38,safety,error,error,38,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1351,safety,error,error,1351,"unt matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1513,safety,Input,Input,1513,"hon. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3362,safety,log,logging,3362,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3448,safety,error,error,3448,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3362,security,log,logging,3362,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1478,testability,Trace,Traceback,1478,"represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3362,testability,log,logging,3362,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:38,usability,error,error,38,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:231,usability,help,help,231,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "") ; Hi, could someone help me resolve the following. I am trying to read a count matrix that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1351,usability,error,error,1351,"unt matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1513,usability,Input,Input,1513,"hon. # Read the count matrix . adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names. adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]. adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names. sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample. for sample in sample_list:. sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```. However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. . ```pytb. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). Input In [5], in <cell line: 2>(). 1 # iterate through the sample names and create a new AnnData object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3448,usability,error,error,3448,"ta object for each sample. 2 for sample in sample_list:. ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index). 1111 def __getitem__(self, index: Index) -> ""AnnData"":. 1112 """"""Returns a sliced view of the object."""""". -> 1113 oidx, vidx = self._normalize_indices(index). 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index). 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1). 34 ax0, ax1 = unpack_index(index). 35 ax0 = _normalize_index(ax0, names0). ---> 36 ax1 = _normalize_index(ax1, names1). 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index). 88 elif issubclass(indexer.dtype.type, np.bool_):. 89 if indexer.shape != index.shape:. ---> 90 raise IndexError(. 91 f""Boolean index does not match AnnDatas shape along this "". 92 f""dimension. Boolean index has shape {indexer.shape} while "". 93 f""AnnData index has shape {index.shape}."". 94 ). 95 positions = np.where(indexer)[0]. 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```. I would appreciate any insights. Thank you so much! . #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version. version('scanpy'). I got an output: '1.9.1'. </details> .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2403:131,energy efficiency,cool,cool,131,"Is there a way to export UMAP data as a UMAP class?; Hi there! . I am extremely impressed with ScanPy and am using it for a really cool non-traditional analysis. I saw that the UMAP package actually has interactive 3D plotting functions, and I was wondering if the UMAP data from ScanPy could be cast or exported in such a way that I could leverage that functionality?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2403
https://github.com/scverse/scanpy/issues/2403:182,modifiability,pac,package,182,"Is there a way to export UMAP data as a UMAP class?; Hi there! . I am extremely impressed with ScanPy and am using it for a really cool non-traditional analysis. I saw that the UMAP package actually has interactive 3D plotting functions, and I was wondering if the UMAP data from ScanPy could be cast or exported in such a way that I could leverage that functionality?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2403
https://github.com/scverse/scanpy/issues/2403:203,usability,interact,interactive,203,"Is there a way to export UMAP data as a UMAP class?; Hi there! . I am extremely impressed with ScanPy and am using it for a really cool non-traditional analysis. I saw that the UMAP package actually has interactive 3D plotting functions, and I was wondering if the UMAP data from ScanPy could be cast or exported in such a way that I could leverage that functionality?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2403
https://github.com/scverse/scanpy/issues/2404:1039,availability,error,errors,1039,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:219,deployability,version,version,219,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:613,deployability,scale,scale,613,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:904,deployability,Version,Versions,904,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:924,deployability,version,version,924,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:948,deployability,version,versions,948,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1054,deployability,version,version,1054,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:613,energy efficiency,scale,scale,613,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:31,integrability,rout,routine,31,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:219,integrability,version,version,219,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:828,integrability,rout,routine,828,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:904,integrability,Version,Versions,904,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:924,integrability,version,version,924,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:948,integrability,version,versions,948,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1054,integrability,version,version,1054,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:219,modifiability,version,version,219,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:613,modifiability,scal,scale,613,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:904,modifiability,Version,Versions,904,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:924,modifiability,version,version,924,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:948,modifiability,version,versions,948,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1054,modifiability,version,version,1054,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:613,performance,scale,scale,613,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1039,performance,error,errors,1039,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1039,safety,error,errors,1039,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:179,usability,confirm,confirmed,179,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:271,usability,guid,guide,271,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:326,usability,minim,minimal-bug-reports,326,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:432,usability,Minim,Minimal,432,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:1039,usability,error,errors,1039,"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. ... ... test_data = sc.pp.regress_out(test_data,['n_count'], copy=True). sc.pp.scale(test_data). sc.tl.pca(test_data,n_comps=30, use_highly_variable=True). sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical. OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8. and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem? .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/pull/2405:324,safety,review,review,324,Fix some typos in scanpy.tl.paga; Found some typos in the docstring. Also searched them in other places. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/pull/2405:324,testability,review,review,324,Fix some typos in scanpy.tl.paga; Found some typos in the docstring. Also searched them in other places. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/pull/2405:175,usability,guid,guidelines,175,Fix some typos in scanpy.tl.paga; Found some typos in the docstring. Also searched them in other places. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/pull/2405:206,usability,guid,guide,206,Fix some typos in scanpy.tl.paga; Found some typos in the docstring. Also searched them in other places. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/pull/2405:302,usability,workflow,workflow,302,Fix some typos in scanpy.tl.paga; Found some typos in the docstring. Also searched them in other places. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/issues/2406:136,availability,Error,Error,136,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3897,availability,error,errors,3897," ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1690,deployability,modul,module,1690,"dean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:394,energy efficiency,core,core,394,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:656,energy efficiency,CPU,CPUDispatcher,656,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3416,energy efficiency,core,core,3416,"n3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_over",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3726,energy efficiency,core,core,3726,"6 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 67",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4057,energy efficiency,core,core,4057,"""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4318,energy efficiency,core,core,4318,".indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4568,energy efficiency,core,core,4568," config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4825,energy efficiency,core,core,4825,"). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4951,energy efficiency,reduc,reduce,4951,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5102,energy efficiency,core,core,5102,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5325,energy efficiency,core,core,5325,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5648,energy efficiency,core,core,5648,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:142,integrability,messag,message,142,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2551,integrability,transform,transform,2551,"f the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2693,integrability,transform,transform,2693," 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5577,integrability,protocol,protocol,5577,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5751,integrability,protocol,protocol,5751,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:142,interoperability,messag,message,142,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2551,interoperability,transform,transform,2551,"f the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2693,interoperability,transform,transform,2693," 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5577,interoperability,protocol,protocol,5577,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5751,interoperability,protocol,protocol,5751,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:379,modifiability,pac,packages,379,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1690,modifiability,modul,module,1690,"dean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1878,modifiability,pac,packages,1878,",-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, eps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2165,modifiability,pac,packages,2165,"pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2428,modifiability,pac,packages,2428,"d6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2667,modifiability,pac,packages,2667,"/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2946,modifiability,pac,packages,2946,"ing_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3192,modifiability,pac,packages,3192,"y in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 ret",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3401,modifiability,pac,packages,3401,"lng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3711,modifiability,pac,packages,3711,"15 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4042,modifiability,pac,packages,4042,"asattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4303,modifiability,pac,packages,4303,"reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4553,modifiability,pac,packages,4553,"LL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4810,modifiability,pac,packages,4810,"peof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5087,modifiability,pac,packages,5087,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5310,modifiability,pac,packages,5310,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5633,modifiability,pac,packages,5633,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:136,performance,Error,Error,136,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:399,performance,cach,caching,399,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:656,performance,CPU,CPUDispatcher,656,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3897,performance,error,errors,3897," ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4573,performance,cach,caching,4573,", this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4830,performance,cach,caching,4830,"try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5107,performance,cach,caching,5107,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5330,performance,cach,caching,5330,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5653,performance,cach,caching,5653,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:136,safety,Error,Error,136,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:533,safety,except,except,533,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1568,safety,except,exception,1568,"2, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1587,safety,except,exception,1587,"t32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1690,safety,modul,module,1690,"dean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3890,safety,except,except,3890,"n. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3897,safety,error,errors,3897," ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3651,security,sign,signature,3651,"on3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:302,testability,Trace,Traceback,302,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1618,testability,Trace,Traceback,1618," C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5018,testability,context,contextlib,5018,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5029,testability,context,contextmanager,5029,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5776,testability,context,contextlib,5776,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5787,testability,context,contextmanager,5787,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:136,usability,Error,Error,136,"TypeError: cannot pickle 'weakref' object; I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::. ```. sc.tl.ingest(bdata,. lungreference,obs='new_celltype'. ). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:1894,usability,tool,tools,1894,"512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2181,usability,tool,tools,2181,"opcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:2444,usability,tool,tools,2444,"fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). /tmp/ipykernel_875/1088574315.py in <module>. 2 print(transgene). 3 bdata=adata[adata.obs.treatment==transgene]. ----> 4 sc.tl.ingest(bdata,. 5 lungreference,obs='new_celltype'. 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 128 . 129 for method in embedding_method:. --> 130 ing.map_embedding(method). 131 . 132 if obs is not None:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method). 497 """""". 498 if method == 'umap':. --> 499 self._obsm['X_umap'] = self._umap_transform(). 500 elif method == 'pca':. 501 self._obsm['X_pca'] = self._pca(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in _umap_transform(self). 486 . 487 def _umap_transform(self):. --> 488 return self._umap.transform(self._obsm['rep']). 489 . 490 def map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X). 2715 else:. 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12. -> 2717 indices, dists = self._knn_search_index.query(. 2718 X, self.n_neighbors, epsilon=epsilon. 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3897,usability,error,errors,3897," ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1054 ). 1055 else:. -> 1056 diversify_csr(. 1057 reverse_graph.indptr,. 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2408:206,deployability,version,version,206,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:384,deployability,updat,updated,384,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:702,deployability,log,logic,702,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:206,integrability,version,version,206,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:206,modifiability,version,version,206,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:592,modifiability,paramet,parameters,592,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:762,modifiability,paramet,parameters,762,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:856,modifiability,paramet,parameters,856,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:384,safety,updat,updated,384,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:702,safety,log,logic,702,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:384,security,updat,updated,384,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:702,security,log,logic,702,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:702,testability,log,logic,702,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:0,usability,Document,Documentation,0,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:45,usability,tool,tools,45,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:166,usability,confirm,confirmed,166,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:249,usability,confirm,confirmed,249,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:319,usability,document,documentation,319,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:395,usability,indicat,indicate,395,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:454,usability,document,documentation,454,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:512,usability,indicat,indicate,512,"Documentation inconsistencies and mistakes - tools / embeddings / tsne, phate, umap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields. 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters. 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/pull/2409:254,safety,review,review,254,"Leiden, Louvain with Katana Graph; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/pull/2409:254,testability,review,review,254,"Leiden, Louvain with Katana Graph; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/pull/2409:105,usability,guid,guidelines,105,"Leiden, Louvain with Katana Graph; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/pull/2409:136,usability,guid,guide,136,"Leiden, Louvain with Katana Graph; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/pull/2409:232,usability,workflow,workflow,232,"Leiden, Louvain with Katana Graph; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/issues/2410:287,availability,error,error,287,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:16,deployability,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:130,deployability,modul,module,130,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:298,deployability,version,version,298,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:298,integrability,version,version,298,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:16,modifiability,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:130,modifiability,modul,module,130,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:298,modifiability,version,version,298,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:287,performance,error,error,287,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:255,reliability,doe,does,255,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:16,safety,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:130,safety,modul,module,130,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:287,safety,error,error,287,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2410:287,usability,error,error,287,"AttributeError: module 'scanpy' has no attribute 'utils'; when run sc.utils.sanitize_anndata(adata), it returns:. AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error? the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2411:201,deployability,version,version,201,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:228,deployability,Updat,Updated,228,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:422,deployability,instal,install,422,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:583,deployability,modul,module,583,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:650,deployability,modul,module,650,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:755,deployability,modul,module,755,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:856,deployability,modul,module,856,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:952,deployability,modul,module,952,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1153,deployability,Version,Versions,1153,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1188,deployability,log,logging,1188,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:201,integrability,version,version,201,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:991,integrability,Sub,SubplotBase,991,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1098,integrability,sub,subclass,1098,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1153,integrability,Version,Versions,1153,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:22,interoperability,conflict,conflict,22,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:54,interoperability,incompatib,incompatible,54,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1032,interoperability,conflict,conflict,1032,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:201,modifiability,version,version,201,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:583,modifiability,modul,module,583,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:607,modifiability,pac,packages,607,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:650,modifiability,modul,module,650,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:704,modifiability,pac,packages,704,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:755,modifiability,modul,module,755,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:804,modifiability,pac,packages,804,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:856,modifiability,modul,module,856,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:902,modifiability,pac,packages,902,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:952,modifiability,modul,module,952,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1153,modifiability,Version,Versions,1153,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:228,safety,Updat,Updated,228,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:355,safety,Test,Tested,355,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:583,safety,modul,module,583,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:650,safety,modul,module,650,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:755,safety,modul,module,755,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:856,safety,modul,module,856,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:952,safety,modul,module,952,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1188,safety,log,logging,1188,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:228,security,Updat,Updated,228,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1188,security,log,logging,1188,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:355,testability,Test,Tested,355,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:519,testability,Trace,Traceback,519,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1188,testability,log,logging,1188,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:161,usability,confirm,confirmed,161,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:246,usability,confirm,confirmed,246,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:308,usability,Minim,Minimal,308,"`TypeError: metaclass conflict`: matplotlib v3.7.0 is incompatible with scanpy; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```. (new-venv) $ pip install scanpy==1.9.1. ```. Then from within that venv:. ```python. import scanpy. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/pull/2412:180,deployability,modul,module,180,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:219,integrability,Sub,SubplotBase,219,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:327,integrability,sub,subclass,327,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:30,interoperability,incompatib,incompatibility,30,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:85,interoperability,incompatib,incompatibility,85,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:260,interoperability,conflict,conflict,260,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:130,modifiability,pac,packages,130,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:180,modifiability,modul,module,180,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/pull/2412:180,safety,modul,module,180,"Exclude matplotlib 3.7 due to incompatibility; matplotlib 3.7 introduces a metaclass incompatibility with scanpy:. File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class. must be a (non-strict) subclass of the metaclasses of all its bases. Excluding v3.7 works around this issue (#2411).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2412
https://github.com/scverse/scanpy/issues/2413:170,deployability,instal,installed,170,Matplotlib lower bound causes issues in google colab; https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/pyproject.toml#L57. Colab has 3.2.2 installed and installing scanpy requires restarting the runtime. I also can't find a great reason why 3.4 was chosen. https://github.com/scverse/scanpy/pull/2212/. based on this 3.2.2 should be fine?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413
https://github.com/scverse/scanpy/issues/2413:184,deployability,instal,installing,184,Matplotlib lower bound causes issues in google colab; https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/pyproject.toml#L57. Colab has 3.2.2 installed and installing scanpy requires restarting the runtime. I also can't find a great reason why 3.4 was chosen. https://github.com/scverse/scanpy/pull/2212/. based on this 3.2.2 should be fine?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413
https://github.com/scverse/scanpy/pull/2415:8,deployability,Updat,Update,8,"Revert ""Update external page""; Reverts scverse/scanpy#2400",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2415
https://github.com/scverse/scanpy/pull/2415:8,safety,Updat,Update,8,"Revert ""Update external page""; Reverts scverse/scanpy#2400",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2415
https://github.com/scverse/scanpy/pull/2415:8,security,Updat,Update,8,"Revert ""Update external page""; Reverts scverse/scanpy#2400",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2415
https://github.com/scverse/scanpy/issues/2416:0,deployability,Updat,Update,0,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:7,deployability,releas,release,7,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:73,deployability,updat,update,73,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:84,deployability,releas,release,84,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:0,safety,Updat,Update,0,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:73,safety,updat,update,73,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:0,security,Updat,Update,0,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:73,security,updat,update,73,Update release notes; I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2418:224,availability,sli,slicing,224,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:16,deployability,fail,fails,16,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:572,deployability,api,api,572,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:747,deployability,version,version,747,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1477,deployability,modul,module,1477,"on could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2136,deployability,Version,Versions,2136,"sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2160,deployability,log,logging,2160,"'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:4349,deployability,updat,updated,4349,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:252,energy efficiency,current,current,252,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:317,energy efficiency,current,current,317,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1324,energy efficiency,core,core,1324,"amples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2437,energy efficiency,cloud,cloudpickle,2437,"put-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:572,integrability,api,api,572,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:747,integrability,version,version,747,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2136,integrability,Version,Versions,2136,"sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:215,interoperability,specif,specific,215,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:572,interoperability,api,api,572,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:3296,interoperability,platform,platformdirs,3296,"backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:102,modifiability,scenario,scenarios,102,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:747,modifiability,version,version,747,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1307,modifiability,pac,packages,1307,"y the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1477,modifiability,modul,module,1477,"on could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1603,modifiability,pac,packages,1603,"_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1790,modifiability,pac,packages,1790,"irmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1959,modifiability,pac,packages,1959,"rt numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2136,modifiability,Version,Versions,2136,"sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2565,modifiability,deco,decorator,2565,"/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:3201,modifiability,pac,packaging,3201,0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Pyth,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:4218,modifiability,pac,packaged,4218,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2349,performance,bottleneck,bottleneck,2349,"e 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:16,reliability,fail,fails,16,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:224,reliability,sli,slicing,224,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:265,reliability,doe,doesn,265,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1441,safety,input,input-,1441,"(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1477,safety,modul,module,1477,"on could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2160,safety,log,logging,2160,"'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:4349,safety,updat,updated,4349,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2160,security,log,logging,2160,"'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2378,security,certif,certifi,2378,"de_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyproc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:3820,security,soc,socks,3820,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:4329,security,Session,Session,4329,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:4349,security,updat,updated,4349,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1203,testability,Trace,Traceback,1203,"in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2160,testability,log,logging,2160,"'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:0,usability,Tool,Tools,0,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:707,usability,confirm,confirmed,707,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:790,usability,confirm,confirmed,790,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:857,usability,Minim,Minimal,857,"Tools dendogram fails when using categorical obs key where not all categories have values; In certain scenarios `sc.tl.dendrogram` is used with an obs key which is categorial, but not all categories are used in the specific slicing of use. Because the current code doesn't check if all the categories are used by the current samples selection, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1329,usability,interact,interactiveshell,1329,"ction, it creates a non-symmetric matrix when line 133 of `_dendogram.py` creates `mean_df = rep_df.groupby(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. bino",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1441,usability,input,input-,1441,"(level=0).mean()`. maybe some solution could be found using [remove_unused_categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:1619,usability,tool,tools,1619,"l). - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. import pandas as pd. import numpy as np. import scanpy as sc. obs = pd.DataFrame(pd.Categorical([""a"",""b""], categories=[""a"",""b"",""c""]), columns=['cat_key']). adata = sc.AnnData(np.ones((2, 1)), obs=obs). sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). ```. ```pytb. Traceback (most recent call last):. File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>. sc.tl.dendrogram(adata, 'cat_key', use_rep='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram. corr_condensed = distance.squareform(1 - corr_matrix). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform. is_valid_dm(X, throw=True, name='X'). File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm. raise ValueError(('Distance matrix \'%s\' must be '. ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() . -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. PyQt5 NA. anyio NA. asttokens NA. attr 22.2.0. babel 2.11.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.6. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:3921,usability,tool,toolz,3921,"2.12.07. cffi 1.15.1. charset_normalizer 2.1.1. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.1.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. gepdynamics NA. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.21.1. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonschema 4.17.3. jupyter_events 0.5.0. jupyter_server 2.2.1. jupyterlab_server 2.19.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. louvain 0.8.0. markupsafe 2.1.2. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pydev_ipython NA. pydevd 1.4.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2022.7.1. requests 2.28.2. scipy 1.10.0. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.1.0. sip NA. sitecustomize NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.9.0. typing_extensions NA. unicodedata2 NA. urllib3 1.26.14. wcwidth 0.2.6. websocket 1.5.1. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.9.0. jupyter_client 8.0.2. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]. macOS-13.2.1-x86_64-i386-64bit. -----. Session information updated at 2023-02-15 22:51. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/pull/2420:0,deployability,updat,update,0,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:28,deployability,instal,install,28,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:0,safety,updat,update,0,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:19,safety,test,tests,19,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:44,safety,test,test,44,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:274,safety,review,review,274,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:0,security,updat,update,0,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:19,testability,test,tests,19,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:44,testability,test,test,44,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:274,testability,review,review,274,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:125,usability,guid,guidelines,125,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:156,usability,guid,guide,156,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:252,usability,workflow,workflow,252,update anndata-dev tests to install anndata test deps; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2421:142,availability,error,error,142,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:271,availability,error,error,271,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:0,deployability,Updat,Update,0,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:84,deployability,instal,install,84,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:113,deployability,version,version,113,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:348,deployability,releas,release,348,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:105,energy efficiency,Current,Current,105,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:113,integrability,version,version,113,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:277,integrability,messag,messages,277,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:277,interoperability,messag,messages,277,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:113,modifiability,version,version,113,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:142,performance,error,error,142,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:271,performance,error,error,271,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:0,safety,Updat,Update,0,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:53,safety,test,tests,53,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:142,safety,error,error,142,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:174,safety,compl,complaint,174,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:223,safety,compl,complicated,223,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:271,safety,error,error,271,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:0,security,Updat,Update,0,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:174,security,compl,complaint,174,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:223,security,compl,complicated,223,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:53,testability,test,tests,53,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:142,usability,error,error,142,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:271,usability,error,error,271,"Update dev branch; Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2422:75,safety,test,tests,75,"Revert ""Stephen/spaceranger2.0""; Reverts scverse/scanpy#2296 due to broken tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2422
https://github.com/scverse/scanpy/pull/2422:75,testability,test,tests,75,"Revert ""Stephen/spaceranger2.0""; Reverts scverse/scanpy#2296 due to broken tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2422
https://github.com/scverse/scanpy/issues/2423:353,availability,error,error,353,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:281,deployability,version,version,281,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:677,deployability,Version,Version,677,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:281,integrability,version,version,281,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:677,integrability,Version,Version,677,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:281,modifiability,version,version,281,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:677,modifiability,Version,Version,677,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:353,performance,error,error,353,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:353,safety,error,error,353,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2423:353,usability,error,error,353,"'AnnData' object has no attribute 'tl'; Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you! `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/pull/2424:0,deployability,updat,updated,0,updated read_visium() to read in spaceranger 2.0 files; Can now read in spaceranger 2.0 files where the tissue position file name is different and a header is included. Code adapated from squidpy's [read.visium()](https://github.com/scverse/squidpy/blob/main/squidpy/read/_read.py#L25) in response to [scverse/squidpy#599](https://github.com/scverse/squidpy/issues/599) and [scverse/scanpy#2296](https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424
https://github.com/scverse/scanpy/pull/2424:0,safety,updat,updated,0,updated read_visium() to read in spaceranger 2.0 files; Can now read in spaceranger 2.0 files where the tissue position file name is different and a header is included. Code adapated from squidpy's [read.visium()](https://github.com/scverse/squidpy/blob/main/squidpy/read/_read.py#L25) in response to [scverse/squidpy#599](https://github.com/scverse/squidpy/issues/599) and [scverse/scanpy#2296](https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424
https://github.com/scverse/scanpy/pull/2424:0,security,updat,updated,0,updated read_visium() to read in spaceranger 2.0 files; Can now read in spaceranger 2.0 files where the tissue position file name is different and a header is included. Code adapated from squidpy's [read.visium()](https://github.com/scverse/squidpy/blob/main/squidpy/read/_read.py#L25) in response to [scverse/squidpy#599](https://github.com/scverse/squidpy/issues/599) and [scverse/scanpy#2296](https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424
https://github.com/scverse/scanpy/issues/2425:246,availability,avail,available,246,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:25,deployability,version,versions,25,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:179,deployability,version,versions,179,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:256,deployability,version,versions,256,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:385,deployability,releas,releases,385,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:669,deployability,version,version,669,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:719,deployability,releas,release,719,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:758,deployability,Resourc,Resources,758,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:779,deployability,version,version,779,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:844,deployability,version,versions,844,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:870,deployability,automat,automatically,870,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:893,deployability,version,versions,893,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:968,deployability,automat,automation-rules,968,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1017,deployability,Automat,Automated,1017,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1027,deployability,version,versioning,1027,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,deployability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1095,deployability,automat,automated-versioning,1095,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1128,deployability,continu,continuous,1128,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1153,deployability,deploy,deployment,1153,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1197,deployability,version,versioned,1197,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:226,energy efficiency,Current,Currently,226,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:327,energy efficiency,current,current,327,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:758,energy efficiency,Resourc,Resources,758,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:25,integrability,version,versions,25,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:179,integrability,version,versions,179,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:256,integrability,version,versions,256,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:669,integrability,version,version,669,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:779,integrability,version,version,779,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:844,integrability,version,versions,844,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:893,integrability,version,versions,893,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1027,integrability,version,versioning,1027,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,integrability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1105,integrability,version,versioning,1105,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1197,integrability,version,versioned,1197,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,interoperability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:25,modifiability,version,versions,25,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:179,modifiability,version,versions,179,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:256,modifiability,version,versions,256,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:669,modifiability,version,version,669,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:779,modifiability,version,version,779,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:844,modifiability,version,versions,844,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:884,modifiability,maintain,maintain,884,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:893,modifiability,version,versions,893,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1027,modifiability,version,versioning,1027,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,modifiability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1105,modifiability,version,versioning,1105,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1197,modifiability,version,versioned,1197,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:758,performance,Resourc,Resources,758,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:246,reliability,availab,available,246,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,reliability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:246,safety,avail,available,246,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:758,safety,Resourc,Resources,758,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:884,safety,maintain,maintain,884,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:246,security,availab,available,246,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,security,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:758,testability,Resourc,Resources,758,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:870,testability,automat,automatically,870,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:968,testability,automat,automation-rules,968,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1017,testability,Automat,Automated,1017,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1077,testability,integr,integrations,1077,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1095,testability,automat,automated-versioning,1095,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:102,usability,tool,tool,102,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:196,usability,document,documentation,196,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:335,usability,document,documentation,335,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:418,usability,behavi,behavior,418,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:496,usability,menu,menu,496,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:557,usability,user,user-images,557,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:684,usability,document,documentation,684,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:791,usability,document,documentation,791,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1139,usability,document,documentation,1139,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1207,usability,document,documentation,1207,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1250,usability,document,documentation,1250,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1318,usability,user,user-images,1318,"feat(docs): tag `scanpy` versions on readthedocs; Thank you for creating `scanpy`! It's such a useful tool! ## Overview of request. Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior. I would like to be able to... 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page. ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png). 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources. - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html). - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags). - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example. As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2427:694,availability,Cluster,Clusters,694,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,deployability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:694,deployability,Cluster,Clusters,694,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,integrability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:331,integrability,batch,batch,331,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:964,integrability,sub,subset,964,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1244,integrability,sub,subset,1244,"hod mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1483,integrability,sub,subset,1483," to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1909,integrability,sub,subset,1909,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1916,integrability,sub,subset,1916,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2280,integrability,sub,subset,2280,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,interoperability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:366,interoperability,specif,specifying,366,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:425,interoperability,specif,specifying,425,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,modifiability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:499,modifiability,paramet,parameter,499,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:729,modifiability,layer,layers,729,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:767,modifiability,layer,layers,767,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:926,modifiability,layer,layer,926,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1202,modifiability,layer,layer,1202,"ssembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1308,modifiability,pac,packages,1308,". . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1401,modifiability,layer,layer,1401," get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1787,modifiability,layer,layer,1787,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1793,modifiability,layer,layer,1793,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2044,modifiability,layer,layer,2044,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2050,modifiability,layer,layer,2050,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2125,modifiability,pac,packages,2125,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2229,modifiability,layer,layer,2229,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:331,performance,batch,batch,331,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:54,reliability,doe,does,54,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,reliability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:517,reliability,doe,does,517,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,security,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:631,security,ident,ident,631,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:142,testability,integr,integration,142,"flavor=""seurat_v3"" from sc.pp.highly_variable_genes() does not work; Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:1067,testability,Trace,Traceback,1067," I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me? Thanks a lot! ```. adata. AnnData object with n_obs  n_vars = 73998  13639. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'. uns: 'log1p'. layers: 'counts'. for i in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 fla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:2696,usability,support,supported,2696,"in adatas:. i.layers['counts'] = i.X. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. layer=""counts"",. batch_key=""Sample"",. subset=True. ). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [197], line 1. ----> 1 sc.pp.highly_variable_genes(. 2 adata_new,. 3 flavor=""seurat_v3"",. 4 layer=""counts"",. 5 batch_key=""Sample"",. 6 subset=True. 7 ). 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 416 raise ValueError(. 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 419 ). 421 if flavor == 'seurat_v3':. --> 422 return _highly_variable_genes_seurat_v3(. 423 adata,. 424 layer=layer,. 425 n_top_genes=n_top_genes,. 426 batch_key=batch_key,. 427 check_values=check_values,. 428 span=span,. 429 subset=subset,. 430 inplace=inplace,. 431 ). 433 if batch_key is None:. 434 df = _highly_variable_genes_single_batch(. 435 adata,. 436 layer=layer,. (...). 443 flavor=flavor,. 444 ). File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:126, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 123 # this is done in SelectIntegrationFeatures() in Seurat v3. 124 ranked_norm_gene_vars = ranked_norm_gene_vars.astype(np.float32). 125 num_batches_high_var = np.sum(. --> 126 (ranked_norm_gene_vars < n_top_genes).astype(int), axis=0. 127 ). 128 ranked_norm_gene_vars[ranked_norm_gene_vars >= n_top_genes] = np.nan. 129 ma_ranked = np.ma.masked_invalid(ranked_norm_gene_vars). TypeError: '<' not supported between instances of 'float' and 'NoneType' ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/pull/2426:143,modifiability,extens,extension,143,"Nearest neighbours; We have replaced the existing nearest neighbor implementation from umap with scikit-learn's implementation. By using Intel extension for scikit-learn, this implementation can be upto 2x faster for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2426
https://github.com/scverse/scanpy/pull/2426:104,usability,learn,learn,104,"Nearest neighbours; We have replaced the existing nearest neighbor implementation from umap with scikit-learn's implementation. By using Intel extension for scikit-learn, this implementation can be upto 2x faster for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2426
https://github.com/scverse/scanpy/pull/2426:164,usability,learn,learn,164,"Nearest neighbours; We have replaced the existing nearest neighbor implementation from umap with scikit-learn's implementation. By using Intel extension for scikit-learn, this implementation can be upto 2x faster for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2426
https://github.com/scverse/scanpy/issues/2428:937,availability,error,error,937,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:247,deployability,version,version,247,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:716,deployability,contain,contains,716,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:880,deployability,Version,Versions,880,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:247,integrability,version,version,247,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:880,integrability,Version,Versions,880,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:1105,integrability,sub,subset,1105,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:247,modifiability,version,version,247,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:880,modifiability,Version,Versions,880,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:937,performance,error,error,937,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:1179,performance,memor,memory,1179,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:937,safety,error,error,937,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:39,security,modif,modify,39,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:983,security,modif,modify,983,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:207,usability,confirm,confirmed,207,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:290,usability,confirm,confirmed,290,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:937,usability,error,error,937,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/issues/2428:1179,usability,memor,memory,1179,"ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python. #remove all ribosomal genes. malat1 = adata1.var_names.str.startswith('MALAT1'). ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")). # we need to redefine the mito_genes since they were first . # calculated on the full object before removing low expressed genes. mito_genes = adata1.var_names.str.startswith('MT-'). hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1). remove = np.add(remove, hb_genes). keep = np.invert(remove). adata3 = adata1[:,keep]. adata3. ```. #### Versions. anndata 0.8.0. scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/pull/2429:0,deployability,Updat,Update,0,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:0,safety,Updat,Update,0,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:215,safety,input,input,215,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:0,security,Updat,Update,0,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:7,security,hash,hashsolo,7,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:65,security,Hash,Hashsolo,65,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:146,usability,clarit,clarity,146,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:215,usability,input,input,215,"Update hashsolo docstring; Hi, this is a PR with some changes to Hashsolo, mainly the docstring:. - Rewrite some param descriptions for brevity + clarity. - Explicitly list the obs keys being added to adata. - Copy input adata if inplace=False.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/issues/2430:603,availability,error,error,603,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:785,availability,toler,tolerance,785,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2738,availability,error,error,2738,"2 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.nd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3175,availability,sli,slice,3175,"d_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3909,availability,toler,tolerance,3909,"bs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:170,deployability,version,version,170,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1462,deployability,modul,module,1462,"Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4150,deployability,Version,Versions,4150,"._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4363,deployability,log,logging,4363,"ex). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:6266,deployability,updat,updated,6266,"nndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-02-24 14:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:734,energy efficiency,core,core,734,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3858,energy efficiency,core,core,3858,"ctor(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4565,energy efficiency,cloud,cloudpickle,4565,"ize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:170,integrability,version,version,170,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2034,integrability,compon,components,2034,"n pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4150,integrability,Version,Versions,4150,"._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2034,interoperability,compon,components,2034,"n pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:170,modifiability,version,version,170,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:718,modifiability,pac,packages,718,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:908,modifiability,pac,packages,908,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1006,modifiability,pac,packages,1006,"adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1462,modifiability,modul,module,1462,"Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1546,modifiability,pac,packages,1546,"l.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1840,modifiability,pac,packages,1840,"casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2034,modifiability,compon,components,2034,"n pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2058,modifiability,layer,layer,2058,"ndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2572,modifiability,pac,packages,2572,"s\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2693,modifiability,layer,layer,2693,"var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2939,modifiability,layer,layer,2939,"w, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._eng",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2945,modifiability,layer,layer,2945,"t_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2974,modifiability,pac,packages,2974,"dges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3088,modifiability,deco,decorator,3088,"lor_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3256,modifiability,pac,packages,3256,"orm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3529,modifiability,pac,packages,3529,"9 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3842,modifiability,pac,packages,3842,"ata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4150,modifiability,Version,Versions,4150,"._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4696,modifiability,deco,decorator,4696,"lif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. skle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:5191,modifiability,pac,packaging,5191,".5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:603,performance,error,error,603,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2738,performance,error,error,2738,"2 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.nd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4534,performance,bottleneck,bottleneck,4534,"nndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:785,reliability,toleran,tolerance,785,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2752,reliability,doe,doesn,2752,", show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3175,reliability,sli,slice,3175,"d_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3909,reliability,toleran,tolerance,3909,"bs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:603,safety,error,error,603,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:862,safety,except,except,862,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1303,safety,except,exception,1303,"e](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1351,safety,except,exception,1351,"28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1462,safety,modul,module,1462,"Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2738,safety,error,error,2738,"2 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.nd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3972,safety,except,except,3972,"ackages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4040,safety,except,except,4040,"tor(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4363,safety,log,logging,4363,"ex). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:6266,safety,updat,updated,6266,"nndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-02-24 14:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1139,security,hash,hashtable,1139," bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1235,security,hash,hashtable,1235,"n the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4363,security,log,logging,4363,"ex). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:6246,security,Session,Session,6246,"nndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-02-24 14:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:6266,security,updat,updated,6266,"nndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-02-24 14:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:662,testability,Trace,Traceback,662,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1372,testability,Trace,Traceback,1372,"s) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4363,testability,log,logging,4363,"ex). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:130,usability,confirm,confirmed,130,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:213,usability,confirm,confirmed,213,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:304,usability,guid,guide,304,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:359,usability,minim,minimal-bug-reports,359,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:465,usability,Minim,Minimal,465,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:603,usability,error,error,603,"sc.pl.pca(adata, color='CST3') can't find color; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.pca(adata, color='CST3'). ```. ```pytb. [Paste the error output produced by the above code here]. ```KeyError Traceback (most recent call last). D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3628 try:. -> 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>. 1 #  PCA . ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 869 """""". 870 if not annotate_var_explained:. --> 871 return embedding(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2730,usability,help,helpful,2730,"ng(. 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2738,usability,error,error,2738,"2 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 # ]. 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):. --> 257 color_source_vector = _get_color_source_vector(. 258 adata,. 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1165 ] # TODO: Throw helpful error if this doesn't work. 1166 if use_raw and value_to_plot not in adata.obs.columns:. -> 1167 values = adata.raw.obs_vector(value_to_plot). 1168 else:. 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k). 169 def obs_vector(self, k: str) -> np.ndarray:. 170 # TODO decorator to copy AnnData.obs_vector docstring. --> 171 idx = self._normalize_indices((slice(None), k)). 172 a = self.X[idx]. 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.nd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4249,usability,learn,learn,4249,"ite-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index). 160 obs, var = unpack_index(packed_index). 161 obs = _normalize_index(obs, self._adata.obs_names). --> 162 var = _normalize_index(var, self.var_names). 163 return obs, var. 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 73 return indexer. 74 elif isinstance(indexer, str):. ---> 75 return index.get_loc(indexer) # int. 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):. 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 3629 return self._engine.get_loc(casted_key). 3630 except KeyError as err:. -> 3631 raise KeyError(key) from err. 3632 except TypeError:. 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions. scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:5839,usability,tool,toolz,5839,"nndescent==0.5.8. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. fsspec 2022.7.1. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.1.2. matplotlib 3.5.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.9. pythoncom NA. pytz 2022.1. pywintypes NA. ruamel NA. scipy 1.9.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.4.1. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. statsmodels 0.13.2. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.4.1. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-02-24 14:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2431:179,deployability,version,version,179,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:894,deployability,modul,module,894,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1535,deployability,Version,Versions,1535,"as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2555,deployability,updat,updated,2555,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1229,energy efficiency,optim,optimiser,1229,"is bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1346,energy efficiency,Optim,Optimiser,1346," raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:179,integrability,version,version,179,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1535,integrability,Version,Versions,1535,"as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:179,modifiability,version,version,179,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:894,modifiability,modul,module,894,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:971,modifiability,pac,packages,971,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1167,modifiability,pac,packages,1167," latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1327,modifiability,pac,packages,1327,"ndomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:1535,modifiability,Version,Versions,1535,"as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2032,modifiability,pac,packaging,2032,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2415,modifiability,pac,packaged,2415,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:396,reliability,doe,doesn,396,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:623,reliability,poisson,poisson,623,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:894,safety,modul,module,894,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2555,safety,updat,updated,2555,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2535,security,Session,Session,2535,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:2555,security,updat,updated,2555,"nnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pycparser 2.21. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.1. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-6.1.12-arch1-1-x86_64-with-glibc2.37. -----. Session information updated at 2023-02-25 19:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:830,testability,Trace,Traceback,830,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:139,usability,confirm,confirmed,139,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:222,usability,confirm,confirmed,222,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2431:987,usability,tool,tools,987,"TypeError when RandomState object passed to sc.tl.leiden; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The leiden function is supposed to accept a RandomState object but raises a TypeError when one is passed. This doesn't happen with any other function that accepts a RandomState object. . ```python. import scanpy as sc. import anndata as ad. import numpy as np. from scipy.sparse import csr_matrix. adata = ad.AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)). rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs). sc.pp.neighbors(adata, random_state=rs). sc.tl.leiden(adata, random_state=rs). ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden. part = leidenalg.find_partition(g, partition_type, **partition_kwargs). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition. optimiser.set_rng_seed(seed). File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed. _c_leiden._Optimiser_set_rng_seed(self._optimiser, value). TypeError: an integer is required (got type numpy.random.mtrand.RandomState). ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.4.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. invgauss_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2432:1042,availability,error,errors,1042," doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4266,availability,error,error,4266,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,deployability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:392,deployability,log,logcounts,392,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,deployability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,deployability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1169,deployability,contain,contain,1169,"om scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in cr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,deployability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3056,deployability,modul,module,3056,"pe, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,deployability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4417,deployability,Resourc,ResourceWarning,4417,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4527,deployability,Resourc,ResourceWarning,4527,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:447,energy efficiency,model,model,447,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:527,energy efficiency,model,model,527,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:681,energy efficiency,model,model,681,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4417,energy efficiency,Resourc,ResourceWarning,4417,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4527,energy efficiency,Resourc,ResourceWarning,4527,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,integrability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:426,integrability,sub,subset,426,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,integrability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,integrability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1825,integrability,wrap,wrapper,1825,"on(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2465,integrability,wrap,wrapper,2465,""", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"",",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2536,integrability,wrap,wrapper,2536,"gs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,integrability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,integrability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3832,integrability,wrap,wrapper,3832,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,interoperability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,interoperability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,interoperability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1619,interoperability,registr,registry,1619,"on(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1799,interoperability,registr,registry,1799,"ae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1825,interoperability,wrapper,wrapper,1825,"on(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2465,interoperability,wrapper,wrapper,2465,""", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"",",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2536,interoperability,wrapper,wrapper,2536,"gs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,interoperability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,interoperability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3617,interoperability,registr,registry,3617,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3806,interoperability,registr,registry,3806,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3832,interoperability,wrapper,wrapper,3832,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,modifiability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:207,modifiability,layer,layers,207,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:385,modifiability,layer,layer,385,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:479,modifiability,layer,layer,479,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,modifiability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,modifiability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1440,modifiability,pac,packages,1440,"vi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1592,modifiability,pac,packages,1592,"vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetI",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1772,modifiability,pac,packages,1772,"sm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1919,modifiability,pac,packages,1919,"ncat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2129,modifiability,pac,packages,2129,"1:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2305,modifiability,pac,packages,2305,"ates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,modifiability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3056,modifiability,modul,module,3056,"pe, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,modifiability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3149,modifiability,pac,packages,3149,"py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", lin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3272,modifiability,pac,packages,3272,"ng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error rais",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3438,modifiability,pac,packages,3438,"5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3590,modifiability,pac,packages,3590,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3779,modifiability,pac,packages,3779,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3926,modifiability,pac,packages,3926,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4118,modifiability,pac,packages,4118,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1042,performance,error,errors,1042," doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4266,performance,error,error,4266,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4417,performance,Resourc,ResourceWarning,4417,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4527,performance,Resourc,ResourceWarning,4527,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,reliability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,reliability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,reliability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,reliability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,reliability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:392,safety,log,logcounts,392,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1042,safety,error,errors,1042," doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2924,safety,except,exception,2924,"nndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2972,safety,except,exception,2972,"_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3056,safety,modul,module,3056,"pe, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4266,safety,error,error,4266,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4417,safety,Resourc,ResourceWarning,4417,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4527,safety,Resourc,ResourceWarning,4527,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,security,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:392,security,log,logcounts,392,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:447,security,model,model,447,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:527,security,model,model,527,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:681,security,model,model,681,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,security,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,security,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1712,security,modif,modifiers,1712,". adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,security,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,security,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3691,security,modif,modifiers,3691,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4303,security,ident,ident,4303,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:62,testability,integr,integration,62,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:392,testability,log,logcounts,392,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:853,testability,Integr,Integrated,853,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:976,testability,integr,integration,976,"obs_names_make_unique not working?; Hi, I was doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1357,testability,Trace,Traceback,1357,"riable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2984,testability,Trace,Traceback,2984,"_array. f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3026,testability,integr,integration,3026,"e(str_dtype), dtype=str_dtype, **dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3083,testability,Integr,Integrated,3083,"/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset. dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset. dset_id.write(h5s.ALL, h5s.ALL, data). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4417,testability,Resourc,ResourceWarning,4417,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4527,testability,Resourc,ResourceWarning,4527,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1042,usability,error,errors,1042," doing a dataset integration on quite some datasets. . ```py. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:. i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas). adata.obs_names_make_unique. sc.pp.log1p(adata). sc.pp.highly_variable_genes(. adata,. layer=""logcounts"",. batch_key=""Sample"",. subset=True. ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256). vae.train(). adata.obsm[""X_scVI""] = vae.get_latent_representation(). sc.pp.neighbors(adata, use_rep=""X_scVI""). from scvi.model.utils import mde. import pymde. adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]). adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(). adata.write_h5ad('Integrated.h5ad'). ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb. Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items. Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]. Traceback (most recent call last):. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem. _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array. f.create_dataset(k, data=elem.astype(str_dtype),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4266,usability,error,error,4266,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write. File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw. File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen. File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter. File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen. TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""integration.py"", line 66, in <module>. adata.write_h5ad('Integrated.h5ad'). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad. _write_h5ad(. File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad. write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper. return func(elem, key, val, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem. _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper. result = func(g, k, *args, **kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe. write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs). File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper. raise type(e)(. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /. /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>. _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2433:24,availability,cluster,clustering,24,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/issues/2433:266,availability,cluster,clustering,266,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/issues/2433:24,deployability,cluster,clustering,24,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/issues/2433:266,deployability,cluster,clustering,266,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/issues/2433:43,modifiability,variab,variables,43,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/issues/2433:285,modifiability,variab,variables,285,Computes a hierarchical clustering for the variables(genes) ; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? <!-- Please describe your wishes below: -->. Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/pull/2434:232,safety,test,tests,232,"Prepare for pandas 2.0; Collection of fixes for pandas 2.0. Interestingly enough, for is_categorical -> is_categorical_dtype we have already made this change in all but one file. I'm suspecting this file is left because this has no tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2434
https://github.com/scverse/scanpy/pull/2434:232,testability,test,tests,232,"Prepare for pandas 2.0; Collection of fixes for pandas 2.0. Interestingly enough, for is_categorical -> is_categorical_dtype we have already made this change in all but one file. I'm suspecting this file is left because this has no tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2434
https://github.com/scverse/scanpy/pull/2435:307,deployability,Releas,Release,307,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:611,safety,review,review,611,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:611,testability,review,review,611,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:462,usability,guid,guidelines,462,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:493,usability,guid,guide,493,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:589,usability,workflow,workflow,589,"Backport of Prepare for pandas 2.0 (#2434) onto 1.9.x; * is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/issues/2436:3237,availability,error,error,3237,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:192,deployability,version,version,192,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:1011,deployability,modul,module,1011,"sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3010,deployability,Version,Versions,3010,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3274,deployability,log,logging,3274,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:192,integrability,version,version,192,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3010,integrability,Version,Versions,3010,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:192,modifiability,version,version,192,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:1011,modifiability,modul,module,1011,"sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:1195,modifiability,pac,packages,1195," of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:1663,modifiability,pac,packages,1663,"0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_bat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:2269,modifiability,pac,packages,2269,"et, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3010,modifiability,Version,Versions,3010,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3237,performance,error,error,3237,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:22,reliability,doe,does,22,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3144,reliability,doe,does,3144,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:1011,safety,modul,module,1011,"sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
